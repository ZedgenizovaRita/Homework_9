{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alvOhaG_Y8w5"
   },
   "source": [
    "# Знакомство с pytorch (5 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jDDd8zvPY8w_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting scikit-learn==1.1\n",
      "  Using cached scikit-learn-1.1.0.tar.gz (6.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [2244 lines of output]\n",
      "  Partial import of sklearn during the build process.\n",
      "  setup.py:128: DeprecationWarning:\n",
      "  \n",
      "    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "    of the deprecation of `distutils` itself. It will be removed for\n",
      "    Python >= 3.12. For older Python versions it will remain present.\n",
      "    It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "    For more details, see:\n",
      "      https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "  \n",
      "  \n",
      "    from numpy.distutils.command.build_ext import build_ext  # noqa\n",
      "  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\ATLMFC\\include -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\include -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt /Tctest_program.c /Foobjects\\test_program.obj\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\ATLMFC\\lib\\x64 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.19041.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe\n",
      "  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\ATLMFC\\include -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\include -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt /Tctest_program.c /Foobjects\\test_program.obj /openmp\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\ATLMFC\\lib\\x64 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.19041.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe /openmp\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:67:5: Exception check on 'sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:122:5: Exception check on 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:147:5: Exception check on 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:177:5: Exception check on 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:206:5: Exception check on 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:217:5: Exception check on 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:242:5: Exception check on 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:253:5: Exception check on 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:300:5: Exception check on 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:323:5: Exception check on 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:386:5: Exception check on 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:418:5: Exception check on 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:476:5: Exception check on 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:499:5: Exception check on 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:312:38: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:314:36: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:335:38: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:337:36: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:735:44: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:806:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:813:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:806:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:813:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:806:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:813:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:806:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:813:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:837:40: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:908:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:915:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:908:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:915:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:908:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:915:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:908:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:915:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:944:38: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1015:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1022:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1015:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1022:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1015:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1022:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1015:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1022:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1055:38: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1100:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1107:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1100:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1107:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1100:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1107:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1100:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1107:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1156:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1163:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1156:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1163:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1156:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1163:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1156:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1163:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1194:36: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1239:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1246:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1239:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1246:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1239:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1246:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1239:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1246:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1295:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1302:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1295:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1302:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1295:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1302:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1295:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1302:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1350:38: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1395:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1402:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1395:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1402:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1395:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1402:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1395:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1402:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1451:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1458:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1451:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1458:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1451:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1458:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1451:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1458:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1495:47: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1540:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1547:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1540:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1547:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1540:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1547:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1540:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1547:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1596:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1603:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1596:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1603:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1596:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1603:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1596:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1603:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1628:39: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1673:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1680:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1673:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1680:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1673:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1680:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1673:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1680:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1729:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1736:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1729:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1736:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1729:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1736:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1729:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1736:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1790:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1806:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1790:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1806:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1790:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1806:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1790:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1806:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1846:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1865:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1846:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1865:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1846:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1865:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1846:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1865:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1907:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1921:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1907:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1921:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1907:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1921:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1907:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1921:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1957:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1973:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1957:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1973:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1957:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1973:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1957:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1973:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2015:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2029:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2015:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2029:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2015:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2029:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2015:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2029:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:27:5: Exception check on '_euclidean_dense_dense' will always require the GIL to be acquired. Declare '_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:59:5: Exception check on '_euclidean_sparse_dense' will always require the GIL to be acquired. Declare '_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:121:44: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:121:44: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:160:45: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:160:45: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:11:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:284:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:296:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:326:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:334:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:341:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:526:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:538:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:571:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:579:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:586:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:359:5: Exception check on '_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:605:5: Exception check on '_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:94:41: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:99:45: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:94:41: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:99:45: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:176:42: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:184:46: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:176:42: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:184:46: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:311:31: Exception check after calling '__pyx_fuse_0_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:311:31: Exception check after calling '__pyx_fuse_1_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:405:60: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:416:57: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:405:60: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:416:57: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:553:32: Exception check after calling '__pyx_fuse_0_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:553:32: Exception check after calling '__pyx_fuse_1_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:655:61: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:667:58: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:655:61: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:667:58: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:9:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:107:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:119:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:149:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:157:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:165:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:312:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:324:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:354:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:362:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:369:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:174:5: Exception check on '_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:379:5: Exception check on '_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:135:31: Exception check after calling '__pyx_fuse_0_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:135:31: Exception check after calling '__pyx_fuse_1_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:208:9: Exception check after calling '__pyx_fuse_0_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:208:9: Exception check after calling '__pyx_fuse_1_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:339:32: Exception check after calling '__pyx_fuse_0_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:339:32: Exception check after calling '__pyx_fuse_1_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:67:5: Exception check on 'update_center_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'update_center_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'update_center_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:175:5: Exception check on 'update_center_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'update_center_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'update_center_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:60:31: Exception check after calling '__pyx_fuse_0update_center_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0update_center_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0update_center_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:60:31: Exception check after calling '__pyx_fuse_1update_center_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1update_center_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1update_center_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:168:32: Exception check after calling '__pyx_fuse_0update_center_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0update_center_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0update_center_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:168:32: Exception check after calling '__pyx_fuse_1update_center_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1update_center_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1update_center_sparse' to allow an error code to be returned.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx:15:5: Exception check on 'init_bitset' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'init_bitset' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'init_bitset' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx:23:5: Exception check on 'set_bitset' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'set_bitset' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'set_bitset' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pxd:10:28: No exception value declared for 'in_bitset' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pxd:12:40: No exception value declared for 'in_bitset_memoryview' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pxd:15:42: No exception value declared for 'in_bitset_2d_memoryview' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx:69:38: Exception check after calling 'in_bitset_2d_memoryview' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'in_bitset_2d_memoryview' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx:74:40: Exception check after calling 'in_bitset_2d_memoryview' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'in_bitset_2d_memoryview' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx:135:38: Exception check after calling 'in_bitset_2d_memoryview' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'in_bitset_2d_memoryview' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:257:6: Exception check on '_build_histogram_naive' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_naive' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_naive' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:281:6: Exception check on '_subtract_histograms' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:305:6: Exception check on '_build_histogram' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:352:6: Exception check on '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:396:6: Exception check on '_build_histogram_root' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:449:6: Exception check on '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:161:60: Exception check after calling '_compute_histogram_brute_single_feature' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_histogram_brute_single_feature' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_histogram_brute_single_feature' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:193:48: Exception check after calling '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:197:37: Exception check after calling '_build_histogram_root' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:202:43: Exception check after calling '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:206:32: Exception check after calling '_build_histogram' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:249:32: Exception check after calling '_subtract_histograms' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          if n_used_bins <= 1:\n",
      "              free(cat_infos)\n",
      "              return\n",
      "  \n",
      "          qsort(cat_infos, n_used_bins, sizeof(categorical_info),\n",
      "                compare_cat_infos)\n",
      "                ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:920:14: Cannot assign type 'int (const void *, const void *) except? -1 nogil' to 'int (*)(const void *, const void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of 'compare_cat_infos'.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:46:5: Exception check on 'fmax' will always require the GIL to be acquired. Declare 'fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:52:5: Exception check on 'fsign' will always require the GIL to be acquired. Declare 'fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:61:5: Exception check on 'abs_max' will always require the GIL to be acquired. Declare 'abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:73:5: Exception check on 'max' will always require the GIL to be acquired. Declare 'max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:85:5: Exception check on 'diff_abs_max' will always require the GIL to be acquired. Declare 'diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:154:13: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:155:13: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:159:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:177:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:180:26: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:34: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:190:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:194:30: Exception check after calling '__pyx_fuse_0fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_0fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:206:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:207:21: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:213:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:218:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:221:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:231:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:235:38: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:154:13: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:155:13: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:159:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:177:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:180:26: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:34: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:190:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:194:30: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:206:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:207:21: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:213:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:218:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:221:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:231:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:235:38: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:396:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:447:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:447:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:468:30: Exception check after calling '__pyx_fuse_0fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_0fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:470:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:494:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:496:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:500:34: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:509:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:518:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:520:54: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:396:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:447:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:447:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:468:30: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:470:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:494:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:496:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:500:34: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:509:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:518:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:520:54: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:620:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:628:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:628:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:633:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:650:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:655:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:657:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:666:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:677:37: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:620:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:628:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:628:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:633:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:650:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:655:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:657:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:666:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:677:37: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:759:35: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:762:13: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:766:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:770:25: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:785:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:797:29: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:807:34: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:811:26: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:814:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:21: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:828:29: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:832:37: Exception check after calling '__pyx_fuse_0diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:837:38: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:849:42: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:857:41: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:864:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:865:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:875:29: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:880:37: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:759:35: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:762:13: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:766:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:770:25: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:785:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:797:29: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:807:34: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:811:26: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:814:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:21: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:828:29: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:832:37: Exception check after calling '__pyx_fuse_1diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:837:38: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:849:42: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:857:41: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:864:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:865:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:875:29: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:880:37: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1194:5: Exception check on 'predict_sample64' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1241:5: Exception check on 'predict_sample32' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:461:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:489:32: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:494:35: Exception check after calling 'dloss' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dloss' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:497:44: Exception check after calling 'dloss' will always require the GIL to be acquired. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:790:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:818:32: Exception check after calling 'predict_sample32' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:823:35: Exception check after calling 'dloss' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dloss' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:826:44: Exception check after calling 'dloss' will always require the GIL to be acquired. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1329:24: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1333:28: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1337:27: Exception check after calling 'dloss' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dloss' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1340:39: Exception check after calling '_loss' will always require the GIL to be acquired. Declare '_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:704:5: Exception check on 'l1penalty' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:547:31: Exception check after calling 'shuffle' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'shuffle' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'shuffle' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:549:28: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:557:25: Exception check after calling 'dot' will always require the GIL to be acquired. Declare 'dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:564:40: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:575:45: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:578:38: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:580:38: Exception check after calling 'dloss' will always require the GIL to be acquired. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:602:27: Exception check after calling 'scale' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'scale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'scale' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:605:25: Exception check after calling 'add' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'add' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:618:33: Exception check after calling 'add_average' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'add_average' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add_average' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:625:29: Exception check after calling 'l1penalty' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\manifold\\_barnes_hut_tsne.pyx:220:30: Exception check after calling 'summarize' will always require the GIL to be acquired. Declare 'summarize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:301:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:309:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:341:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:345:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:442:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:446:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:449:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:452:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:481:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:490:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:493:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:496:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:519:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:552:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:614:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:627:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:630:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:633:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:688:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:696:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:699:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:702:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:751:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:767:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:770:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:773:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:796:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:818:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:841:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:867:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:897:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:921:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:946:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:971:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:995:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1019:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1043:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1077:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1083:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1086:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1089:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1189:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\metrics\\_dist_metrics.pyx:1320:24: Exception check after calling 'dist' will always require the GIL to be acquired. Declare 'dist' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:115:37: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:338:43: Exception check after calling '_openmp_thread_num' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_openmp_thread_num' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:341:45: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:351:46: Exception check after calling '_parallel_on_X_init_chunk' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_init_chunk' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_init_chunk' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:360:64: Exception check after calling '_compute_and_reduce_distances_on_chunks' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_and_reduce_distances_on_chunks' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_and_reduce_distances_on_chunks' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:367:56: Exception check after calling '_parallel_on_X_prange_iter_finalize' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_prange_iter_finalize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_prange_iter_finalize' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:372:49: Exception check after calling '_parallel_on_X_parallel_finalize' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_finalize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_finalize' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:399:32: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:409:47: Exception check after calling '_openmp_thread_num' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_openmp_thread_num' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:412:49: Exception check after calling '_parallel_on_Y_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:421:64: Exception check after calling '_compute_and_reduce_distances_on_chunks' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_and_reduce_distances_on_chunks' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_and_reduce_distances_on_chunks' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:434:43: Exception check after calling '_parallel_on_Y_synchronize' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_synchronize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_synchronize' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:438:36: Exception check after calling '_parallel_on_Y_finalize' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_finalize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_finalize' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:763:53: Exception check after calling 'surrogate_dist' will always require the GIL to be acquired. Declare 'surrogate_dist' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:759:25: Exception check after calling '__pyx_fuse_1heap_push' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1heap_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:791:29: Exception check after calling '__pyx_fuse_1simultaneous_sort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1simultaneous_sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:851:33: Exception check after calling '__pyx_fuse_1heap_push' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1heap_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:874:33: Exception check after calling '__pyx_fuse_1simultaneous_sort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1simultaneous_sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:997:13: Exception check after calling '__pyx_fuse_1_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1088:60: Exception check after calling 'compute_exact_distances' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'compute_exact_distances' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'compute_exact_distances' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1095:61: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1096:60: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1103:52: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1104:51: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1120:94: Exception check after calling '_compute_distances_on_chunks' will always require the GIL to be acquired. Declare '_compute_distances_on_chunks' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1131:25: Exception check after calling '__pyx_fuse_1heap_push' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1heap_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1409:62: Exception check after calling 'surrogate_dist' will always require the GIL to be acquired. Declare 'surrogate_dist' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1451:33: Exception check after calling '__pyx_fuse_1simultaneous_sort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1simultaneous_sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1515:35: Exception check after calling '_merge_vectors' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_merge_vectors' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_merge_vectors' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1525:37: Exception check after calling '__pyx_fuse_1simultaneous_sort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1simultaneous_sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1644:71: Exception check after calling 'compute_exact_distances' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'compute_exact_distances' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'compute_exact_distances' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1651:72: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1652:60: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1659:63: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1660:51: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1676:93: Exception check after calling '_compute_distances_on_chunks' will always require the GIL to be acquired. Declare '_compute_distances_on_chunks' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:541:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:549:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:998:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1007:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1592:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:104:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:120:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:131:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          # determine number of levels in the tree, and from this\n",
      "          # the number of nodes in the tree.  This results in leaf nodes\n",
      "          # with numbers of points between leaf_size and 2 * leaf_size\n",
      "          self.n_levels = int(\n",
      "              np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1)\n",
      "          self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                              ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\neighbors\\_binary_tree.pxi:858:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'Py_ssize_t')\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1037:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1038:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1162:17: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1294:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1599:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1647:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1648:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1701:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1702:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1797:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1798:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1800:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1801:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1883:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1884:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1970:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1974:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1975:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1976:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2132:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2133:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2138:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2139:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2253:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2254:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2303:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2304:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2305:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2306:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:56:9: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:57:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:58:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:64:24: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_ball_tree.pyx\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:541:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:549:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:998:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1007:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1592:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:86:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:147:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          # determine number of levels in the tree, and from this\n",
      "          # the number of nodes in the tree.  This results in leaf nodes\n",
      "          # with numbers of points between leaf_size and 2 * leaf_size\n",
      "          self.n_levels = int(\n",
      "              np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1)\n",
      "          self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                              ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\neighbors\\_binary_tree.pxi:858:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'Py_ssize_t')\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1037:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1038:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1162:17: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1294:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1599:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1647:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1648:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1701:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1702:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1797:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1798:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1800:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1801:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1883:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1884:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1970:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1974:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1975:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1976:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2132:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2133:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2138:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2139:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2253:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2254:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2303:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2304:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2305:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2306:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:47:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:48:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:49:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:50:9: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_kd_tree.pyx\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:116:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:305:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:464:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:559:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:571:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      def __cinit__(self, int n_dimensions, int verbose):\n",
      "          \"\"\"Constructor.\"\"\"\n",
      "          # Parameters of the tree\n",
      "          self.n_dimensions = n_dimensions\n",
      "          self.verbose = verbose\n",
      "          self.n_cells_per_cell = 2 ** self.n_dimensions\n",
      "                                    ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\neighbors\\_quad_tree.pyx:56:34: Cannot assign type 'double' to 'SIZE_t' (alias of 'Py_ssize_t')\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_quad_tree.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          free_problem(problem)\n",
      "          free_parameter(param)\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:55:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          free_parameter(param)\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "      blas_functions.axpy = _axpy[double]\n",
      "                                 ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:56:31: Cannot assign type 'void (int, double, double *, int, double *, int) except * nogil' to 'axpy_func' (alias of 'void (*)(int, double, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "      blas_functions.axpy = _axpy[double]\n",
      "      blas_functions.scal = _scal[double]\n",
      "                                 ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:57:31: Cannot assign type 'void (int, double, double *, int) except * nogil' to 'scal_func' (alias of 'void (*)(int, double, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "      blas_functions.axpy = _axpy[double]\n",
      "      blas_functions.scal = _scal[double]\n",
      "      blas_functions.nrm2 = _nrm2[double]\n",
      "                                 ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:58:31: Cannot assign type 'double (int, double *, int) except * nogil' to 'nrm2_func' (alias of 'double (*)(int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\svm\\_liblinear.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if error_msg:\n",
      "          # for SVR: epsilon is called p in libsvm\n",
      "          error_repl = error_msg.decode('utf-8').replace(\"p < 0\", \"epsilon < 0\")\n",
      "          raise ValueError(error_repl)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:194:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                         class_weight_label.data, class_weight.data)\n",
      "      model = set_model(&param, <int> nSV.shape[0], SV.data, SV.shape,\n",
      "                        support.data, support.shape, sv_coef.strides,\n",
      "                        sv_coef.data, intercept.data, nSV.data, probA.data, probB.data)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:362:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                        sv_coef.data, intercept.data, nSV.data,\n",
      "                        probA.data, probB.data)\n",
      "  \n",
      "      cdef np.npy_intp n_class = get_nr(model)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:468:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          n_class = 1\n",
      "      else:\n",
      "          n_class = get_nr(model)\n",
      "          n_class = n_class * (n_class - 1) // 2\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:574:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if error_msg:\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef np.ndarray[np.float64_t, ndim=1, mode='c'] target\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:718:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\svm\\_libsvm.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if error_msg:\n",
      "          free_problem(problem)\n",
      "          free_param(param)\n",
      "          raise ValueError(error_msg)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:154:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                            sv_coef.data, intercept.data,\n",
      "                            nSV.data, probA.data, probB.data)\n",
      "      #TODO: use check_model\n",
      "      dec_values = np.empty(T_indptr.shape[0]-1)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:289:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      #TODO: use check_model\n",
      "      cdef np.npy_intp n_class = get_nr(model)\n",
      "      cdef int rv\n",
      "      dec_values = np.empty((T_indptr.shape[0]-1, n_class), dtype=np.float64)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:348:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          n_class = get_nr(model)\n",
      "          n_class = n_class * (n_class - 1) // 2\n",
      "  \n",
      "      dec_values = np.empty((T_indptr.shape[0] - 1, n_class), dtype=np.float64)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:417:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\svm\\_libsvm_sparse.pyx\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:46:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:71:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:78:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:85:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:250:76: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:311:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:328:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:345:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:641:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:684:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:695:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:706:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:918:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:968:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:999:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:1027:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:154:30: Exception check after calling 'children_impurity' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'children_impurity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'children_impurity' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:467:44: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:496:49: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:501:50: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:962:89: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:990:74: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:992:62: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1018:75: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1020:63: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1058:70: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1074:69: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1138:74: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1150:75: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1245:32: Exception check after calling 'poisson_loss' will always require the GIL to be acquired. Declare 'poisson_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1289:61: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1290:63: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1311:44: Exception check after calling 'poisson_loss' will always require the GIL to be acquired. Declare 'poisson_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1314:45: Exception check after calling 'poisson_loss' will always require the GIL to be acquired. Declare 'poisson_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:181:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:211:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:265:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:465:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:983:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:1213:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:43:5: Exception check on '_init_split' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_init_split' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_init_split' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:827:5: Exception check on 'binary_search' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'binary_search' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:852:5: Exception check on 'extract_nnz_index_to_samples' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'extract_nnz_index_to_samples' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_index_to_samples' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:892:5: Exception check on 'extract_nnz_binary_search' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'extract_nnz_binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_binary_search' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:964:5: Exception check on 'sparse_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'sparse_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sparse_swap' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if not is_samples_sorted[0]:\n",
      "          n_samples = end - start\n",
      "          memcpy(sorted_samples + start, samples + start,\n",
      "                 n_samples * sizeof(SIZE_t))\n",
      "          qsort(sorted_samples + start, n_samples, sizeof(SIZE_t),\n",
      "                compare_SIZE_t)\n",
      "                ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\tree\\_splitter.pyx:920:14: Cannot assign type 'int (const void *, const void *) except? -1 nogil' to 'int (*)(const void *, const void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of 'compare_SIZE_t'.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\tree\\_splitter.pyx\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:453:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:707:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:719:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:753:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_tree.pyx:315:5: Exception check on '_add_to_frontier' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_add_to_frontier' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_add_to_frontier' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "          # Initial capacity\n",
      "          cdef int init_capacity\n",
      "  \n",
      "          if tree.max_depth <= 10:\n",
      "              init_capacity = (2 ** (tree.max_depth + 1)) - 1\n",
      "                                                          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\tree\\_tree.pyx:163:56: Cannot assign type 'double' to 'int'\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\tree\\_tree.pyx\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:25:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:107:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:124:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:282:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:296:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:25:5: Exception check on 'safe_realloc' will always require the GIL to be acquired. Declare 'safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pxd:53:20: No exception value declared for 'rand_int' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\tree\\_utils.pxd:57:24: No exception value declared for 'rand_uniform' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\tree\\_utils.pxd:61:15: No exception value declared for 'log' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:115:20: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:138:24: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:280:32: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:305:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:306:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:309:47: Exception check after calling 'update_median_parameters_post_push' will always require the GIL to be acquired. Declare 'update_median_parameters_post_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:320:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:340:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:343:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:349:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:352:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:362:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:363:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:365:42: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:366:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:377:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:378:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:381:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:384:39: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:385:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:396:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:403:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:424:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:427:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:434:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:437:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:445:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:446:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:449:52: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:20:5: Exception check on '_dot' will always require the GIL to be acquired. Declare '_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:33:5: Exception check on '_asum' will always require the GIL to be acquired. Declare '_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:45:5: Exception check on '_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:58:5: Exception check on '_nrm2' will always require the GIL to be acquired. Declare '_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:70:5: Exception check on '_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:82:5: Exception check on '_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:94:5: Exception check on '_rotg' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_rotg' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rotg' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:107:5: Exception check on '_rot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_rot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rot' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:124:5: Exception check on '_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:153:5: Exception check on '_ger' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_ger' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:183:5: Exception check on '_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_heap.pxd:8:18: No exception value declared for 'heap_push' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  warning: sklearn\\utils\\_openmp_helpers.pyx:1:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\utils\\_openmp_helpers.pyx:44:4: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\utils\\_openmp_helpers.pyx:68:4: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  performance hint: sklearn\\utils\\_openmp_helpers.pxd:6:27: No exception value declared for '_openmp_thread_num' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:77:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:78:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:114:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:115:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:402:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:403:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:439:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:440:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:3:5: Exception check on 'dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pxd:5:26: No exception value declared for 'simultaneous_sort' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:53:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:56:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:58:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:60:25: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:68:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:70:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:72:25: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:81:25: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:83:17: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:53:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:56:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:58:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:60:25: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:68:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:70:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:72:25: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:81:25: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:83:17: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:178:29: Exception check after calling 'reset_wscale' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'reset_wscale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'reset_wscale' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:183:17: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:185:17: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:189:13: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:351:29: Exception check after calling 'reset_wscale' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'reset_wscale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'reset_wscale' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:356:17: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:358:17: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:362:13: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "  Compiling sklearn\\__check_build\\_check_build.pyx because it changed.\n",
      "  Compiling sklearn\\preprocessing\\_csr_polynomial_expansion.pyx because it changed.\n",
      "  Compiling sklearn\\_loss\\_loss.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_dbscan_inner.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_hierarchical_fast.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_common.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_lloyd.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_elkan.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_minibatch.pyx because it changed.\n",
      "  Compiling sklearn\\datasets\\_svmlight_format_fast.pyx because it changed.\n",
      "  Compiling sklearn\\decomposition\\_online_lda_fast.pyx because it changed.\n",
      "  Compiling sklearn\\decomposition\\_cdnmf_fast.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_gradient_boosting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx because it changed.\n",
      "  Compiling sklearn\\feature_extraction\\_hashing_fast.pyx because it changed.\n",
      "  Compiling sklearn\\manifold\\_utils.pyx because it changed.\n",
      "  Compiling sklearn\\manifold\\_barnes_hut_tsne.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_fast.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_dist_metrics.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_distances_reduction.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_ball_tree.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_kd_tree.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_partition_nodes.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_quad_tree.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_tree.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_splitter.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_criterion.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_utils.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\sparsefuncs_fast.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_cython_blas.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\arrayfuncs.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\murmurhash.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_fast_dict.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_openmp_helpers.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_seq_dataset.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_weight_vector.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_random.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_logistic_sigmoid.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_readonly_array_wrapper.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_typedefs.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_heap.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_sorting.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_vector_sentinel.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_newrand.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_libsvm.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_liblinear.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_libsvm_sparse.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_cd_fast.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_sgd_fast.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_sag_fast.pyx because it changed.\n",
      "  Compiling sklearn\\_isotonic.pyx because it changed.\n",
      "  multiprocessing.pool.RemoteTraceback:\n",
      "  \"\"\"\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "      result = (True, func(*args, **kwds))\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 48, in mapstar\n",
      "      return list(map(*args))\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  \"\"\"\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "  [ 1/59] Cythonizing sklearn\\__check_build\\_check_build.pyx\n",
      "  [ 2/59] Cythonizing sklearn\\_isotonic.pyx\n",
      "  [ 3/59] Cythonizing sklearn\\_loss\\_loss.pyx\n",
      "  [ 4/59] Cythonizing sklearn\\cluster\\_dbscan_inner.pyx\n",
      "  [ 5/59] Cythonizing sklearn\\cluster\\_hierarchical_fast.pyx\n",
      "  [ 6/59] Cythonizing sklearn\\cluster\\_k_means_common.pyx\n",
      "  [ 7/59] Cythonizing sklearn\\cluster\\_k_means_elkan.pyx\n",
      "  [ 8/59] Cythonizing sklearn\\cluster\\_k_means_lloyd.pyx\n",
      "  [ 9/59] Cythonizing sklearn\\cluster\\_k_means_minibatch.pyx\n",
      "  [10/59] Cythonizing sklearn\\datasets\\_svmlight_format_fast.pyx\n",
      "  [11/59] Cythonizing sklearn\\decomposition\\_cdnmf_fast.pyx\n",
      "  [12/59] Cythonizing sklearn\\decomposition\\_online_lda_fast.pyx\n",
      "  [13/59] Cythonizing sklearn\\ensemble\\_gradient_boosting.pyx\n",
      "  [14/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx\n",
      "  [15/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx\n",
      "  [16/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx\n",
      "  [17/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx\n",
      "  [18/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx\n",
      "  [19/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx\n",
      "  [20/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  [21/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx\n",
      "  [22/59] Cythonizing sklearn\\feature_extraction\\_hashing_fast.pyx\n",
      "  [23/59] Cythonizing sklearn\\linear_model\\_cd_fast.pyx\n",
      "  [24/59] Cythonizing sklearn\\linear_model\\_sag_fast.pyx\n",
      "  [25/59] Cythonizing sklearn\\linear_model\\_sgd_fast.pyx\n",
      "  [26/59] Cythonizing sklearn\\manifold\\_barnes_hut_tsne.pyx\n",
      "  [27/59] Cythonizing sklearn\\manifold\\_utils.pyx\n",
      "  [28/59] Cythonizing sklearn\\metrics\\_dist_metrics.pyx\n",
      "  [29/59] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction.pyx\n",
      "  [30/59] Cythonizing sklearn\\metrics\\_pairwise_fast.pyx\n",
      "  [31/59] Cythonizing sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx\n",
      "  [32/59] Cythonizing sklearn\\neighbors\\_ball_tree.pyx\n",
      "  [33/59] Cythonizing sklearn\\neighbors\\_kd_tree.pyx\n",
      "  [34/59] Cythonizing sklearn\\neighbors\\_partition_nodes.pyx\n",
      "  [35/59] Cythonizing sklearn\\neighbors\\_quad_tree.pyx\n",
      "  [36/59] Cythonizing sklearn\\preprocessing\\_csr_polynomial_expansion.pyx\n",
      "  [37/59] Cythonizing sklearn\\svm\\_liblinear.pyx\n",
      "  [38/59] Cythonizing sklearn\\svm\\_libsvm.pyx\n",
      "  [39/59] Cythonizing sklearn\\svm\\_libsvm_sparse.pyx\n",
      "  [40/59] Cythonizing sklearn\\svm\\_newrand.pyx\n",
      "  [41/59] Cythonizing sklearn\\tree\\_criterion.pyx\n",
      "  [42/59] Cythonizing sklearn\\tree\\_splitter.pyx\n",
      "  [43/59] Cythonizing sklearn\\tree\\_tree.pyx\n",
      "  [44/59] Cythonizing sklearn\\tree\\_utils.pyx\n",
      "  [45/59] Cythonizing sklearn\\utils\\_cython_blas.pyx\n",
      "  [46/59] Cythonizing sklearn\\utils\\_fast_dict.pyx\n",
      "  [47/59] Cythonizing sklearn\\utils\\_heap.pyx\n",
      "  [48/59] Cythonizing sklearn\\utils\\_logistic_sigmoid.pyx\n",
      "  [49/59] Cythonizing sklearn\\utils\\_openmp_helpers.pyx\n",
      "  [50/59] Cythonizing sklearn\\utils\\_random.pyx\n",
      "  [51/59] Cythonizing sklearn\\utils\\_readonly_array_wrapper.pyx\n",
      "  [52/59] Cythonizing sklearn\\utils\\_seq_dataset.pyx\n",
      "  [53/59] Cythonizing sklearn\\utils\\_sorting.pyx\n",
      "  [54/59] Cythonizing sklearn\\utils\\_typedefs.pyx\n",
      "  [55/59] Cythonizing sklearn\\utils\\_vector_sentinel.pyx\n",
      "  [56/59] Cythonizing sklearn\\utils\\_weight_vector.pyx\n",
      "  [57/59] Cythonizing sklearn\\utils\\arrayfuncs.pyx\n",
      "  [58/59] Cythonizing sklearn\\utils\\murmurhash.pyx\n",
      "  [59/59] Cythonizing sklearn\\utils\\sparsefuncs_fast.pyx\n",
      "      main()\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 174, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 268, in run_setup\n",
      "      self).run_setup(setup_script=setup_script)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 158, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 328, in <module>\n",
      "      setup_package()\n",
      "    File \"setup.py\", line 324, in setup_package\n",
      "      setup(**metadata)\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 135, in setup\n",
      "      config = configuration()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "    File \"setup.py\", line 187, in configuration\n",
      "      config.add_subpackage(\"sklearn\")\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1050, in add_subpackage\n",
      "      config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1016, in get_subpackage\n",
      "      config = self._get_configuration_from_setup_py(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 958, in _get_configuration_from_setup_py\n",
      "      config = setup_module.configuration(*args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-install-zhdcz9et\\scikit-learn_5eb1221bb6cc44d0b4e9c952a5ff1649\\sklearn\\setup.py\", line 85, in configuration\n",
      "      cythonize_extensions(top_path, config)\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-install-zhdcz9et\\scikit-learn_5eb1221bb6cc44d0b4e9c952a5ff1649\\sklearn\\_build_utils\\__init__.py\", line 74, in cythonize_extensions\n",
      "      config.ext_modules = cythonize(\n",
      "                           ^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-02qzd062\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1145, in cythonize\n",
      "      result.get(99999)  # seconds\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 774, in get\n",
      "      raise self._value\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.1\n",
      "  Using cached scikit-learn-1.1.0.tar.gz (6.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [2244 lines of output]\n",
      "  Partial import of sklearn during the build process.\n",
      "  setup.py:128: DeprecationWarning:\n",
      "  \n",
      "    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "    of the deprecation of `distutils` itself. It will be removed for\n",
      "    Python >= 3.12. For older Python versions it will remain present.\n",
      "    It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "    For more details, see:\n",
      "      https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "  \n",
      "  \n",
      "    from numpy.distutils.command.build_ext import build_ext  # noqa\n",
      "  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\ATLMFC\\include -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\include -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt /Tctest_program.c /Foobjects\\test_program.obj\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\ATLMFC\\lib\\x64 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.19041.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe\n",
      "  INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\ATLMFC\\include -IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\include -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt /Tctest_program.c /Foobjects\\test_program.obj /openmp\n",
      "  INFO: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\bin\\HostX86\\x64\\link.exe /nologo /INCREMENTAL:NO /LTCG /MANIFEST:EMBED,ID=1 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\ATLMFC\\lib\\x64 /LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.32.31326\\lib\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64 /LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.19041.0\\\\um\\x64 objects\\test_program.obj /OUT:test_program.exe /openmp\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:67:5: Exception check on 'sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:122:5: Exception check on 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:147:5: Exception check on 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:177:5: Exception check on 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:206:5: Exception check on 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:217:5: Exception check on 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:242:5: Exception check on 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:253:5: Exception check on 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:300:5: Exception check on 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:323:5: Exception check on 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:386:5: Exception check on 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:418:5: Exception check on 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:476:5: Exception check on 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:499:5: Exception check on 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:312:38: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:314:36: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:335:38: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:337:36: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:735:44: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:806:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:813:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:806:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:813:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:806:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:813:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:806:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:813:52: Exception check after calling 'cgrad_hess_half_squared_error' will always require the GIL to be acquired. Declare 'cgrad_hess_half_squared_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:837:40: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:908:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:915:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:908:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:915:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:908:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:915:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:908:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:915:48: Exception check after calling 'cgrad_hess_absolute_error' will always require the GIL to be acquired. Declare 'cgrad_hess_absolute_error' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:944:38: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1015:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1022:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1015:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1022:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1015:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1022:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1015:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1022:46: Exception check after calling 'cgrad_hess_pinball_loss' will always require the GIL to be acquired. Declare 'cgrad_hess_pinball_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1055:38: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1100:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1107:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1100:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1107:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1100:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1107:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1100:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1107:46: Exception check after calling 'closs_grad_half_poisson' will always require the GIL to be acquired. Declare 'closs_grad_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1156:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1163:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1156:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1163:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1156:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1163:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1156:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1163:46: Exception check after calling 'cgrad_hess_half_poisson' will always require the GIL to be acquired. Declare 'cgrad_hess_half_poisson' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1194:36: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1239:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1246:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1239:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1246:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1239:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1246:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1239:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1246:44: Exception check after calling 'closs_grad_half_gamma' will always require the GIL to be acquired. Declare 'closs_grad_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1295:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1302:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1295:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1302:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1295:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1302:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1295:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1302:44: Exception check after calling 'cgrad_hess_half_gamma' will always require the GIL to be acquired. Declare 'cgrad_hess_half_gamma' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1350:38: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1395:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1402:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1395:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1402:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1395:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1402:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1395:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1402:46: Exception check after calling 'closs_grad_half_tweedie' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1451:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1458:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1451:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1458:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1451:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1458:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1451:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1458:46: Exception check after calling 'cgrad_hess_half_tweedie' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1495:47: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1540:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1547:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1540:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1547:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1540:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1547:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1540:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1547:55: Exception check after calling 'closs_grad_half_tweedie_identity' will always require the GIL to be acquired. Declare 'closs_grad_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1596:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1603:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1596:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1603:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1596:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1603:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1596:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1603:55: Exception check after calling 'cgrad_hess_half_tweedie_identity' will always require the GIL to be acquired. Declare 'cgrad_hess_half_tweedie_identity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1628:39: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1673:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1680:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1673:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1680:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1673:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1680:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1673:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1680:47: Exception check after calling 'closs_grad_half_binomial' will always require the GIL to be acquired. Declare 'closs_grad_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1729:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1736:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1729:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1736:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1729:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1736:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1729:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1736:47: Exception check after calling 'cgrad_hess_half_binomial' will always require the GIL to be acquired. Declare 'cgrad_hess_half_binomial' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1790:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1806:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1790:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1806:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1790:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1806:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1790:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1806:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1846:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1865:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1846:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1865:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1846:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1865:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1846:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1865:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1907:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1921:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1907:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1921:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1907:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1921:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1907:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1921:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1957:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1973:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1957:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1973:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1957:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1973:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1957:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:1973:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2015:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2029:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2015:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2029:37: Exception check after calling '__pyx_fuse_0sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2015:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2029:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2015:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\_loss\\_loss.pyx:2029:37: Exception check after calling '__pyx_fuse_1sum_exp_minus_max' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1sum_exp_minus_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1sum_exp_minus_max' to allow an error code to be returned.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:27:5: Exception check on '_euclidean_dense_dense' will always require the GIL to be acquired. Declare '_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:59:5: Exception check on '_euclidean_sparse_dense' will always require the GIL to be acquired. Declare '_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:121:44: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:121:44: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:160:45: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_common.pyx:160:45: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:11:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:284:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:296:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:326:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:334:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:341:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:526:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:538:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:571:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:579:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_elkan.pyx:586:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:359:5: Exception check on '_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:605:5: Exception check on '_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:94:41: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:99:45: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:94:41: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:99:45: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:176:42: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:184:46: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:176:42: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:184:46: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:311:31: Exception check after calling '__pyx_fuse_0_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:311:31: Exception check after calling '__pyx_fuse_1_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:405:60: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:416:57: Exception check after calling '__pyx_fuse_0_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:405:60: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:416:57: Exception check after calling '__pyx_fuse_1_euclidean_dense_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_dense_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:553:32: Exception check after calling '__pyx_fuse_0_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:553:32: Exception check after calling '__pyx_fuse_1_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:655:61: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:667:58: Exception check after calling '__pyx_fuse_0_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:655:61: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\cluster\\_k_means_elkan.pyx:667:58: Exception check after calling '__pyx_fuse_1_euclidean_sparse_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_euclidean_sparse_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:9:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:107:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:119:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:149:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:157:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:165:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:312:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:324:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:354:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:362:12: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\cluster\\_k_means_lloyd.pyx:369:8: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:174:5: Exception check on '_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:379:5: Exception check on '_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:135:31: Exception check after calling '__pyx_fuse_0_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:135:31: Exception check after calling '__pyx_fuse_1_update_chunk_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:208:9: Exception check after calling '__pyx_fuse_0_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:208:9: Exception check after calling '__pyx_fuse_1_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:339:32: Exception check after calling '__pyx_fuse_0_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_lloyd.pyx:339:32: Exception check after calling '__pyx_fuse_1_update_chunk_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_update_chunk_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_update_chunk_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:67:5: Exception check on 'update_center_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'update_center_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'update_center_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:175:5: Exception check on 'update_center_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'update_center_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'update_center_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:60:31: Exception check after calling '__pyx_fuse_0update_center_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0update_center_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0update_center_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:60:31: Exception check after calling '__pyx_fuse_1update_center_dense' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1update_center_dense' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1update_center_dense' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:168:32: Exception check after calling '__pyx_fuse_0update_center_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0update_center_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0update_center_sparse' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\cluster\\_k_means_minibatch.pyx:168:32: Exception check after calling '__pyx_fuse_1update_center_sparse' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1update_center_sparse' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1update_center_sparse' to allow an error code to be returned.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx:15:5: Exception check on 'init_bitset' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'init_bitset' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'init_bitset' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx:23:5: Exception check on 'set_bitset' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'set_bitset' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'set_bitset' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pxd:10:28: No exception value declared for 'in_bitset' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pxd:12:40: No exception value declared for 'in_bitset_memoryview' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pxd:15:42: No exception value declared for 'in_bitset_2d_memoryview' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx:69:38: Exception check after calling 'in_bitset_2d_memoryview' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'in_bitset_2d_memoryview' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx:74:40: Exception check after calling 'in_bitset_2d_memoryview' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'in_bitset_2d_memoryview' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx:135:38: Exception check after calling 'in_bitset_2d_memoryview' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'in_bitset_2d_memoryview' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:257:6: Exception check on '_build_histogram_naive' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_naive' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_naive' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:281:6: Exception check on '_subtract_histograms' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:305:6: Exception check on '_build_histogram' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:352:6: Exception check on '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:396:6: Exception check on '_build_histogram_root' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:449:6: Exception check on '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:161:60: Exception check after calling '_compute_histogram_brute_single_feature' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_histogram_brute_single_feature' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_histogram_brute_single_feature' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:193:48: Exception check after calling '_build_histogram_root_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:197:37: Exception check after calling '_build_histogram_root' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_root' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_root' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:202:43: Exception check after calling '_build_histogram_no_hessian' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram_no_hessian' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram_no_hessian' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:206:32: Exception check after calling '_build_histogram' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_build_histogram' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_build_histogram' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx:249:32: Exception check after calling '_subtract_histograms' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_subtract_histograms' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_subtract_histograms' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          if n_used_bins <= 1:\n",
      "              free(cat_infos)\n",
      "              return\n",
      "  \n",
      "          qsort(cat_infos, n_used_bins, sizeof(categorical_info),\n",
      "                compare_cat_infos)\n",
      "                ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx:920:14: Cannot assign type 'int (const void *, const void *) except? -1 nogil' to 'int (*)(const void *, const void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of 'compare_cat_infos'.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:46:5: Exception check on 'fmax' will always require the GIL to be acquired. Declare 'fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:52:5: Exception check on 'fsign' will always require the GIL to be acquired. Declare 'fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:61:5: Exception check on 'abs_max' will always require the GIL to be acquired. Declare 'abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:73:5: Exception check on 'max' will always require the GIL to be acquired. Declare 'max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:85:5: Exception check on 'diff_abs_max' will always require the GIL to be acquired. Declare 'diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:154:13: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:155:13: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:159:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:177:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:180:26: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:34: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:190:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:194:30: Exception check after calling '__pyx_fuse_0fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_0fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:206:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:207:21: Exception check after calling '__pyx_fuse_0_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:213:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:218:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:221:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:231:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:235:38: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:154:13: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:155:13: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:159:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:177:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:180:26: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:34: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:185:46: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:190:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:194:30: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:196:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:206:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:207:21: Exception check after calling '__pyx_fuse_1_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:213:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:215:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:218:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:221:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:231:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:235:38: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:396:19: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:447:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:447:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:468:30: Exception check after calling '__pyx_fuse_0fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_0fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:470:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:494:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:496:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:500:34: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:509:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:518:31: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:520:54: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:396:19: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:447:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:447:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:468:30: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:470:28: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:494:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:496:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:500:34: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:509:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:518:31: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:520:54: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:620:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:628:33: Exception check after calling '__pyx_fuse_0fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_0fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:628:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:633:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:650:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:655:39: Exception check after calling '__pyx_fuse_0max' will always require the GIL to be acquired. Declare '__pyx_fuse_0max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:657:43: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:666:30: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:677:37: Exception check after calling '__pyx_fuse_0_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:620:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:628:33: Exception check after calling '__pyx_fuse_1fsign' will always require the GIL to be acquired. Declare '__pyx_fuse_1fsign' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:628:45: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:633:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:650:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:655:39: Exception check after calling '__pyx_fuse_1max' will always require the GIL to be acquired. Declare '__pyx_fuse_1max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:657:43: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:666:30: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:677:37: Exception check after calling '__pyx_fuse_1_asum' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:759:35: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:762:13: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:766:25: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:770:25: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:785:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:797:29: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:807:34: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:811:26: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:814:21: Exception check after calling '__pyx_fuse_0_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:21: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:828:29: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:832:37: Exception check after calling '__pyx_fuse_0diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:837:38: Exception check after calling '__pyx_fuse_0abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_0abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:849:42: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:857:41: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:864:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:865:30: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:875:29: Exception check after calling '__pyx_fuse_0_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:880:37: Exception check after calling '__pyx_fuse_0_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:759:35: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:762:13: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:766:25: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:770:25: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:785:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:797:29: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:807:34: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:811:26: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:814:21: Exception check after calling '__pyx_fuse_1_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:35: Exception check after calling '__pyx_fuse_1fmax' will always require the GIL to be acquired. Declare '__pyx_fuse_1fmax' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:815:21: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:828:29: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:832:37: Exception check after calling '__pyx_fuse_1diff_abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1diff_abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:837:38: Exception check after calling '__pyx_fuse_1abs_max' will always require the GIL to be acquired. Declare '__pyx_fuse_1abs_max' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:849:42: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:857:41: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:864:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:865:30: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:875:29: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_cd_fast.pyx:880:37: Exception check after calling '__pyx_fuse_1_nrm2' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1194:5: Exception check on 'predict_sample64' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1241:5: Exception check on 'predict_sample32' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:461:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:489:32: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:494:35: Exception check after calling 'dloss' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dloss' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:497:44: Exception check after calling 'dloss' will always require the GIL to be acquired. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:790:43: Exception check after calling 'random' will always require the GIL to be acquired. Declare 'random' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:818:32: Exception check after calling 'predict_sample32' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample32' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample32' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:823:35: Exception check after calling 'dloss' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dloss' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:826:44: Exception check after calling 'dloss' will always require the GIL to be acquired. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1329:24: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1333:28: Exception check after calling 'predict_sample64' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'predict_sample64' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'predict_sample64' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1337:27: Exception check after calling 'dloss' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dloss' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sag_fast.pyx:1340:39: Exception check after calling '_loss' will always require the GIL to be acquired. Declare '_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:704:5: Exception check on 'l1penalty' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:547:31: Exception check after calling 'shuffle' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'shuffle' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'shuffle' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:549:28: Exception check after calling 'next' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'next' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'next' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:557:25: Exception check after calling 'dot' will always require the GIL to be acquired. Declare 'dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:564:40: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:575:45: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:578:38: Exception check after calling 'loss' will always require the GIL to be acquired. Declare 'loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:580:38: Exception check after calling 'dloss' will always require the GIL to be acquired. Declare 'dloss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:602:27: Exception check after calling 'scale' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'scale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'scale' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:605:25: Exception check after calling 'add' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'add' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:618:33: Exception check after calling 'add_average' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'add_average' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'add_average' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\linear_model\\_sgd_fast.pyx:625:29: Exception check after calling 'l1penalty' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'l1penalty' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'l1penalty' to allow an error code to be returned.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\manifold\\_barnes_hut_tsne.pyx:220:30: Exception check after calling 'summarize' will always require the GIL to be acquired. Declare 'summarize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:301:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:309:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:341:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:345:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:442:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:446:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:449:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:452:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:481:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:490:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:493:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:496:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:519:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:552:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:614:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:627:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:630:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:633:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:688:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:696:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:699:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:702:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:751:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:767:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:770:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:773:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:796:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:818:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:841:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:867:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:897:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:921:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:946:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:971:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:995:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1019:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1043:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1077:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1083:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1086:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1089:74: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pyx:1189:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\metrics\\_dist_metrics.pyx:1320:24: Exception check after calling 'dist' will always require the GIL to be acquired. Declare 'dist' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:115:37: Exception check after calling '__pyx_fuse_1_dot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:338:43: Exception check after calling '_openmp_thread_num' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_openmp_thread_num' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:341:45: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:351:46: Exception check after calling '_parallel_on_X_init_chunk' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_init_chunk' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_init_chunk' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:360:64: Exception check after calling '_compute_and_reduce_distances_on_chunks' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_and_reduce_distances_on_chunks' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_and_reduce_distances_on_chunks' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:367:56: Exception check after calling '_parallel_on_X_prange_iter_finalize' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_prange_iter_finalize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_prange_iter_finalize' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:372:49: Exception check after calling '_parallel_on_X_parallel_finalize' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_finalize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_finalize' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:399:32: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:409:47: Exception check after calling '_openmp_thread_num' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_openmp_thread_num' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:412:49: Exception check after calling '_parallel_on_Y_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:421:64: Exception check after calling '_compute_and_reduce_distances_on_chunks' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_compute_and_reduce_distances_on_chunks' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_compute_and_reduce_distances_on_chunks' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:434:43: Exception check after calling '_parallel_on_Y_synchronize' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_synchronize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_synchronize' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:438:36: Exception check after calling '_parallel_on_Y_finalize' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_finalize' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_finalize' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:763:53: Exception check after calling 'surrogate_dist' will always require the GIL to be acquired. Declare 'surrogate_dist' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:759:25: Exception check after calling '__pyx_fuse_1heap_push' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1heap_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:791:29: Exception check after calling '__pyx_fuse_1simultaneous_sort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1simultaneous_sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:851:33: Exception check after calling '__pyx_fuse_1heap_push' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1heap_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:874:33: Exception check after calling '__pyx_fuse_1simultaneous_sort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1simultaneous_sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:997:13: Exception check after calling '__pyx_fuse_1_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1088:60: Exception check after calling 'compute_exact_distances' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'compute_exact_distances' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'compute_exact_distances' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1095:61: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1096:60: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1103:52: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1104:51: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1120:94: Exception check after calling '_compute_distances_on_chunks' will always require the GIL to be acquired. Declare '_compute_distances_on_chunks' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1131:25: Exception check after calling '__pyx_fuse_1heap_push' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1heap_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1409:62: Exception check after calling 'surrogate_dist' will always require the GIL to be acquired. Declare 'surrogate_dist' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1451:33: Exception check after calling '__pyx_fuse_1simultaneous_sort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1simultaneous_sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1515:35: Exception check after calling '_merge_vectors' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_merge_vectors' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_merge_vectors' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1525:37: Exception check after calling '__pyx_fuse_1simultaneous_sort' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1simultaneous_sort' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1644:71: Exception check after calling 'compute_exact_distances' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'compute_exact_distances' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'compute_exact_distances' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1651:72: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1652:60: Exception check after calling '_parallel_on_X_parallel_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_X_parallel_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_X_parallel_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1659:63: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1660:51: Exception check after calling '_parallel_on_Y_init' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_parallel_on_Y_init' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_parallel_on_Y_init' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\metrics\\_pairwise_distances_reduction.pyx:1676:93: Exception check after calling '_compute_distances_on_chunks' will always require the GIL to be acquired. Declare '_compute_distances_on_chunks' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:541:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:549:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:998:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1007:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1592:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:104:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:120:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:131:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          # determine number of levels in the tree, and from this\n",
      "          # the number of nodes in the tree.  This results in leaf nodes\n",
      "          # with numbers of points between leaf_size and 2 * leaf_size\n",
      "          self.n_levels = int(\n",
      "              np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1)\n",
      "          self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                              ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\neighbors\\_binary_tree.pxi:858:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'Py_ssize_t')\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1037:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1038:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1162:17: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1294:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1599:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1647:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1648:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1701:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1702:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1797:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1798:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1800:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1801:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1883:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1884:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1970:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1974:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1975:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1976:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2132:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2133:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2138:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2139:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2253:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2254:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2303:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2304:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2305:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2306:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:56:9: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:57:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:58:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_ball_tree.pyx:64:24: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_ball_tree.pyx\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:541:66: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:549:49: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:998:58: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1007:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1592:78: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:86:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:147:82: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:12:64: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:22:65: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:31:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:35:79: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:54:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:57:52: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:64:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\metrics\\_dist_metrics.pxd:66:67: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          # determine number of levels in the tree, and from this\n",
      "          # the number of nodes in the tree.  This results in leaf nodes\n",
      "          # with numbers of points between leaf_size and 2 * leaf_size\n",
      "          self.n_levels = int(\n",
      "              np.log2(fmax(1, (n_samples - 1) / self.leaf_size)) + 1)\n",
      "          self.n_nodes = (2 ** self.n_levels) - 1\n",
      "                                              ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\neighbors\\_binary_tree.pxi:858:44: Cannot assign type 'double' to 'ITYPE_t' (alias of 'Py_ssize_t')\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1037:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1038:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1162:17: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1294:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1599:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1647:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1648:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1701:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1702:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1797:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1798:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1800:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1801:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1883:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1884:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1970:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1974:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1975:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:1976:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2132:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2133:13: Assigning to 'NodeData_t *' from 'const NodeData_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2138:28: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2139:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2253:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2254:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2303:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2304:13: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2305:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_binary_tree.pxi:2306:13: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:47:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:48:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:49:9: Assigning to 'DTYPE_t *' from 'const DTYPE_t *' discards const qualifier\n",
      "  warning: sklearn\\neighbors\\_kd_tree.pyx:50:9: Assigning to 'ITYPE_t *' from 'const ITYPE_t *' discards const qualifier\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_kd_tree.pyx\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:116:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:305:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:464:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:559:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pyx:571:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      def __cinit__(self, int n_dimensions, int verbose):\n",
      "          \"\"\"Constructor.\"\"\"\n",
      "          # Parameters of the tree\n",
      "          self.n_dimensions = n_dimensions\n",
      "          self.verbose = verbose\n",
      "          self.n_cells_per_cell = 2 ** self.n_dimensions\n",
      "                                    ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\neighbors\\_quad_tree.pyx:56:34: Cannot assign type 'double' to 'SIZE_t' (alias of 'Py_ssize_t')\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\neighbors\\_quad_tree.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          free_problem(problem)\n",
      "          free_parameter(param)\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:55:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          free_parameter(param)\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "      blas_functions.axpy = _axpy[double]\n",
      "                                 ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:56:31: Cannot assign type 'void (int, double, double *, int, double *, int) except * nogil' to 'axpy_func' (alias of 'void (*)(int, double, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "      blas_functions.axpy = _axpy[double]\n",
      "      blas_functions.scal = _scal[double]\n",
      "                                 ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:57:31: Cannot assign type 'void (int, double, double *, int) except * nogil' to 'scal_func' (alias of 'void (*)(int, double, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "      blas_functions.axpy = _axpy[double]\n",
      "      blas_functions.scal = _scal[double]\n",
      "      blas_functions.nrm2 = _nrm2[double]\n",
      "                                 ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_liblinear.pyx:58:31: Cannot assign type 'double (int, double *, int) except * nogil' to 'nrm2_func' (alias of 'double (*)(int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\svm\\_liblinear.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if error_msg:\n",
      "          # for SVR: epsilon is called p in libsvm\n",
      "          error_repl = error_msg.decode('utf-8').replace(\"p < 0\", \"epsilon < 0\")\n",
      "          raise ValueError(error_repl)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:194:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                         class_weight_label.data, class_weight.data)\n",
      "      model = set_model(&param, <int> nSV.shape[0], SV.data, SV.shape,\n",
      "                        support.data, support.shape, sv_coef.strides,\n",
      "                        sv_coef.data, intercept.data, nSV.data, probA.data, probB.data)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:362:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                        sv_coef.data, intercept.data, nSV.data,\n",
      "                        probA.data, probB.data)\n",
      "  \n",
      "      cdef np.npy_intp n_class = get_nr(model)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:468:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          n_class = 1\n",
      "      else:\n",
      "          n_class = get_nr(model)\n",
      "          n_class = n_class * (n_class - 1) // 2\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:574:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if error_msg:\n",
      "          raise ValueError(error_msg)\n",
      "  \n",
      "      cdef np.ndarray[np.float64_t, ndim=1, mode='c'] target\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm.pyx:718:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\svm\\_libsvm.pyx\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if error_msg:\n",
      "          free_problem(problem)\n",
      "          free_param(param)\n",
      "          raise ValueError(error_msg)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:154:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "                            sv_coef.data, intercept.data,\n",
      "                            nSV.data, probA.data, probB.data)\n",
      "      #TODO: use check_model\n",
      "      dec_values = np.empty(T_indptr.shape[0]-1)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:289:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      #TODO: use check_model\n",
      "      cdef np.npy_intp n_class = get_nr(model)\n",
      "      cdef int rv\n",
      "      dec_values = np.empty((T_indptr.shape[0]-1, n_class), dtype=np.float64)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:348:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "          n_class = get_nr(model)\n",
      "          n_class = n_class * (n_class - 1) // 2\n",
      "  \n",
      "      dec_values = np.empty((T_indptr.shape[0] - 1, n_class), dtype=np.float64)\n",
      "      cdef BlasFunctions blas_functions\n",
      "      blas_functions.dot = _dot[double]\n",
      "                               ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\svm\\_libsvm_sparse.pyx:417:29: Cannot assign type 'double (int, double *, int, double *, int) except * nogil' to 'dot_func' (alias of 'double (*)(int, double *, int, double *, int) noexcept'). Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\svm\\_libsvm_sparse.pyx\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:46:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:71:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:78:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:85:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:250:76: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:311:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:328:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:345:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:641:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:684:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:695:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:706:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:918:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:968:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:999:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pyx:1027:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:154:30: Exception check after calling 'children_impurity' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'children_impurity' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'children_impurity' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:467:44: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:496:49: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:501:50: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:962:89: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:990:74: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:992:62: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1018:75: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1020:63: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1058:70: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1074:69: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1138:74: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1150:75: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1245:32: Exception check after calling 'poisson_loss' will always require the GIL to be acquired. Declare 'poisson_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1289:61: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1290:63: Exception check after calling 'log' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'log' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1311:44: Exception check after calling 'poisson_loss' will always require the GIL to be acquired. Declare 'poisson_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_criterion.pyx:1314:45: Exception check after calling 'poisson_loss' will always require the GIL to be acquired. Declare 'poisson_loss' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:181:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:211:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:265:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:465:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:983:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pyx:1213:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:43:5: Exception check on '_init_split' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_init_split' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_init_split' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:827:5: Exception check on 'binary_search' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'binary_search' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:852:5: Exception check on 'extract_nnz_index_to_samples' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'extract_nnz_index_to_samples' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_index_to_samples' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:892:5: Exception check on 'extract_nnz_binary_search' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'extract_nnz_binary_search' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'extract_nnz_binary_search' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\tree\\_splitter.pyx:964:5: Exception check on 'sparse_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'sparse_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'sparse_swap' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "      if not is_samples_sorted[0]:\n",
      "          n_samples = end - start\n",
      "          memcpy(sorted_samples + start, samples + start,\n",
      "                 n_samples * sizeof(SIZE_t))\n",
      "          qsort(sorted_samples + start, n_samples, sizeof(SIZE_t),\n",
      "                compare_SIZE_t)\n",
      "                ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\tree\\_splitter.pyx:920:14: Cannot assign type 'int (const void *, const void *) except? -1 nogil' to 'int (*)(const void *, const void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of 'compare_SIZE_t'.\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\tree\\_splitter.pyx\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:453:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:707:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:719:70: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pyx:753:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_tree.pyx:315:5: Exception check on '_add_to_frontier' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_add_to_frontier' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_add_to_frontier' to allow an error code to be returned.\n",
      "  \n",
      "  Error compiling Cython file:\n",
      "  ------------------------------------------------------------\n",
      "  ...\n",
      "  \n",
      "          # Initial capacity\n",
      "          cdef int init_capacity\n",
      "  \n",
      "          if tree.max_depth <= 10:\n",
      "              init_capacity = (2 ** (tree.max_depth + 1)) - 1\n",
      "                                                          ^\n",
      "  ------------------------------------------------------------\n",
      "  \n",
      "  sklearn\\tree\\_tree.pyx:163:56: Cannot assign type 'double' to 'int'\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\tree\\_tree.pyx\n",
      "  warning: sklearn\\tree\\_utils.pxd:47:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:78:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:80:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:101:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pxd:102:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:61:73: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:62:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_tree.pxd:63:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:84:72: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_splitter.pxd:89:68: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:49:45: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:50:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:51:48: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_criterion.pxd:52:57: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:72:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:91:51: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:94:59: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:95:63: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\neighbors\\_quad_tree.pxd:96:80: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:25:75: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:107:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:124:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:282:40: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  warning: sklearn\\tree\\_utils.pyx:296:71: The keyword 'nogil' should appear at the end of the function signature line. Placing it before 'except' or 'noexcept' will be disallowed in a future version of Cython.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:25:5: Exception check on 'safe_realloc' will always require the GIL to be acquired. Declare 'safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pxd:53:20: No exception value declared for 'rand_int' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\tree\\_utils.pxd:57:24: No exception value declared for 'rand_uniform' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\tree\\_utils.pxd:61:15: No exception value declared for 'log' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:115:20: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:138:24: Exception check after calling '__pyx_fuse_3safe_realloc' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_3safe_realloc' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Declare any exception value explicitly for functions in pxd files.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:280:32: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:305:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:306:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:309:47: Exception check after calling 'update_median_parameters_post_push' will always require the GIL to be acquired. Declare 'update_median_parameters_post_push' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:320:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:340:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:343:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:349:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:352:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:362:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:363:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:365:42: Exception check after calling 'remove' will always require the GIL to be acquired. Declare 'remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:366:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:377:20: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:378:45: Exception check after calling 'get_median' will always require the GIL to be acquired. Declare 'get_median' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:381:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:384:39: Exception check after calling 'pop' will always require the GIL to be acquired. Declare 'pop' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:385:49: Exception check after calling 'update_median_parameters_post_remove' will always require the GIL to be acquired. Declare 'update_median_parameters_post_remove' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:396:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:403:28: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:424:44: Exception check after calling 'size' will always require the GIL to be acquired. Declare 'size' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:427:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:434:69: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:437:68: Exception check after calling 'get_weight_from_index' will always require the GIL to be acquired. Declare 'get_weight_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:445:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:446:53: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\tree\\_utils.pyx:449:52: Exception check after calling 'get_value_from_index' will always require the GIL to be acquired. Declare 'get_value_from_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:20:5: Exception check on '_dot' will always require the GIL to be acquired. Declare '_dot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:33:5: Exception check on '_asum' will always require the GIL to be acquired. Declare '_asum' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:45:5: Exception check on '_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:58:5: Exception check on '_nrm2' will always require the GIL to be acquired. Declare '_nrm2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:70:5: Exception check on '_copy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_copy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_copy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:82:5: Exception check on '_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:94:5: Exception check on '_rotg' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_rotg' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rotg' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:107:5: Exception check on '_rot' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_rot' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_rot' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:124:5: Exception check on '_gemv' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_gemv' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemv' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:153:5: Exception check on '_ger' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_ger' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_ger' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_cython_blas.pyx:183:5: Exception check on '_gemm' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_gemm' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_gemm' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_heap.pxd:8:18: No exception value declared for 'heap_push' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  warning: sklearn\\utils\\_openmp_helpers.pyx:1:0: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\utils\\_openmp_helpers.pyx:44:4: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  warning: sklearn\\utils\\_openmp_helpers.pyx:68:4: The 'IF' statement is deprecated and will be removed in a future Cython version. Consider using runtime conditions or C macros instead. See https://github.com/cython/cython/issues/4310\n",
      "  performance hint: sklearn\\utils\\_openmp_helpers.pxd:6:27: No exception value declared for '_openmp_thread_num' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:77:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:78:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:114:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:115:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:402:53: Exception check after calling '_get_next_index' will always require the GIL to be acquired. Declare '_get_next_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:403:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:439:55: Exception check after calling '_get_random_index' will always require the GIL to be acquired. Declare '_get_random_index' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "  performance hint: sklearn\\utils\\_seq_dataset.pyx:440:20: Exception check after calling '_sample' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '_sample' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_sample' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:3:5: Exception check on 'dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pxd:5:26: No exception value declared for 'simultaneous_sort' in pxd file.\n",
      "  Users cimporting this function and calling it without the gil will always require an exception check.\n",
      "  Suggest adding an explicit exception value.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:53:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:56:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:58:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:60:25: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:68:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:70:21: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:72:25: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:81:25: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:83:17: Exception check after calling '__pyx_fuse_0dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:53:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:56:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:58:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:60:25: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:68:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:70:21: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:72:25: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:81:25: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_sorting.pyx:83:17: Exception check after calling '__pyx_fuse_1dual_swap' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1dual_swap' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1dual_swap' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:178:29: Exception check after calling 'reset_wscale' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'reset_wscale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'reset_wscale' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:183:17: Exception check after calling '__pyx_fuse_1_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:185:17: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:189:13: Exception check after calling '__pyx_fuse_1_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_1_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_1_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:351:29: Exception check after calling 'reset_wscale' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare 'reset_wscale' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on 'reset_wscale' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:356:17: Exception check after calling '__pyx_fuse_0_axpy' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_axpy' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_axpy' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:358:17: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "  performance hint: sklearn\\utils\\_weight_vector.pyx:362:13: Exception check after calling '__pyx_fuse_0_scal' will always require the GIL to be acquired.\n",
      "  Possible solutions:\n",
      "          1. Declare '__pyx_fuse_0_scal' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '__pyx_fuse_0_scal' to allow an error code to be returned.\n",
      "  Compiling sklearn\\__check_build\\_check_build.pyx because it changed.\n",
      "  Compiling sklearn\\preprocessing\\_csr_polynomial_expansion.pyx because it changed.\n",
      "  Compiling sklearn\\_loss\\_loss.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_dbscan_inner.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_hierarchical_fast.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_common.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_lloyd.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_elkan.pyx because it changed.\n",
      "  Compiling sklearn\\cluster\\_k_means_minibatch.pyx because it changed.\n",
      "  Compiling sklearn\\datasets\\_svmlight_format_fast.pyx because it changed.\n",
      "  Compiling sklearn\\decomposition\\_online_lda_fast.pyx because it changed.\n",
      "  Compiling sklearn\\decomposition\\_cdnmf_fast.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_gradient_boosting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx because it changed.\n",
      "  Compiling sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx because it changed.\n",
      "  Compiling sklearn\\feature_extraction\\_hashing_fast.pyx because it changed.\n",
      "  Compiling sklearn\\manifold\\_utils.pyx because it changed.\n",
      "  Compiling sklearn\\manifold\\_barnes_hut_tsne.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_fast.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_dist_metrics.pyx because it changed.\n",
      "  Compiling sklearn\\metrics\\_pairwise_distances_reduction.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_ball_tree.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_kd_tree.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_partition_nodes.pyx because it changed.\n",
      "  Compiling sklearn\\neighbors\\_quad_tree.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_tree.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_splitter.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_criterion.pyx because it changed.\n",
      "  Compiling sklearn\\tree\\_utils.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\sparsefuncs_fast.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_cython_blas.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\arrayfuncs.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\murmurhash.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_fast_dict.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_openmp_helpers.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_seq_dataset.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_weight_vector.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_random.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_logistic_sigmoid.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_readonly_array_wrapper.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_typedefs.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_heap.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_sorting.pyx because it changed.\n",
      "  Compiling sklearn\\utils\\_vector_sentinel.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_newrand.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_libsvm.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_liblinear.pyx because it changed.\n",
      "  Compiling sklearn\\svm\\_libsvm_sparse.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_cd_fast.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_sgd_fast.pyx because it changed.\n",
      "  Compiling sklearn\\linear_model\\_sag_fast.pyx because it changed.\n",
      "  Compiling sklearn\\_isotonic.pyx because it changed.\n",
      "  multiprocessing.pool.RemoteTraceback:\n",
      "  \"\"\"\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "      result = (True, func(*args, **kwds))\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 48, in mapstar\n",
      "      return list(map(*args))\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1345, in cythonize_one_helper\n",
      "      return cythonize_one(*m)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "      raise CompileError(None, pyx_file)\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  \"\"\"\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "  [ 1/59] Cythonizing sklearn\\__check_build\\_check_build.pyx\n",
      "  [ 2/59] Cythonizing sklearn\\_isotonic.pyx\n",
      "  [ 3/59] Cythonizing sklearn\\_loss\\_loss.pyx\n",
      "  [ 4/59] Cythonizing sklearn\\cluster\\_dbscan_inner.pyx\n",
      "  [ 5/59] Cythonizing sklearn\\cluster\\_hierarchical_fast.pyx\n",
      "  [ 6/59] Cythonizing sklearn\\cluster\\_k_means_common.pyx\n",
      "  [ 7/59] Cythonizing sklearn\\cluster\\_k_means_elkan.pyx\n",
      "  [ 8/59] Cythonizing sklearn\\cluster\\_k_means_lloyd.pyx\n",
      "  [ 9/59] Cythonizing sklearn\\cluster\\_k_means_minibatch.pyx\n",
      "  [10/59] Cythonizing sklearn\\datasets\\_svmlight_format_fast.pyx\n",
      "  [11/59] Cythonizing sklearn\\decomposition\\_cdnmf_fast.pyx\n",
      "  [12/59] Cythonizing sklearn\\decomposition\\_online_lda_fast.pyx\n",
      "  [13/59] Cythonizing sklearn\\ensemble\\_gradient_boosting.pyx\n",
      "  [14/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_binning.pyx\n",
      "  [15/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_bitset.pyx\n",
      "  [16/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_gradient_boosting.pyx\n",
      "  [17/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\_predictor.pyx\n",
      "  [18/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\common.pyx\n",
      "  [19/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\histogram.pyx\n",
      "  [20/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  [21/59] Cythonizing sklearn\\ensemble\\_hist_gradient_boosting\\utils.pyx\n",
      "  [22/59] Cythonizing sklearn\\feature_extraction\\_hashing_fast.pyx\n",
      "  [23/59] Cythonizing sklearn\\linear_model\\_cd_fast.pyx\n",
      "  [24/59] Cythonizing sklearn\\linear_model\\_sag_fast.pyx\n",
      "  [25/59] Cythonizing sklearn\\linear_model\\_sgd_fast.pyx\n",
      "  [26/59] Cythonizing sklearn\\manifold\\_barnes_hut_tsne.pyx\n",
      "  [27/59] Cythonizing sklearn\\manifold\\_utils.pyx\n",
      "  [28/59] Cythonizing sklearn\\metrics\\_dist_metrics.pyx\n",
      "  [29/59] Cythonizing sklearn\\metrics\\_pairwise_distances_reduction.pyx\n",
      "  [30/59] Cythonizing sklearn\\metrics\\_pairwise_fast.pyx\n",
      "  [31/59] Cythonizing sklearn\\metrics\\cluster\\_expected_mutual_info_fast.pyx\n",
      "  [32/59] Cythonizing sklearn\\neighbors\\_ball_tree.pyx\n",
      "  [33/59] Cythonizing sklearn\\neighbors\\_kd_tree.pyx\n",
      "  [34/59] Cythonizing sklearn\\neighbors\\_partition_nodes.pyx\n",
      "  [35/59] Cythonizing sklearn\\neighbors\\_quad_tree.pyx\n",
      "  [36/59] Cythonizing sklearn\\preprocessing\\_csr_polynomial_expansion.pyx\n",
      "  [37/59] Cythonizing sklearn\\svm\\_liblinear.pyx\n",
      "  [38/59] Cythonizing sklearn\\svm\\_libsvm.pyx\n",
      "  [39/59] Cythonizing sklearn\\svm\\_libsvm_sparse.pyx\n",
      "  [40/59] Cythonizing sklearn\\svm\\_newrand.pyx\n",
      "  [41/59] Cythonizing sklearn\\tree\\_criterion.pyx\n",
      "  [42/59] Cythonizing sklearn\\tree\\_splitter.pyx\n",
      "  [43/59] Cythonizing sklearn\\tree\\_tree.pyx\n",
      "  [44/59] Cythonizing sklearn\\tree\\_utils.pyx\n",
      "  [45/59] Cythonizing sklearn\\utils\\_cython_blas.pyx\n",
      "  [46/59] Cythonizing sklearn\\utils\\_fast_dict.pyx\n",
      "  [47/59] Cythonizing sklearn\\utils\\_heap.pyx\n",
      "  [48/59] Cythonizing sklearn\\utils\\_logistic_sigmoid.pyx\n",
      "  [49/59] Cythonizing sklearn\\utils\\_openmp_helpers.pyx\n",
      "  [50/59] Cythonizing sklearn\\utils\\_random.pyx\n",
      "  [51/59] Cythonizing sklearn\\utils\\_readonly_array_wrapper.pyx\n",
      "  [52/59] Cythonizing sklearn\\utils\\_seq_dataset.pyx\n",
      "  [53/59] Cythonizing sklearn\\utils\\_sorting.pyx\n",
      "  [54/59] Cythonizing sklearn\\utils\\_typedefs.pyx\n",
      "  [55/59] Cythonizing sklearn\\utils\\_vector_sentinel.pyx\n",
      "  [56/59] Cythonizing sklearn\\utils\\_weight_vector.pyx\n",
      "  [57/59] Cythonizing sklearn\\utils\\arrayfuncs.pyx\n",
      "  [58/59] Cythonizing sklearn\\utils\\murmurhash.pyx\n",
      "  [59/59] Cythonizing sklearn\\utils\\sparsefuncs_fast.pyx\n",
      "      main()\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 174, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 268, in run_setup\n",
      "      self).run_setup(setup_script=setup_script)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 158, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 328, in <module>\n",
      "      setup_package()\n",
      "    File \"setup.py\", line 324, in setup_package\n",
      "      setup(**metadata)\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 135, in setup\n",
      "      config = configuration()\n",
      "               ^^^^^^^^^^^^^^^\n",
      "    File \"setup.py\", line 187, in configuration\n",
      "      config.add_subpackage(\"sklearn\")\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1050, in add_subpackage\n",
      "      config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1016, in get_subpackage\n",
      "      config = self._get_configuration_from_setup_py(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 958, in _get_configuration_from_setup_py\n",
      "      config = setup_module.configuration(*args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-install-t_psc1nw\\scikit-learn_0bfdca1d0f944ee8a09ab3aa97ee1147\\sklearn\\setup.py\", line 85, in configuration\n",
      "      cythonize_extensions(top_path, config)\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-install-t_psc1nw\\scikit-learn_0bfdca1d0f944ee8a09ab3aa97ee1147\\sklearn\\_build_utils\\__init__.py\", line 74, in cythonize_extensions\n",
      "      config.ext_modules = cythonize(\n",
      "                           ^^^^^^^^^^\n",
      "    File \"C:\\Users\\Admin'\\AppData\\Local\\Temp\\pip-build-env-gdyv8rfw\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1145, in cythonize\n",
      "      result.get(99999)  # seconds\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\mzedg\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 774, in get\n",
      "      raise self._value\n",
      "  Cython.Compiler.Errors.CompileError: sklearn\\ensemble\\_hist_gradient_boosting\\splitting.pyx\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "!pip install scikit-learn==1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1699643388056,
     "user": {
      "displayName": "Иван Капранов",
      "userId": "03211624233193923671"
     },
     "user_tz": -180
    },
    "id": "_NqOKnrFY8xQ",
    "outputId": "65f66f78-415b-460b-b158-502f86390101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "add 5 :\n",
      "tensor([[ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.],\n",
      "        [17., 18., 19., 20.]])\n",
      "X*X^T  :\n",
      " tensor([[ 14.,  38.,  62.,  86.],\n",
      "        [ 38., 126., 214., 302.],\n",
      "        [ 62., 214., 366., 518.],\n",
      "        [ 86., 302., 518., 734.]])\n",
      "mean over cols :\n",
      " tensor([ 1.5000,  5.5000,  9.5000, 13.5000])\n",
      "cumsum of cols :\n",
      " tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  6.,  8., 10.],\n",
      "        [12., 15., 18., 21.],\n",
      "        [24., 28., 32., 36.]])\n"
     ]
    }
   ],
   "source": [
    "# pytorch world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "x = torch.from_numpy(x).type(torch.FloatTensor) #or torch.arange(0,16).view(4,4)\n",
    "\n",
    "print(\"X :\\n%s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", torch.matmul(x, x.transpose(1, 0)))\n",
    "print(\"mean over cols :\\n\", torch.mean(x, dim=-1))\n",
    "print(\"cumsum of cols :\\n\", torch.cumsum(x, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxJiOWdJY8xW"
   },
   "source": [
    "## NumPy vs Pytorch\n",
    "\n",
    "Numpy и Pytorch не требуют описания статического графа вычислений.\n",
    "\n",
    "Можно отлаживаться с помощью pdb или просто print.\n",
    "\n",
    "API несколько различается:\n",
    "\n",
    "```\n",
    "x.reshape([1,2,8]) -> x.view(1,2,8)\n",
    "x.sum(axis=-1) -> x.sum(dim=-1)\n",
    "x.astype('int64') -> x.type(torch.int64)\n",
    "```\n",
    "\n",
    "\n",
    "Легко конвертировать между собой:\n",
    "\n",
    "```\n",
    "torch.from_numpy(npx) -- вернет Tensor\n",
    "tt.numpy() -- вернет Numpy Array\n",
    "```\n",
    "\n",
    "Преобразовать тензор из одного числа в обычное питоновское число:\n",
    "```\n",
    "torch.tensor([1]).item() -> 1\n",
    "```\n",
    "\n",
    "\n",
    "Если что:\n",
    "- смотрите документацию https://pytorch.org/docs/\n",
    "- гуглите (Stackoverflow/tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAVLDMj_ou7t"
   },
   "source": [
    "Давайте кое что посчитаем\n",
    "\n",
    "$$ x(t) = t - 1.5 * cos( 15 t) $$\n",
    "$$ y(t) = t - 1.5 * sin( 16 t) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kWKDglA_Y8xX",
    "outputId": "35480c7e-a728-44ea-e75d-659ba2b7468a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f807028bd0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "t = torch.linspace(-10, 10, steps = 10000)\n",
    "x = t - 1.5 * torch.cos(15 * t)\n",
    "y = t - 1.5 * torch.sin(16 * t)\n",
    "\n",
    "# compute x(t) and y(t) as defined above\n",
    "\n",
    "plt.plot(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvBccGm8Y8xh"
   },
   "source": [
    "# Automatic gradients\n",
    "\n",
    "У каждого тензора в Pytorch есть флаг `requires_grad`, который отвечает за автоматическое вычисление градиентов:\n",
    "\n",
    "1. Создать переменную: `a = torch.tensor(..., requires_grad=True)`\n",
    "\n",
    "2. Определить какую-нибудь дифференцируемую функцию `loss = whatever(a)`\n",
    "\n",
    "3. Запросить обратный проход `loss.backward()`\n",
    "\n",
    "4. Градиенты будут доступны в `a.grads`\n",
    "\n",
    "\n",
    "Есть два важных отличия Pytorch от Theano/TF:\n",
    "\n",
    "1. Функцию ошибки можно изменять динамически, например на каждом минибатче.\n",
    "\n",
    "2. После вычисления `.backward()` градиенты сохраняются в `.grad` каждой задействованной переменной, при повторных вызовах градиенты суммируются. Это позволяет использовать несколько функций ошибок или виртуально увеличивать batch_size. Поэтому, после каждого шага оптимизатора градиенты стоит обнулять.\n",
    "\n",
    "\n",
    "\n",
    "## Leaf vs Non-leaf Variable:\n",
    "```\n",
    "x = torch.tensor([1., 2., 3., 4.], requires_grad=True))  # leaf tensor\n",
    "y = x + 1  # not a leaf variable\n",
    "```\n",
    "\n",
    "Градиенты будут сохранены и доступны для использования только для `leaf tensor`.\n",
    "Такое поведение по-умолчанию сделано ради экономии памяти. Все тензоры с флагом `requires_grad = False` считаются`leaf tensors` по умолчанию.\n",
    "\n",
    "\n",
    "Обратите внимание, что вычисление градиентов работает только для тензоров с вещественным типом данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UCMFdtG1kbKo"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# will not work\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "# will not work\n",
    "x = torch.tensor([1, 2, 3, 4], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zIjcCUJ1T1V"
   },
   "source": [
    "\n",
    "Чтобы выставить флаг `requires_grad=False` и выключить автоматическое вычисление градиентов для нескольких тензоров, можно использовать `with torch.no_grad()` или `detach`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1JQjCVpb1Uy1",
    "outputId": "8ce6a9bb-6c2a-4ea5-cd06-e24624163127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y = x**2\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.exp(x)\n",
    "    print(z.requires_grad)\n",
    "\n",
    "# detach from the graph\n",
    "w = torch.log(x).detach()\n",
    "print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NHwzSqakbUt"
   },
   "source": [
    "Рассмотрим пример линейной регрессии на датасете Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8sVwJ5DfY8xj",
    "outputId": "509e7fc0-d473-44c5-eacb-8c2a88d88d56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f80a70f4d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from sklearn.datasets import load_boston\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "x, y = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]]), raw_df.values[1::2, 2]\n",
    "#x, y = load_boston(return_X_y=True)\n",
    "\n",
    "#select one column for simplicity.\n",
    "x = x[:, -1] / x[:, -1].std()\n",
    "y = y / y.std()\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iqXtxfdjY8xr",
    "outputId": "8bc41158-8233-433f-dd1e-54fdea99d433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "True True\n",
      "True False\n",
      "True False\n"
     ]
    }
   ],
   "source": [
    "# model tensors\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# data tensors\n",
    "x = torch.from_numpy(x).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "# все тензоры являются leaf-tensors\n",
    "# x и y не требуют вычисления градиентов\n",
    "for vv in [w, b, x, y]:\n",
    "    print(vv.is_leaf, vv.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qSGyePQY8x-"
   },
   "source": [
    "# Линейная регрессия c помощью pytroch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "mj_-PaVzY8yA",
    "outputId": "9d2190bc-f394-47f8-c044-8e2053dc6787"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.4960967\n",
      "189 Done!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    #запишите формулу линейной регрессии с помощью w, x, b\n",
    "    y_pred = w * x + b\n",
    "\n",
    "    #посчитайте MSE с помощью torch.mean, y и переменной в которую вы записали результат строкой выше\n",
    "    loss = torch.mean(abs(y_pred - y)* 2)\n",
    "\n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # вот так руками можно применять градиенты\n",
    "    w.data -= 0.05 * w.grad.data\n",
    "    b.data -= 0.05 * b.grad.data\n",
    "\n",
    "    # обнуляем градиенты руками\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    # строим графики\n",
    "    if (i+1)%5==0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(x.data.numpy(), y.data.numpy())\n",
    "        plt.scatter(x.data.numpy(), y_pred.data.numpy(), color='orange', linewidth=5)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.data.numpy())\n",
    "        if loss.data.numpy() < 0.5:\n",
    "            print(i, \"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiEVpQBQY8yE"
   },
   "source": [
    "# Optimizers\n",
    "\n",
    "В этом примере мы пользовались простым правилом для градиентного спуска:\n",
    "  \n",
    "$$\\theta^{n+1} = \\theta^{n} - \\alpha \\nabla_{\\theta}L$$\n",
    "\n",
    "\n",
    "Единственным параметром в нем является $\\alpha$ -- это `learning_rate`.\n",
    "\n",
    "На практике часто используют различные модификации (например _Momentum_):\n",
    "\n",
    "$$\\theta^{n+1} = \\theta^{n} - U^{n}\\\\\n",
    "U^{n} = \\gamma U^{n-1} + \\alpha \\nabla_{\\theta}(L)\n",
    "$$\n",
    "\n",
    "Хороший обзор алгоритмов оптимизации для сетей можно посмотреть [тут](http://ruder.io/optimizing-gradient-descent/).\n",
    "\n",
    "\n",
    "\n",
    "Pytorch предоставляет практически все широкораспространненные оптимизаторы:    \n",
    "http://pytorch.org/docs/master/optim.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Оптимизаторы удобны в использовании:\n",
    "\n",
    "- требуется указать список переменных для оптимизации\n",
    "- `opt.step()` применяет `update` ($U^{n}$) к весам\n",
    "- `opt.zero_grad()` сбрасывает градиенты\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "crmZenu4Y8yF",
    "outputId": "ea27b544-cb19-47ba-d4f2-46520371d6b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.4912589490413666\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "#x, y = load_boston(return_X_y=True)\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "x, y = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]]), raw_df.values[1::2, 2]\n",
    "x = x[:, -1] / x[:, -1].std()\n",
    "y = y / y.std()\n",
    "\n",
    "# data tensors\n",
    "x = torch.from_numpy(x).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "# model tensors\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# define optimizer\n",
    "opt = torch.optim.RMSprop([w, b], lr=0.1)\n",
    "\n",
    "for i in range(100):\n",
    "    # посчитайте ошибку\n",
    "    y_pred = w * x + b\n",
    "    loss = torch.mean(abs(y_pred - y))\n",
    "    \n",
    "    # backprop and gradient descent но теперь не руками а с помощью оптимизатора и функци описанных выше\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    #the rest of code is just bells and whistles\n",
    "    if (i + 1) % 5 == 0:\n",
    "        #draw linear regression prediction vs data\n",
    "        clear_output(True)\n",
    "        plt.axhline(0, color='gray')\n",
    "        plt.axvline(0, color='gray')\n",
    "        plt.scatter(x.numpy(), y.numpy())\n",
    "        plt.plot(x.numpy(), y_pred.data.numpy(), color='orange')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.item())\n",
    "        if loss.item() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVyfwGuzou7x"
   },
   "source": [
    "# Немного более сложных тензоров (2 балла)\n",
    "\n",
    "$$\\rho(\\theta) = (1 + 0.9 \\cdot cos (8 \\cdot \\theta) ) \\cdot (1 + 0.1 \\cdot cos(24 \\cdot \\theta)) \\cdot (0.9 + 0.05 \\cdot cos(200 \\cdot \\theta)) \\cdot (1 + sin(\\theta))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BA1eG3Loou7x"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import cos\n",
    "from torch import sin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "theta = torch.linspace(- np.pi, np.pi, steps=1000)\n",
    "\n",
    "# compute rho(theta) as per formula above\n",
    "rho = (1 + 0.9 * cos(8 * theta)) * (1 + 0.1 * cos(24 * theta)) * (0.9 + 0.05 * cos(200 * theta)) * (1 + sin(theta))\n",
    "\n",
    "x = rho * torch.cos(theta)\n",
    "y = rho * torch.sin(theta)\n",
    "\n",
    "plt.figure(figsize=[6,6])\n",
    "plt.fill(x.numpy(), y.numpy(), color='green')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "8qoOsLGuY8yK",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Highlevel-API (5 баллов)\n",
    "\n",
    "При работе с нейронными сетями становится неудобно контролировать переменные с весами по-отдельности. Pytorch предоставляет высокоуровневый API для моделей http://pytorch.org/docs/master/nn.html#torch.nn.Module.\n",
    "\n",
    "\n",
    "Чтобы воспользоваться моделью необходимо отнаследоваться от torch.nn.Module, определить слои и описать `forward`, `backward` будет вычислен автоматически.\n",
    "\n",
    "\n",
    "Для демонстрации воспользуемся MNIST'ом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Obtaining dependency information for keras from https://files.pythonhosted.org/packages/c2/88/eef50051a772dcb4433d1f3e4c1d6576ba450fe83e89d028d7e8b85a2122/keras-3.6.0-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from keras) (1.24.3)\n",
      "Collecting rich (from keras)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/67/91/5474b84e505a6ccc295b2d322d90ff6aa0746745717839ee0c5fb4fdcceb/rich-13.9.2-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/73/59/7854fbfb59f8ae35483ce93493708be5942ebb6328cd85b3a609df629736/namex-0.0.8-py3-none-any.whl.metadata\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Requirement already satisfied: h5py in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from keras) (3.9.0)\n",
      "Collecting optree (from keras)\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/89/d5/a999b5e995afb98676cc5671b91b4b160e87980fb3a852d1370507614ca1/optree-0.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading optree-0.13.0-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.7 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 10.2/48.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 48.7/48.7 kB 818.8 kB/s eta 0:00:00\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Obtaining dependency information for ml-dtypes from https://files.pythonhosted.org/packages/bf/31/058b9bcf9a81abd51623985add78711a915e4b0f6045baa5f9a0b41eb039/ml_dtypes-0.5.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading ml_dtypes-0.5.0-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.2 MB 1.9 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.2 MB 825.8 kB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.1/1.2 MB 939.4 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.1/1.2 MB 853.3 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.2 MB 841.6 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.2/1.2 MB 942.1 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.2 MB 853.3 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 952.6 kB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.4/1.2 MB 933.2 kB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.5/1.2 MB 938.8 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.5/1.2 MB 983.0 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.6/1.2 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.2 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.7/1.2 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.8/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.9/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.0/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.1/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.1/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 41.0/133.7 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 41.0/133.7 kB 2.0 MB/s eta 0:00:01\n",
      "   ----------------- --------------------- 61.4/133.7 kB 469.7 kB/s eta 0:00:01\n",
      "   ----------------------- --------------- 81.9/133.7 kB 416.7 kB/s eta 0:00:01\n",
      "   -------------------------- ------------ 92.2/133.7 kB 438.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- 133.7/133.7 kB 527.6 kB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.0-cp311-cp311-win_amd64.whl (211 kB)\n",
      "   ---------------------------------------- 0.0/211.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/211.9 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 41.0/211.9 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 102.4/211.9 kB 845.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 184.3/211.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 211.9/211.9 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp311-cp311-win_amd64.whl (283 kB)\n",
      "   ---------------------------------------- 0.0/283.7 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/283.7 kB 960.0 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/283.7 kB 812.7 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/283.7 kB 812.7 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/283.7 kB 812.7 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/283.7 kB 812.7 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/283.7 kB 812.7 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/283.7 kB 812.7 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/283.7 kB 812.7 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 61.4/283.7 kB 812.7 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 81.9/283.7 kB 169.9 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 81.9/283.7 kB 169.9 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 81.9/283.7 kB 169.9 kB/s eta 0:00:02\n",
      "   -------------------- ----------------- 153.6/283.7 kB 241.3 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 225.3/283.7 kB 344.1 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 235.5/283.7 kB 342.9 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 256.0/283.7 kB 349.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 283.7/283.7 kB 357.1 kB/s eta 0:00:00\n",
      "Downloading rich-13.9.2-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.1 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 61.4/242.1 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 122.9/242.1 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 194.6/242.1 kB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 235.5/242.1 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 242.1/242.1 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: namex, optree, ml-dtypes, absl-py, rich, keras\n",
      "Successfully installed absl-py-2.1.0 keras-3.6.0 ml-dtypes-0.5.0 namex-0.0.8 optree-0.13.0 rich-13.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/ed/b6/62345568cd07de5d9254fcf64d7e44aacbb6abde11ea953b3cb320e58d19/tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.17.0 from https://files.pythonhosted.org/packages/66/03/5c447feceb72f5a38ac2aa79d306fa5b5772f982c2b480c1329c7e382900/tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=24.3.25 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/a3/61/8001b38461d751cd1a0c3a6ae84346796a5758123f3ed97a1b121dfbf4f3/gast-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for h5py>=3.10.0 from https://files.pythonhosted.org/packages/1d/4d/cbd3014eb78d1e449b29beba1f3293a841aa8086c6f7968c383c2c7ff076/h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/0b/2d/3f480b1e1d31eb3d6de5e3ef641954e5c67430d5ac93b7fa7e07589576c7/libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes<0.5.0,>=0.3.1 from https://files.pythonhosted.org/packages/e8/d3/ddfd9878b223b3aa9a930c6100a99afca5cfab7ea703662e00323acb7568/ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/23/cd/066e86230ae37ed0be70aae89aabf03ca8d9f39c8aea0dec8029455b5540/opt_einsum-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/a7/ad/bf3f358e90b7e70bf7fb520702cb15307ef268262292d3bdb16ad8ebc815/protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (66.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/f8/22/cf3e6ef61c62e631d5567810432a826a3f5752f132d6c3352f6cfbedbedb/grpcio-1.66.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.66.2-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.18,>=2.17 from https://files.pythonhosted.org/packages/d4/41/dccba8c5f955bc35b6110ff78574e4e5c8226ad62f08e732096c3861309b/tensorboard-2.17.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.6.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/ac/4e/9566a313927be582ca99455a9523a097c7888fc819695bdc08415432b202/tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.9.2)\n",
      "Requirement already satisfied: namex in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mzedg\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
      "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/385.0 MB 653.6 kB/s eta 0:09:50\n",
      "   ---------------------------------------- 0.1/385.0 MB 1.5 MB/s eta 0:04:24\n",
      "   ---------------------------------------- 0.2/385.0 MB 1.4 MB/s eta 0:04:37\n",
      "   ---------------------------------------- 0.3/385.0 MB 1.5 MB/s eta 0:04:19\n",
      "   ---------------------------------------- 0.3/385.0 MB 1.5 MB/s eta 0:04:19\n",
      "   ---------------------------------------- 0.3/385.0 MB 1.2 MB/s eta 0:05:13\n",
      "   ---------------------------------------- 0.4/385.0 MB 1.2 MB/s eta 0:05:10\n",
      "   ---------------------------------------- 0.5/385.0 MB 1.4 MB/s eta 0:04:42\n",
      "   ---------------------------------------- 0.6/385.0 MB 1.5 MB/s eta 0:04:19\n",
      "   ---------------------------------------- 0.7/385.0 MB 1.5 MB/s eta 0:04:13\n",
      "   ---------------------------------------- 0.8/385.0 MB 1.6 MB/s eta 0:04:07\n",
      "   ---------------------------------------- 0.9/385.0 MB 1.6 MB/s eta 0:03:59\n",
      "   ---------------------------------------- 1.0/385.0 MB 1.7 MB/s eta 0:03:53\n",
      "   ---------------------------------------- 1.1/385.0 MB 1.7 MB/s eta 0:03:44\n",
      "   ---------------------------------------- 1.3/385.0 MB 1.8 MB/s eta 0:03:32\n",
      "   ---------------------------------------- 1.4/385.0 MB 1.9 MB/s eta 0:03:26\n",
      "   ---------------------------------------- 1.5/385.0 MB 1.9 MB/s eta 0:03:25\n",
      "   ---------------------------------------- 1.6/385.0 MB 1.9 MB/s eta 0:03:18\n",
      "   ---------------------------------------- 1.8/385.0 MB 2.0 MB/s eta 0:03:08\n",
      "   ---------------------------------------- 1.9/385.0 MB 2.1 MB/s eta 0:03:03\n",
      "   ---------------------------------------- 2.1/385.0 MB 2.1 MB/s eta 0:03:00\n",
      "   ---------------------------------------- 2.2/385.0 MB 2.2 MB/s eta 0:02:58\n",
      "   ---------------------------------------- 2.3/385.0 MB 2.2 MB/s eta 0:02:54\n",
      "   ---------------------------------------- 2.5/385.0 MB 2.3 MB/s eta 0:02:50\n",
      "   ---------------------------------------- 2.8/385.0 MB 2.4 MB/s eta 0:02:43\n",
      "   ---------------------------------------- 2.9/385.0 MB 2.4 MB/s eta 0:02:41\n",
      "   ---------------------------------------- 3.1/385.0 MB 2.5 MB/s eta 0:02:35\n",
      "   ---------------------------------------- 3.3/385.0 MB 2.6 MB/s eta 0:02:30\n",
      "   ---------------------------------------- 3.6/385.0 MB 2.6 MB/s eta 0:02:25\n",
      "   ---------------------------------------- 3.6/385.0 MB 2.6 MB/s eta 0:02:27\n",
      "   ---------------------------------------- 3.7/385.0 MB 2.6 MB/s eta 0:02:27\n",
      "   ---------------------------------------- 4.0/385.0 MB 2.7 MB/s eta 0:02:23\n",
      "   ---------------------------------------- 4.1/385.0 MB 2.7 MB/s eta 0:02:23\n",
      "   ---------------------------------------- 4.3/385.0 MB 2.7 MB/s eta 0:02:21\n",
      "   ---------------------------------------- 4.4/385.0 MB 2.7 MB/s eta 0:02:22\n",
      "   ---------------------------------------- 4.5/385.0 MB 2.7 MB/s eta 0:02:21\n",
      "   ---------------------------------------- 4.7/385.0 MB 2.7 MB/s eta 0:02:19\n",
      "    --------------------------------------- 4.9/385.0 MB 2.8 MB/s eta 0:02:17\n",
      "    --------------------------------------- 5.1/385.0 MB 2.8 MB/s eta 0:02:15\n",
      "    --------------------------------------- 5.3/385.0 MB 2.9 MB/s eta 0:02:13\n",
      "    --------------------------------------- 5.5/385.0 MB 2.9 MB/s eta 0:02:11\n",
      "    --------------------------------------- 5.7/385.0 MB 2.9 MB/s eta 0:02:10\n",
      "    --------------------------------------- 5.9/385.0 MB 2.9 MB/s eta 0:02:09\n",
      "    --------------------------------------- 6.1/385.0 MB 3.0 MB/s eta 0:02:08\n",
      "    --------------------------------------- 6.2/385.0 MB 3.0 MB/s eta 0:02:08\n",
      "    --------------------------------------- 6.4/385.0 MB 3.0 MB/s eta 0:02:07\n",
      "    --------------------------------------- 6.6/385.0 MB 3.0 MB/s eta 0:02:06\n",
      "    --------------------------------------- 6.8/385.0 MB 3.0 MB/s eta 0:02:05\n",
      "    --------------------------------------- 7.0/385.0 MB 3.0 MB/s eta 0:02:05\n",
      "    --------------------------------------- 7.2/385.0 MB 3.1 MB/s eta 0:02:03\n",
      "    --------------------------------------- 7.3/385.0 MB 3.1 MB/s eta 0:02:03\n",
      "    --------------------------------------- 7.5/385.0 MB 3.1 MB/s eta 0:02:02\n",
      "    --------------------------------------- 7.7/385.0 MB 3.1 MB/s eta 0:02:02\n",
      "    --------------------------------------- 7.9/385.0 MB 3.1 MB/s eta 0:02:01\n",
      "    --------------------------------------- 8.1/385.0 MB 3.1 MB/s eta 0:02:00\n",
      "    --------------------------------------- 8.3/385.0 MB 3.2 MB/s eta 0:01:59\n",
      "    --------------------------------------- 8.5/385.0 MB 3.2 MB/s eta 0:01:58\n",
      "    --------------------------------------- 8.7/385.0 MB 3.2 MB/s eta 0:01:58\n",
      "    --------------------------------------- 8.9/385.0 MB 3.2 MB/s eta 0:01:57\n",
      "    --------------------------------------- 9.1/385.0 MB 3.3 MB/s eta 0:01:56\n",
      "    --------------------------------------- 9.3/385.0 MB 3.3 MB/s eta 0:01:55\n",
      "    --------------------------------------- 9.6/385.0 MB 3.3 MB/s eta 0:01:54\n",
      "   - -------------------------------------- 9.8/385.0 MB 3.3 MB/s eta 0:01:54\n",
      "   - -------------------------------------- 10.0/385.0 MB 3.3 MB/s eta 0:01:53\n",
      "   - -------------------------------------- 10.3/385.0 MB 3.4 MB/s eta 0:01:52\n",
      "   - -------------------------------------- 10.5/385.0 MB 3.5 MB/s eta 0:01:47\n",
      "   - -------------------------------------- 10.6/385.0 MB 3.6 MB/s eta 0:01:44\n",
      "   - -------------------------------------- 10.9/385.0 MB 3.7 MB/s eta 0:01:42\n",
      "   - -------------------------------------- 11.0/385.0 MB 3.8 MB/s eta 0:01:40\n",
      "   - -------------------------------------- 11.1/385.0 MB 3.8 MB/s eta 0:01:39\n",
      "   - -------------------------------------- 11.4/385.0 MB 3.9 MB/s eta 0:01:38\n",
      "   - -------------------------------------- 11.6/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 11.7/385.0 MB 3.9 MB/s eta 0:01:36\n",
      "   - -------------------------------------- 11.8/385.0 MB 3.9 MB/s eta 0:01:36\n",
      "   - -------------------------------------- 12.0/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 12.2/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 12.3/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 12.4/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 12.5/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 12.7/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 12.9/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 13.1/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 13.2/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 13.4/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 13.6/385.0 MB 3.8 MB/s eta 0:01:38\n",
      "   - -------------------------------------- 13.8/385.0 MB 3.8 MB/s eta 0:01:38\n",
      "   - -------------------------------------- 13.9/385.0 MB 3.9 MB/s eta 0:01:36\n",
      "   - -------------------------------------- 14.1/385.0 MB 3.8 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 14.3/385.0 MB 3.8 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 14.4/385.0 MB 3.9 MB/s eta 0:01:36\n",
      "   - -------------------------------------- 14.7/385.0 MB 3.9 MB/s eta 0:01:36\n",
      "   - -------------------------------------- 14.8/385.0 MB 3.9 MB/s eta 0:01:36\n",
      "   - -------------------------------------- 15.0/385.0 MB 3.9 MB/s eta 0:01:36\n",
      "   - -------------------------------------- 15.1/385.0 MB 3.9 MB/s eta 0:01:36\n",
      "   - -------------------------------------- 15.2/385.0 MB 3.9 MB/s eta 0:01:37\n",
      "   - -------------------------------------- 15.3/385.0 MB 3.8 MB/s eta 0:01:38\n",
      "   - -------------------------------------- 15.4/385.0 MB 3.8 MB/s eta 0:01:39\n",
      "   - -------------------------------------- 15.5/385.0 MB 3.7 MB/s eta 0:01:40\n",
      "   - -------------------------------------- 15.7/385.0 MB 3.7 MB/s eta 0:01:41\n",
      "   - -------------------------------------- 15.8/385.0 MB 3.7 MB/s eta 0:01:41\n",
      "   - -------------------------------------- 15.9/385.0 MB 3.7 MB/s eta 0:01:41\n",
      "   - -------------------------------------- 16.1/385.0 MB 3.7 MB/s eta 0:01:41\n",
      "   - -------------------------------------- 16.2/385.0 MB 3.6 MB/s eta 0:01:42\n",
      "   - -------------------------------------- 16.3/385.0 MB 3.6 MB/s eta 0:01:42\n",
      "   - -------------------------------------- 16.4/385.0 MB 3.6 MB/s eta 0:01:44\n",
      "   - -------------------------------------- 16.5/385.0 MB 3.6 MB/s eta 0:01:44\n",
      "   - -------------------------------------- 16.7/385.0 MB 3.6 MB/s eta 0:01:44\n",
      "   - -------------------------------------- 16.8/385.0 MB 3.5 MB/s eta 0:01:45\n",
      "   - -------------------------------------- 16.9/385.0 MB 3.5 MB/s eta 0:01:46\n",
      "   - -------------------------------------- 17.0/385.0 MB 3.5 MB/s eta 0:01:47\n",
      "   - -------------------------------------- 17.1/385.0 MB 3.5 MB/s eta 0:01:47\n",
      "   - -------------------------------------- 17.3/385.0 MB 3.5 MB/s eta 0:01:47\n",
      "   - -------------------------------------- 17.4/385.0 MB 3.5 MB/s eta 0:01:47\n",
      "   - -------------------------------------- 17.5/385.0 MB 3.4 MB/s eta 0:01:48\n",
      "   - -------------------------------------- 17.7/385.0 MB 3.4 MB/s eta 0:01:48\n",
      "   - -------------------------------------- 17.8/385.0 MB 3.4 MB/s eta 0:01:48\n",
      "   - -------------------------------------- 18.0/385.0 MB 3.4 MB/s eta 0:01:49\n",
      "   - -------------------------------------- 18.1/385.0 MB 3.4 MB/s eta 0:01:49\n",
      "   - -------------------------------------- 18.3/385.0 MB 3.4 MB/s eta 0:01:49\n",
      "   - -------------------------------------- 18.4/385.0 MB 3.4 MB/s eta 0:01:50\n",
      "   - -------------------------------------- 18.6/385.0 MB 3.3 MB/s eta 0:01:50\n",
      "   - -------------------------------------- 18.7/385.0 MB 3.3 MB/s eta 0:01:51\n",
      "   - -------------------------------------- 18.8/385.0 MB 3.3 MB/s eta 0:01:52\n",
      "   - -------------------------------------- 18.9/385.0 MB 3.3 MB/s eta 0:01:52\n",
      "   - -------------------------------------- 19.0/385.0 MB 3.2 MB/s eta 0:01:53\n",
      "   - -------------------------------------- 19.1/385.0 MB 3.2 MB/s eta 0:01:55\n",
      "   - -------------------------------------- 19.1/385.0 MB 3.2 MB/s eta 0:01:55\n",
      "   -- ------------------------------------- 19.3/385.0 MB 3.2 MB/s eta 0:01:56\n",
      "   -- ------------------------------------- 19.5/385.0 MB 3.1 MB/s eta 0:01:57\n",
      "   -- ------------------------------------- 19.6/385.0 MB 3.1 MB/s eta 0:01:57\n",
      "   -- ------------------------------------- 19.7/385.0 MB 3.1 MB/s eta 0:01:58\n",
      "   -- ------------------------------------- 19.9/385.0 MB 3.1 MB/s eta 0:01:58\n",
      "   -- ------------------------------------- 20.1/385.0 MB 3.1 MB/s eta 0:01:58\n",
      "   -- ------------------------------------- 20.2/385.0 MB 3.1 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 20.3/385.0 MB 3.1 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 20.5/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 20.6/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 20.8/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 20.9/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 21.1/385.0 MB 3.0 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 21.2/385.0 MB 3.0 MB/s eta 0:02:03\n",
      "   -- ------------------------------------- 21.4/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 21.5/385.0 MB 3.0 MB/s eta 0:02:03\n",
      "   -- ------------------------------------- 21.7/385.0 MB 3.0 MB/s eta 0:02:03\n",
      "   -- ------------------------------------- 21.9/385.0 MB 3.0 MB/s eta 0:02:03\n",
      "   -- ------------------------------------- 22.1/385.0 MB 3.0 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 22.2/385.0 MB 3.0 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 22.4/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 22.5/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 22.7/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 22.9/385.0 MB 3.0 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 23.1/385.0 MB 3.0 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 23.2/385.0 MB 3.0 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 23.4/385.0 MB 3.1 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 23.6/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 23.8/385.0 MB 3.0 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 23.9/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 24.1/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 24.3/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 24.3/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 24.4/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 24.5/385.0 MB 3.0 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 24.7/385.0 MB 3.0 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 24.9/385.0 MB 3.0 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 25.1/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 25.2/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 25.3/385.0 MB 3.0 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 25.5/385.0 MB 3.0 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 25.6/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 25.7/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 25.9/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 26.0/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 26.1/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 26.3/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 26.4/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 26.5/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 26.7/385.0 MB 3.0 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 26.8/385.0 MB 3.0 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 26.9/385.0 MB 3.0 MB/s eta 0:01:59\n",
      "   -- ------------------------------------- 27.0/385.0 MB 3.0 MB/s eta 0:02:00\n",
      "   -- ------------------------------------- 27.0/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 27.1/385.0 MB 3.0 MB/s eta 0:02:01\n",
      "   -- ------------------------------------- 27.2/385.0 MB 2.9 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 27.3/385.0 MB 2.9 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 27.4/385.0 MB 2.9 MB/s eta 0:02:02\n",
      "   -- ------------------------------------- 27.5/385.0 MB 2.9 MB/s eta 0:02:03\n",
      "   -- ------------------------------------- 27.6/385.0 MB 2.9 MB/s eta 0:02:04\n",
      "   -- ------------------------------------- 27.7/385.0 MB 2.9 MB/s eta 0:02:04\n",
      "   -- ------------------------------------- 27.8/385.0 MB 2.9 MB/s eta 0:02:04\n",
      "   -- ------------------------------------- 27.9/385.0 MB 2.9 MB/s eta 0:02:05\n",
      "   -- ------------------------------------- 27.9/385.0 MB 2.9 MB/s eta 0:02:05\n",
      "   -- ------------------------------------- 28.1/385.0 MB 2.8 MB/s eta 0:02:06\n",
      "   -- ------------------------------------- 28.1/385.0 MB 2.8 MB/s eta 0:02:07\n",
      "   -- ------------------------------------- 28.3/385.0 MB 2.8 MB/s eta 0:02:07\n",
      "   -- ------------------------------------- 28.3/385.0 MB 2.8 MB/s eta 0:02:08\n",
      "   -- ------------------------------------- 28.4/385.0 MB 2.8 MB/s eta 0:02:08\n",
      "   -- ------------------------------------- 28.6/385.0 MB 2.8 MB/s eta 0:02:08\n",
      "   -- ------------------------------------- 28.6/385.0 MB 2.8 MB/s eta 0:02:10\n",
      "   -- ------------------------------------- 28.8/385.0 MB 2.8 MB/s eta 0:02:09\n",
      "   -- ------------------------------------- 28.9/385.0 MB 2.8 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 29.0/385.0 MB 2.8 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 29.0/385.0 MB 2.7 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 29.1/385.0 MB 2.7 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 29.2/385.0 MB 2.8 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 29.3/385.0 MB 2.7 MB/s eta 0:02:10\n",
      "   --- ------------------------------------ 29.3/385.0 MB 2.7 MB/s eta 0:02:11\n",
      "   --- ------------------------------------ 29.5/385.0 MB 2.7 MB/s eta 0:02:11\n",
      "   --- ------------------------------------ 29.6/385.0 MB 2.7 MB/s eta 0:02:11\n",
      "   --- ------------------------------------ 29.6/385.0 MB 2.7 MB/s eta 0:02:12\n",
      "   --- ------------------------------------ 29.7/385.0 MB 2.7 MB/s eta 0:02:12\n",
      "   --- ------------------------------------ 29.8/385.0 MB 2.7 MB/s eta 0:02:13\n",
      "   --- ------------------------------------ 30.0/385.0 MB 2.7 MB/s eta 0:02:13\n",
      "   --- ------------------------------------ 30.0/385.0 MB 2.7 MB/s eta 0:02:14\n",
      "   --- ------------------------------------ 30.1/385.0 MB 2.6 MB/s eta 0:02:15\n",
      "   --- ------------------------------------ 30.2/385.0 MB 2.6 MB/s eta 0:02:15\n",
      "   --- ------------------------------------ 30.4/385.0 MB 2.6 MB/s eta 0:02:15\n",
      "   --- ------------------------------------ 30.4/385.0 MB 2.6 MB/s eta 0:02:16\n",
      "   --- ------------------------------------ 30.6/385.0 MB 2.6 MB/s eta 0:02:17\n",
      "   --- ------------------------------------ 30.6/385.0 MB 2.6 MB/s eta 0:02:17\n",
      "   --- ------------------------------------ 30.8/385.0 MB 2.6 MB/s eta 0:02:17\n",
      "   --- ------------------------------------ 30.9/385.0 MB 2.6 MB/s eta 0:02:18\n",
      "   --- ------------------------------------ 31.0/385.0 MB 2.6 MB/s eta 0:02:18\n",
      "   --- ------------------------------------ 31.1/385.0 MB 2.6 MB/s eta 0:02:19\n",
      "   --- ------------------------------------ 31.2/385.0 MB 2.5 MB/s eta 0:02:19\n",
      "   --- ------------------------------------ 31.3/385.0 MB 2.5 MB/s eta 0:02:20\n",
      "   --- ------------------------------------ 31.4/385.0 MB 2.5 MB/s eta 0:02:20\n",
      "   --- ------------------------------------ 31.6/385.0 MB 2.5 MB/s eta 0:02:20\n",
      "   --- ------------------------------------ 31.7/385.0 MB 2.5 MB/s eta 0:02:20\n",
      "   --- ------------------------------------ 31.8/385.0 MB 2.5 MB/s eta 0:02:21\n",
      "   --- ------------------------------------ 32.0/385.0 MB 2.5 MB/s eta 0:02:21\n",
      "   --- ------------------------------------ 32.0/385.0 MB 2.5 MB/s eta 0:02:21\n",
      "   --- ------------------------------------ 32.1/385.0 MB 2.5 MB/s eta 0:02:23\n",
      "   --- ------------------------------------ 32.3/385.0 MB 2.5 MB/s eta 0:02:23\n",
      "   --- ------------------------------------ 32.4/385.0 MB 2.5 MB/s eta 0:02:23\n",
      "   --- ------------------------------------ 32.5/385.0 MB 2.5 MB/s eta 0:02:23\n",
      "   --- ------------------------------------ 32.7/385.0 MB 2.5 MB/s eta 0:02:24\n",
      "   --- ------------------------------------ 32.8/385.0 MB 2.5 MB/s eta 0:02:24\n",
      "   --- ------------------------------------ 32.9/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 33.0/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 33.2/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 33.4/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 33.5/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 33.7/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 33.8/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 33.9/385.0 MB 2.4 MB/s eta 0:02:26\n",
      "   --- ------------------------------------ 34.1/385.0 MB 2.4 MB/s eta 0:02:26\n",
      "   --- ------------------------------------ 34.2/385.0 MB 2.4 MB/s eta 0:02:26\n",
      "   --- ------------------------------------ 34.3/385.0 MB 2.4 MB/s eta 0:02:26\n",
      "   --- ------------------------------------ 34.5/385.0 MB 2.4 MB/s eta 0:02:24\n",
      "   --- ------------------------------------ 34.6/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 34.8/385.0 MB 2.4 MB/s eta 0:02:24\n",
      "   --- ------------------------------------ 34.9/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 35.1/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 35.2/385.0 MB 2.4 MB/s eta 0:02:26\n",
      "   --- ------------------------------------ 35.3/385.0 MB 2.4 MB/s eta 0:02:26\n",
      "   --- ------------------------------------ 35.5/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 35.6/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 35.7/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 35.9/385.0 MB 2.4 MB/s eta 0:02:24\n",
      "   --- ------------------------------------ 36.0/385.0 MB 2.4 MB/s eta 0:02:25\n",
      "   --- ------------------------------------ 36.2/385.0 MB 2.4 MB/s eta 0:02:24\n",
      "   --- ------------------------------------ 36.3/385.0 MB 2.4 MB/s eta 0:02:24\n",
      "   --- ------------------------------------ 36.5/385.0 MB 2.4 MB/s eta 0:02:24\n",
      "   --- ------------------------------------ 36.7/385.0 MB 2.5 MB/s eta 0:02:23\n",
      "   --- ------------------------------------ 36.8/385.0 MB 2.5 MB/s eta 0:02:23\n",
      "   --- ------------------------------------ 36.9/385.0 MB 2.4 MB/s eta 0:02:23\n",
      "   --- ------------------------------------ 37.0/385.0 MB 2.4 MB/s eta 0:02:23\n",
      "   --- ------------------------------------ 37.2/385.0 MB 2.5 MB/s eta 0:02:19\n",
      "   --- ------------------------------------ 37.4/385.0 MB 2.5 MB/s eta 0:02:19\n",
      "   --- ------------------------------------ 37.5/385.0 MB 2.5 MB/s eta 0:02:18\n",
      "   --- ------------------------------------ 37.5/385.0 MB 2.5 MB/s eta 0:02:18\n",
      "   --- ------------------------------------ 37.6/385.0 MB 2.5 MB/s eta 0:02:20\n",
      "   --- ------------------------------------ 37.7/385.0 MB 2.5 MB/s eta 0:02:19\n",
      "   --- ------------------------------------ 37.9/385.0 MB 2.5 MB/s eta 0:02:18\n",
      "   --- ------------------------------------ 38.0/385.0 MB 2.5 MB/s eta 0:02:18\n",
      "   --- ------------------------------------ 38.2/385.0 MB 2.5 MB/s eta 0:02:17\n",
      "   --- ------------------------------------ 38.3/385.0 MB 2.6 MB/s eta 0:02:16\n",
      "   --- ------------------------------------ 38.5/385.0 MB 2.6 MB/s eta 0:02:16\n",
      "   ---- ----------------------------------- 38.6/385.0 MB 2.6 MB/s eta 0:02:14\n",
      "   ---- ----------------------------------- 38.7/385.0 MB 2.6 MB/s eta 0:02:14\n",
      "   ---- ----------------------------------- 38.9/385.0 MB 2.6 MB/s eta 0:02:12\n",
      "   ---- ----------------------------------- 39.0/385.0 MB 2.7 MB/s eta 0:02:11\n",
      "   ---- ----------------------------------- 39.2/385.0 MB 2.7 MB/s eta 0:02:11\n",
      "   ---- ----------------------------------- 39.4/385.0 MB 2.7 MB/s eta 0:02:09\n",
      "   ---- ----------------------------------- 39.5/385.0 MB 2.7 MB/s eta 0:02:08\n",
      "   ---- ----------------------------------- 39.7/385.0 MB 2.7 MB/s eta 0:02:07\n",
      "   ---- ----------------------------------- 39.9/385.0 MB 2.8 MB/s eta 0:02:04\n",
      "   ---- ----------------------------------- 40.0/385.0 MB 2.8 MB/s eta 0:02:03\n",
      "   ---- ----------------------------------- 40.2/385.0 MB 2.8 MB/s eta 0:02:03\n",
      "   ---- ----------------------------------- 40.4/385.0 MB 2.9 MB/s eta 0:02:01\n",
      "   ---- ----------------------------------- 40.5/385.0 MB 2.9 MB/s eta 0:02:00\n",
      "   ---- ----------------------------------- 40.7/385.0 MB 2.9 MB/s eta 0:01:59\n",
      "   ---- ----------------------------------- 40.8/385.0 MB 2.9 MB/s eta 0:01:58\n",
      "   ---- ----------------------------------- 41.1/385.0 MB 3.0 MB/s eta 0:01:56\n",
      "   ---- ----------------------------------- 41.2/385.0 MB 3.0 MB/s eta 0:01:56\n",
      "   ---- ----------------------------------- 41.3/385.0 MB 3.0 MB/s eta 0:01:56\n",
      "   ---- ----------------------------------- 41.5/385.0 MB 3.0 MB/s eta 0:01:54\n",
      "   ---- ----------------------------------- 41.6/385.0 MB 3.0 MB/s eta 0:01:54\n",
      "   ---- ----------------------------------- 41.9/385.0 MB 3.1 MB/s eta 0:01:53\n",
      "   ---- ----------------------------------- 42.0/385.0 MB 3.1 MB/s eta 0:01:52\n",
      "   ---- ----------------------------------- 42.2/385.0 MB 3.1 MB/s eta 0:01:50\n",
      "   ---- ----------------------------------- 42.4/385.0 MB 3.1 MB/s eta 0:01:49\n",
      "   ---- ----------------------------------- 42.6/385.0 MB 3.1 MB/s eta 0:01:49\n",
      "   ---- ----------------------------------- 42.8/385.0 MB 3.2 MB/s eta 0:01:48\n",
      "   ---- ----------------------------------- 42.9/385.0 MB 3.2 MB/s eta 0:01:48\n",
      "   ---- ----------------------------------- 43.1/385.0 MB 3.2 MB/s eta 0:01:47\n",
      "   ---- ----------------------------------- 43.3/385.0 MB 3.2 MB/s eta 0:01:46\n",
      "   ---- ----------------------------------- 43.4/385.0 MB 3.2 MB/s eta 0:01:46\n",
      "   ---- ----------------------------------- 43.6/385.0 MB 3.2 MB/s eta 0:01:46\n",
      "   ---- ----------------------------------- 43.8/385.0 MB 3.2 MB/s eta 0:01:46\n",
      "   ---- ----------------------------------- 44.0/385.0 MB 3.3 MB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 44.2/385.0 MB 3.3 MB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 44.3/385.0 MB 3.3 MB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 44.5/385.0 MB 3.3 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 44.7/385.0 MB 3.3 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 44.9/385.0 MB 3.4 MB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 45.1/385.0 MB 3.4 MB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 45.4/385.0 MB 3.4 MB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 45.6/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 45.8/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ---- ----------------------------------- 45.9/385.0 MB 3.5 MB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 46.1/385.0 MB 3.5 MB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 46.3/385.0 MB 3.5 MB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 46.3/385.0 MB 3.5 MB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 46.6/385.0 MB 3.5 MB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 46.7/385.0 MB 3.5 MB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 46.8/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ---- ----------------------------------- 47.0/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ---- ----------------------------------- 47.0/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ---- ----------------------------------- 47.2/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ---- ----------------------------------- 47.3/385.0 MB 3.4 MB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 47.4/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 47.5/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 47.6/385.0 MB 3.4 MB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 47.7/385.0 MB 3.3 MB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 47.9/385.0 MB 3.4 MB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 48.0/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ---- ----------------------------------- 48.1/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 48.2/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 48.4/385.0 MB 3.4 MB/s eta 0:01:41\n",
      "   ----- ---------------------------------- 48.5/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 48.7/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 48.8/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 49.0/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 49.1/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 49.3/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 49.4/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 49.6/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 49.7/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 49.9/385.0 MB 3.4 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 50.0/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 50.2/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 50.4/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 50.5/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 50.6/385.0 MB 3.4 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 50.7/385.0 MB 3.3 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 50.7/385.0 MB 3.3 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 50.8/385.0 MB 3.3 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 51.0/385.0 MB 3.3 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 51.1/385.0 MB 3.3 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 51.2/385.0 MB 3.2 MB/s eta 0:01:44\n",
      "   ----- ---------------------------------- 51.4/385.0 MB 3.2 MB/s eta 0:01:44\n",
      "   ----- ---------------------------------- 51.4/385.0 MB 3.2 MB/s eta 0:01:44\n",
      "   ----- ---------------------------------- 51.6/385.0 MB 3.2 MB/s eta 0:01:44\n",
      "   ----- ---------------------------------- 51.7/385.0 MB 3.2 MB/s eta 0:01:45\n",
      "   ----- ---------------------------------- 51.8/385.0 MB 3.2 MB/s eta 0:01:45\n",
      "   ----- ---------------------------------- 52.0/385.0 MB 3.2 MB/s eta 0:01:46\n",
      "   ----- ---------------------------------- 52.1/385.0 MB 3.1 MB/s eta 0:01:46\n",
      "   ----- ---------------------------------- 52.2/385.0 MB 3.1 MB/s eta 0:01:47\n",
      "   ----- ---------------------------------- 52.3/385.0 MB 3.1 MB/s eta 0:01:47\n",
      "   ----- ---------------------------------- 52.5/385.0 MB 3.1 MB/s eta 0:01:47\n",
      "   ----- ---------------------------------- 52.6/385.0 MB 3.1 MB/s eta 0:01:48\n",
      "   ----- ---------------------------------- 52.8/385.0 MB 3.1 MB/s eta 0:01:48\n",
      "   ----- ---------------------------------- 52.9/385.0 MB 3.1 MB/s eta 0:01:49\n",
      "   ----- ---------------------------------- 53.0/385.0 MB 3.1 MB/s eta 0:01:49\n",
      "   ----- ---------------------------------- 53.1/385.0 MB 3.0 MB/s eta 0:01:49\n",
      "   ----- ---------------------------------- 53.2/385.0 MB 3.0 MB/s eta 0:01:50\n",
      "   ----- ---------------------------------- 53.4/385.0 MB 3.0 MB/s eta 0:01:50\n",
      "   ----- ---------------------------------- 53.5/385.0 MB 3.0 MB/s eta 0:01:51\n",
      "   ----- ---------------------------------- 53.6/385.0 MB 3.0 MB/s eta 0:01:50\n",
      "   ----- ---------------------------------- 53.7/385.0 MB 3.0 MB/s eta 0:01:50\n",
      "   ----- ---------------------------------- 53.9/385.0 MB 3.0 MB/s eta 0:01:51\n",
      "   ----- ---------------------------------- 54.0/385.0 MB 3.0 MB/s eta 0:01:52\n",
      "   ----- ---------------------------------- 54.1/385.0 MB 2.9 MB/s eta 0:01:53\n",
      "   ----- ---------------------------------- 54.3/385.0 MB 2.9 MB/s eta 0:01:53\n",
      "   ----- ---------------------------------- 54.4/385.0 MB 2.9 MB/s eta 0:01:53\n",
      "   ----- ---------------------------------- 54.6/385.0 MB 2.9 MB/s eta 0:01:54\n",
      "   ----- ---------------------------------- 54.7/385.0 MB 2.9 MB/s eta 0:01:54\n",
      "   ----- ---------------------------------- 54.9/385.0 MB 2.9 MB/s eta 0:01:54\n",
      "   ----- ---------------------------------- 55.0/385.0 MB 2.9 MB/s eta 0:01:54\n",
      "   ----- ---------------------------------- 55.2/385.0 MB 2.9 MB/s eta 0:01:54\n",
      "   ----- ---------------------------------- 55.3/385.0 MB 2.9 MB/s eta 0:01:55\n",
      "   ----- ---------------------------------- 55.5/385.0 MB 2.9 MB/s eta 0:01:55\n",
      "   ----- ---------------------------------- 55.6/385.0 MB 2.9 MB/s eta 0:01:56\n",
      "   ----- ---------------------------------- 55.8/385.0 MB 2.8 MB/s eta 0:01:56\n",
      "   ----- ---------------------------------- 55.9/385.0 MB 2.9 MB/s eta 0:01:56\n",
      "   ----- ---------------------------------- 56.1/385.0 MB 2.8 MB/s eta 0:01:57\n",
      "   ----- ---------------------------------- 56.3/385.0 MB 2.8 MB/s eta 0:01:56\n",
      "   ----- ---------------------------------- 56.5/385.0 MB 2.8 MB/s eta 0:01:56\n",
      "   ----- ---------------------------------- 56.6/385.0 MB 2.9 MB/s eta 0:01:55\n",
      "   ----- ---------------------------------- 56.8/385.0 MB 2.8 MB/s eta 0:01:56\n",
      "   ----- ---------------------------------- 56.9/385.0 MB 2.8 MB/s eta 0:01:56\n",
      "   ----- ---------------------------------- 57.0/385.0 MB 2.8 MB/s eta 0:01:56\n",
      "   ----- ---------------------------------- 57.2/385.0 MB 2.9 MB/s eta 0:01:55\n",
      "   ----- ---------------------------------- 57.3/385.0 MB 2.9 MB/s eta 0:01:55\n",
      "   ----- ---------------------------------- 57.5/385.0 MB 2.9 MB/s eta 0:01:55\n",
      "   ----- ---------------------------------- 57.6/385.0 MB 2.9 MB/s eta 0:01:54\n",
      "   ----- ---------------------------------- 57.8/385.0 MB 2.9 MB/s eta 0:01:53\n",
      "   ------ --------------------------------- 57.9/385.0 MB 2.9 MB/s eta 0:01:53\n",
      "   ------ --------------------------------- 58.1/385.0 MB 2.9 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 58.2/385.0 MB 2.9 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 58.3/385.0 MB 2.9 MB/s eta 0:01:51\n",
      "   ------ --------------------------------- 58.5/385.0 MB 2.9 MB/s eta 0:01:51\n",
      "   ------ --------------------------------- 58.6/385.0 MB 2.9 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 58.7/385.0 MB 2.9 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 58.9/385.0 MB 2.9 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 59.0/385.0 MB 2.9 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 59.2/385.0 MB 2.9 MB/s eta 0:01:51\n",
      "   ------ --------------------------------- 59.4/385.0 MB 2.9 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 59.6/385.0 MB 2.9 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 59.7/385.0 MB 2.9 MB/s eta 0:01:52\n",
      "   ------ --------------------------------- 59.9/385.0 MB 2.9 MB/s eta 0:01:51\n",
      "   ------ --------------------------------- 60.0/385.0 MB 2.9 MB/s eta 0:01:51\n",
      "   ------ --------------------------------- 60.2/385.0 MB 2.9 MB/s eta 0:01:51\n",
      "   ------ --------------------------------- 60.4/385.0 MB 3.0 MB/s eta 0:01:50\n",
      "   ------ --------------------------------- 60.6/385.0 MB 3.0 MB/s eta 0:01:50\n",
      "   ------ --------------------------------- 60.7/385.0 MB 2.9 MB/s eta 0:01:50\n",
      "   ------ --------------------------------- 60.8/385.0 MB 2.9 MB/s eta 0:01:51\n",
      "   ------ --------------------------------- 61.0/385.0 MB 3.0 MB/s eta 0:01:47\n",
      "   ------ --------------------------------- 61.1/385.0 MB 3.0 MB/s eta 0:01:47\n",
      "   ------ --------------------------------- 61.3/385.0 MB 3.0 MB/s eta 0:01:47\n",
      "   ------ --------------------------------- 61.5/385.0 MB 3.1 MB/s eta 0:01:46\n",
      "   ------ --------------------------------- 61.6/385.0 MB 3.1 MB/s eta 0:01:46\n",
      "   ------ --------------------------------- 61.8/385.0 MB 3.1 MB/s eta 0:01:46\n",
      "   ------ --------------------------------- 62.0/385.0 MB 3.1 MB/s eta 0:01:45\n",
      "   ------ --------------------------------- 62.1/385.0 MB 3.1 MB/s eta 0:01:45\n",
      "   ------ --------------------------------- 62.3/385.0 MB 3.1 MB/s eta 0:01:44\n",
      "   ------ --------------------------------- 62.4/385.0 MB 3.1 MB/s eta 0:01:44\n",
      "   ------ --------------------------------- 62.6/385.0 MB 3.1 MB/s eta 0:01:43\n",
      "   ------ --------------------------------- 62.8/385.0 MB 3.1 MB/s eta 0:01:43\n",
      "   ------ --------------------------------- 62.9/385.0 MB 3.1 MB/s eta 0:01:43\n",
      "   ------ --------------------------------- 63.0/385.0 MB 3.1 MB/s eta 0:01:43\n",
      "   ------ --------------------------------- 63.2/385.0 MB 3.2 MB/s eta 0:01:42\n",
      "   ------ --------------------------------- 63.4/385.0 MB 3.2 MB/s eta 0:01:41\n",
      "   ------ --------------------------------- 63.6/385.0 MB 3.2 MB/s eta 0:01:41\n",
      "   ------ --------------------------------- 63.8/385.0 MB 3.2 MB/s eta 0:01:40\n",
      "   ------ --------------------------------- 63.9/385.0 MB 3.2 MB/s eta 0:01:40\n",
      "   ------ --------------------------------- 64.1/385.0 MB 3.2 MB/s eta 0:01:40\n",
      "   ------ --------------------------------- 64.3/385.0 MB 3.3 MB/s eta 0:01:38\n",
      "   ------ --------------------------------- 64.5/385.0 MB 3.3 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 64.6/385.0 MB 3.3 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 64.7/385.0 MB 3.3 MB/s eta 0:01:38\n",
      "   ------ --------------------------------- 64.9/385.0 MB 3.3 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 65.1/385.0 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 65.3/385.0 MB 3.3 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 65.5/385.0 MB 3.3 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 65.6/385.0 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 65.8/385.0 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 66.0/385.0 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 66.2/385.0 MB 3.4 MB/s eta 0:01:35\n",
      "   ------ --------------------------------- 66.3/385.0 MB 3.4 MB/s eta 0:01:35\n",
      "   ------ --------------------------------- 66.5/385.0 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 66.6/385.0 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 66.8/385.0 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 66.9/385.0 MB 3.4 MB/s eta 0:01:35\n",
      "   ------ --------------------------------- 67.0/385.0 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 67.1/385.0 MB 3.3 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 67.2/385.0 MB 3.3 MB/s eta 0:01:38\n",
      "   ------ --------------------------------- 67.3/385.0 MB 3.3 MB/s eta 0:01:37\n",
      "   ------- -------------------------------- 67.5/385.0 MB 3.3 MB/s eta 0:01:38\n",
      "   ------- -------------------------------- 67.6/385.0 MB 3.3 MB/s eta 0:01:38\n",
      "   ------- -------------------------------- 67.7/385.0 MB 3.3 MB/s eta 0:01:38\n",
      "   ------- -------------------------------- 67.7/385.0 MB 3.3 MB/s eta 0:01:38\n",
      "   ------- -------------------------------- 67.9/385.0 MB 3.2 MB/s eta 0:01:39\n",
      "   ------- -------------------------------- 68.0/385.0 MB 3.2 MB/s eta 0:01:39\n",
      "   ------- -------------------------------- 68.1/385.0 MB 3.2 MB/s eta 0:01:40\n",
      "   ------- -------------------------------- 68.2/385.0 MB 3.2 MB/s eta 0:01:40\n",
      "   ------- -------------------------------- 68.3/385.0 MB 3.2 MB/s eta 0:01:40\n",
      "   ------- -------------------------------- 68.4/385.0 MB 3.2 MB/s eta 0:01:41\n",
      "   ------- -------------------------------- 68.5/385.0 MB 3.1 MB/s eta 0:01:42\n",
      "   ------- -------------------------------- 68.5/385.0 MB 3.1 MB/s eta 0:01:42\n",
      "   ------- -------------------------------- 68.6/385.0 MB 3.1 MB/s eta 0:01:42\n",
      "   ------- -------------------------------- 68.7/385.0 MB 3.1 MB/s eta 0:01:43\n",
      "   ------- -------------------------------- 68.8/385.0 MB 3.1 MB/s eta 0:01:43\n",
      "   ------- -------------------------------- 68.9/385.0 MB 3.1 MB/s eta 0:01:43\n",
      "   ------- -------------------------------- 69.0/385.0 MB 3.1 MB/s eta 0:01:44\n",
      "   ------- -------------------------------- 69.1/385.0 MB 3.0 MB/s eta 0:01:44\n",
      "   ------- -------------------------------- 69.2/385.0 MB 3.0 MB/s eta 0:01:45\n",
      "   ------- -------------------------------- 69.3/385.0 MB 3.0 MB/s eta 0:01:45\n",
      "   ------- -------------------------------- 69.4/385.0 MB 3.0 MB/s eta 0:01:46\n",
      "   ------- -------------------------------- 69.5/385.0 MB 3.0 MB/s eta 0:01:46\n",
      "   ------- -------------------------------- 69.7/385.0 MB 3.0 MB/s eta 0:01:46\n",
      "   ------- -------------------------------- 69.8/385.0 MB 3.0 MB/s eta 0:01:47\n",
      "   ------- -------------------------------- 69.9/385.0 MB 2.9 MB/s eta 0:01:47\n",
      "   ------- -------------------------------- 69.9/385.0 MB 2.9 MB/s eta 0:01:48\n",
      "   ------- -------------------------------- 70.1/385.0 MB 2.9 MB/s eta 0:01:48\n",
      "   ------- -------------------------------- 70.2/385.0 MB 2.9 MB/s eta 0:01:49\n",
      "   ------- -------------------------------- 70.3/385.0 MB 2.9 MB/s eta 0:01:50\n",
      "   ------- -------------------------------- 70.3/385.0 MB 2.9 MB/s eta 0:01:51\n",
      "   ------- -------------------------------- 70.6/385.0 MB 2.9 MB/s eta 0:01:50\n",
      "   ------- -------------------------------- 70.7/385.0 MB 2.8 MB/s eta 0:01:51\n",
      "   ------- -------------------------------- 70.8/385.0 MB 2.8 MB/s eta 0:01:52\n",
      "   ------- -------------------------------- 70.9/385.0 MB 2.8 MB/s eta 0:01:51\n",
      "   ------- -------------------------------- 71.0/385.0 MB 2.8 MB/s eta 0:01:51\n",
      "   ------- -------------------------------- 71.1/385.0 MB 2.8 MB/s eta 0:01:52\n",
      "   ------- -------------------------------- 71.2/385.0 MB 2.8 MB/s eta 0:01:53\n",
      "   ------- -------------------------------- 71.3/385.0 MB 2.8 MB/s eta 0:01:54\n",
      "   ------- -------------------------------- 71.4/385.0 MB 2.8 MB/s eta 0:01:54\n",
      "   ------- -------------------------------- 71.5/385.0 MB 2.8 MB/s eta 0:01:54\n",
      "   ------- -------------------------------- 71.6/385.0 MB 2.7 MB/s eta 0:01:55\n",
      "   ------- -------------------------------- 71.7/385.0 MB 2.7 MB/s eta 0:01:55\n",
      "   ------- -------------------------------- 71.9/385.0 MB 2.7 MB/s eta 0:01:55\n",
      "   ------- -------------------------------- 72.0/385.0 MB 2.7 MB/s eta 0:01:55\n",
      "   ------- -------------------------------- 72.1/385.0 MB 2.7 MB/s eta 0:01:56\n",
      "   ------- -------------------------------- 72.2/385.0 MB 2.7 MB/s eta 0:01:57\n",
      "   ------- -------------------------------- 72.3/385.0 MB 2.7 MB/s eta 0:01:57\n",
      "   ------- -------------------------------- 72.4/385.0 MB 2.7 MB/s eta 0:01:57\n",
      "   ------- -------------------------------- 72.6/385.0 MB 2.7 MB/s eta 0:01:57\n",
      "   ------- -------------------------------- 72.7/385.0 MB 2.7 MB/s eta 0:01:58\n",
      "   ------- -------------------------------- 72.8/385.0 MB 2.7 MB/s eta 0:01:57\n",
      "   ------- -------------------------------- 72.9/385.0 MB 2.7 MB/s eta 0:01:58\n",
      "   ------- -------------------------------- 73.0/385.0 MB 2.7 MB/s eta 0:01:58\n",
      "   ------- -------------------------------- 73.1/385.0 MB 2.6 MB/s eta 0:01:59\n",
      "   ------- -------------------------------- 73.1/385.0 MB 2.6 MB/s eta 0:01:59\n",
      "   ------- -------------------------------- 73.3/385.0 MB 2.6 MB/s eta 0:02:00\n",
      "   ------- -------------------------------- 73.3/385.0 MB 2.6 MB/s eta 0:02:01\n",
      "   ------- -------------------------------- 73.4/385.0 MB 2.6 MB/s eta 0:02:02\n",
      "   ------- -------------------------------- 73.6/385.0 MB 2.6 MB/s eta 0:02:02\n",
      "   ------- -------------------------------- 73.7/385.0 MB 2.5 MB/s eta 0:02:03\n",
      "   ------- -------------------------------- 73.8/385.0 MB 2.5 MB/s eta 0:02:03\n",
      "   ------- -------------------------------- 73.9/385.0 MB 2.5 MB/s eta 0:02:03\n",
      "   ------- -------------------------------- 74.0/385.0 MB 2.5 MB/s eta 0:02:04\n",
      "   ------- -------------------------------- 74.2/385.0 MB 2.5 MB/s eta 0:02:04\n",
      "   ------- -------------------------------- 74.4/385.0 MB 2.5 MB/s eta 0:02:03\n",
      "   ------- -------------------------------- 74.5/385.0 MB 2.5 MB/s eta 0:02:04\n",
      "   ------- -------------------------------- 74.6/385.0 MB 2.5 MB/s eta 0:02:05\n",
      "   ------- -------------------------------- 74.6/385.0 MB 2.5 MB/s eta 0:02:05\n",
      "   ------- -------------------------------- 74.8/385.0 MB 2.5 MB/s eta 0:02:06\n",
      "   ------- -------------------------------- 74.8/385.0 MB 2.5 MB/s eta 0:02:07\n",
      "   ------- -------------------------------- 74.9/385.0 MB 2.4 MB/s eta 0:02:08\n",
      "   ------- -------------------------------- 75.0/385.0 MB 2.4 MB/s eta 0:02:08\n",
      "   ------- -------------------------------- 75.1/385.0 MB 2.4 MB/s eta 0:02:09\n",
      "   ------- -------------------------------- 75.1/385.0 MB 2.4 MB/s eta 0:02:09\n",
      "   ------- -------------------------------- 75.2/385.0 MB 2.4 MB/s eta 0:02:10\n",
      "   ------- -------------------------------- 75.3/385.0 MB 2.4 MB/s eta 0:02:11\n",
      "   ------- -------------------------------- 75.5/385.0 MB 2.4 MB/s eta 0:02:11\n",
      "   ------- -------------------------------- 75.6/385.0 MB 2.4 MB/s eta 0:02:11\n",
      "   ------- -------------------------------- 75.7/385.0 MB 2.3 MB/s eta 0:02:12\n",
      "   ------- -------------------------------- 75.8/385.0 MB 2.3 MB/s eta 0:02:13\n",
      "   ------- -------------------------------- 75.9/385.0 MB 2.3 MB/s eta 0:02:13\n",
      "   ------- -------------------------------- 76.0/385.0 MB 2.3 MB/s eta 0:02:14\n",
      "   ------- -------------------------------- 76.1/385.0 MB 2.3 MB/s eta 0:02:14\n",
      "   ------- -------------------------------- 76.2/385.0 MB 2.3 MB/s eta 0:02:15\n",
      "   ------- -------------------------------- 76.3/385.0 MB 2.3 MB/s eta 0:02:15\n",
      "   ------- -------------------------------- 76.4/385.0 MB 2.3 MB/s eta 0:02:16\n",
      "   ------- -------------------------------- 76.5/385.0 MB 2.3 MB/s eta 0:02:16\n",
      "   ------- -------------------------------- 76.6/385.0 MB 2.3 MB/s eta 0:02:16\n",
      "   ------- -------------------------------- 76.7/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   ------- -------------------------------- 76.8/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   ------- -------------------------------- 76.9/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 77.0/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 77.1/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 77.3/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 77.4/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 77.5/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 77.6/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 77.8/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 77.9/385.0 MB 2.3 MB/s eta 0:02:17\n",
      "   -------- ------------------------------- 78.0/385.0 MB 2.2 MB/s eta 0:02:17\n",
      "   -------- ------------------------------- 78.1/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 78.1/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 78.2/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 78.3/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 78.4/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 78.4/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 78.6/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 78.6/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 78.7/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 78.8/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 78.9/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 79.0/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 79.1/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 79.2/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 79.3/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 79.4/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 79.5/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 79.6/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 79.7/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 79.8/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 79.9/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 80.0/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 80.1/385.0 MB 2.2 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 80.2/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 80.3/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 80.4/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 80.5/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 80.6/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 80.7/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 80.8/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 80.9/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 81.0/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 81.1/385.0 MB 2.2 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 81.3/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 81.3/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 81.4/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 81.5/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 81.6/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 81.7/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 81.8/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 82.0/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 82.1/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 82.2/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 82.3/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 82.4/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 82.5/385.0 MB 2.2 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 82.6/385.0 MB 2.2 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 82.7/385.0 MB 2.2 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 82.8/385.0 MB 2.2 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 83.0/385.0 MB 2.2 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 83.0/385.0 MB 2.2 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 83.1/385.0 MB 2.2 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 83.3/385.0 MB 2.2 MB/s eta 0:02:21\n",
      "   -------- ------------------------------- 83.4/385.0 MB 2.2 MB/s eta 0:02:19\n",
      "   -------- ------------------------------- 83.5/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 83.7/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 83.8/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 84.0/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 84.1/385.0 MB 2.2 MB/s eta 0:02:17\n",
      "   -------- ------------------------------- 84.2/385.0 MB 2.2 MB/s eta 0:02:17\n",
      "   -------- ------------------------------- 84.3/385.0 MB 2.2 MB/s eta 0:02:17\n",
      "   -------- ------------------------------- 84.5/385.0 MB 2.2 MB/s eta 0:02:17\n",
      "   -------- ------------------------------- 84.5/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 84.7/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 84.8/385.0 MB 2.2 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 84.9/385.0 MB 2.2 MB/s eta 0:02:17\n",
      "   -------- ------------------------------- 85.1/385.0 MB 2.2 MB/s eta 0:02:16\n",
      "   -------- ------------------------------- 85.2/385.0 MB 2.2 MB/s eta 0:02:14\n",
      "   -------- ------------------------------- 85.4/385.0 MB 2.3 MB/s eta 0:02:13\n",
      "   -------- ------------------------------- 85.5/385.0 MB 2.3 MB/s eta 0:02:12\n",
      "   -------- ------------------------------- 85.6/385.0 MB 2.3 MB/s eta 0:02:13\n",
      "   -------- ------------------------------- 85.7/385.0 MB 2.3 MB/s eta 0:02:13\n",
      "   -------- ------------------------------- 85.9/385.0 MB 2.3 MB/s eta 0:02:12\n",
      "   -------- ------------------------------- 86.0/385.0 MB 2.3 MB/s eta 0:02:12\n",
      "   -------- ------------------------------- 86.1/385.0 MB 2.3 MB/s eta 0:02:11\n",
      "   -------- ------------------------------- 86.3/385.0 MB 2.3 MB/s eta 0:02:09\n",
      "   -------- ------------------------------- 86.4/385.0 MB 2.3 MB/s eta 0:02:10\n",
      "   -------- ------------------------------- 86.5/385.0 MB 2.3 MB/s eta 0:02:10\n",
      "   --------- ------------------------------ 86.6/385.0 MB 2.3 MB/s eta 0:02:10\n",
      "   --------- ------------------------------ 86.8/385.0 MB 2.3 MB/s eta 0:02:09\n",
      "   --------- ------------------------------ 87.0/385.0 MB 2.3 MB/s eta 0:02:08\n",
      "   --------- ------------------------------ 87.1/385.0 MB 2.4 MB/s eta 0:02:06\n",
      "   --------- ------------------------------ 87.3/385.0 MB 2.4 MB/s eta 0:02:06\n",
      "   --------- ------------------------------ 87.4/385.0 MB 2.4 MB/s eta 0:02:06\n",
      "   --------- ------------------------------ 87.6/385.0 MB 2.4 MB/s eta 0:02:06\n",
      "   --------- ------------------------------ 87.6/385.0 MB 2.4 MB/s eta 0:02:05\n",
      "   --------- ------------------------------ 87.8/385.0 MB 2.4 MB/s eta 0:02:05\n",
      "   --------- ------------------------------ 88.0/385.0 MB 2.4 MB/s eta 0:02:05\n",
      "   --------- ------------------------------ 88.1/385.0 MB 2.4 MB/s eta 0:02:05\n",
      "   --------- ------------------------------ 88.2/385.0 MB 2.4 MB/s eta 0:02:04\n",
      "   --------- ------------------------------ 88.4/385.0 MB 2.4 MB/s eta 0:02:03\n",
      "   --------- ------------------------------ 88.5/385.0 MB 2.4 MB/s eta 0:02:02\n",
      "   --------- ------------------------------ 88.7/385.0 MB 2.5 MB/s eta 0:02:01\n",
      "   --------- ------------------------------ 88.8/385.0 MB 2.5 MB/s eta 0:02:01\n",
      "   --------- ------------------------------ 89.0/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 89.1/385.0 MB 2.5 MB/s eta 0:01:58\n",
      "   --------- ------------------------------ 89.1/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 89.1/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 89.3/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 89.4/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 89.5/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 89.6/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 89.7/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 89.8/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 89.9/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 90.0/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 90.1/385.0 MB 2.5 MB/s eta 0:01:59\n",
      "   --------- ------------------------------ 90.2/385.0 MB 2.5 MB/s eta 0:01:58\n",
      "   --------- ------------------------------ 90.4/385.0 MB 2.5 MB/s eta 0:01:57\n",
      "   --------- ------------------------------ 90.4/385.0 MB 2.5 MB/s eta 0:01:58\n",
      "   --------- ------------------------------ 90.6/385.0 MB 2.5 MB/s eta 0:01:57\n",
      "   --------- ------------------------------ 90.7/385.0 MB 2.5 MB/s eta 0:01:56\n",
      "   --------- ------------------------------ 90.8/385.0 MB 2.5 MB/s eta 0:01:57\n",
      "   --------- ------------------------------ 90.9/385.0 MB 2.5 MB/s eta 0:01:56\n",
      "   --------- ------------------------------ 91.0/385.0 MB 2.5 MB/s eta 0:01:56\n",
      "   --------- ------------------------------ 91.2/385.0 MB 2.5 MB/s eta 0:01:56\n",
      "   --------- ------------------------------ 91.3/385.0 MB 2.6 MB/s eta 0:01:55\n",
      "   --------- ------------------------------ 91.4/385.0 MB 2.6 MB/s eta 0:01:55\n",
      "   --------- ------------------------------ 91.6/385.0 MB 2.6 MB/s eta 0:01:55\n",
      "   --------- ------------------------------ 91.7/385.0 MB 2.6 MB/s eta 0:01:55\n",
      "   --------- ------------------------------ 91.8/385.0 MB 2.6 MB/s eta 0:01:53\n",
      "   --------- ------------------------------ 91.9/385.0 MB 2.6 MB/s eta 0:01:54\n",
      "   --------- ------------------------------ 92.1/385.0 MB 2.6 MB/s eta 0:01:54\n",
      "   --------- ------------------------------ 92.2/385.0 MB 2.6 MB/s eta 0:01:53\n",
      "   --------- ------------------------------ 92.4/385.0 MB 2.6 MB/s eta 0:01:53\n",
      "   --------- ------------------------------ 92.5/385.0 MB 2.6 MB/s eta 0:01:52\n",
      "   --------- ------------------------------ 92.7/385.0 MB 2.6 MB/s eta 0:01:52\n",
      "   --------- ------------------------------ 92.8/385.0 MB 2.7 MB/s eta 0:01:51\n",
      "   --------- ------------------------------ 92.9/385.0 MB 2.7 MB/s eta 0:01:50\n",
      "   --------- ------------------------------ 93.1/385.0 MB 2.7 MB/s eta 0:01:49\n",
      "   --------- ------------------------------ 93.2/385.0 MB 2.7 MB/s eta 0:01:50\n",
      "   --------- ------------------------------ 93.4/385.0 MB 2.7 MB/s eta 0:01:49\n",
      "   --------- ------------------------------ 93.5/385.0 MB 2.7 MB/s eta 0:01:49\n",
      "   --------- ------------------------------ 93.7/385.0 MB 2.7 MB/s eta 0:01:48\n",
      "   --------- ------------------------------ 93.8/385.0 MB 2.7 MB/s eta 0:01:48\n",
      "   --------- ------------------------------ 93.9/385.0 MB 2.7 MB/s eta 0:01:48\n",
      "   --------- ------------------------------ 94.1/385.0 MB 2.7 MB/s eta 0:01:48\n",
      "   --------- ------------------------------ 94.2/385.0 MB 2.7 MB/s eta 0:01:48\n",
      "   --------- ------------------------------ 94.4/385.0 MB 2.7 MB/s eta 0:01:47\n",
      "   --------- ------------------------------ 94.5/385.0 MB 2.7 MB/s eta 0:01:47\n",
      "   --------- ------------------------------ 94.7/385.0 MB 2.7 MB/s eta 0:01:47\n",
      "   --------- ------------------------------ 94.8/385.0 MB 2.7 MB/s eta 0:01:47\n",
      "   --------- ------------------------------ 95.0/385.0 MB 2.8 MB/s eta 0:01:46\n",
      "   --------- ------------------------------ 95.2/385.0 MB 2.8 MB/s eta 0:01:45\n",
      "   --------- ------------------------------ 95.3/385.0 MB 2.8 MB/s eta 0:01:46\n",
      "   --------- ------------------------------ 95.5/385.0 MB 2.8 MB/s eta 0:01:46\n",
      "   --------- ------------------------------ 95.6/385.0 MB 2.7 MB/s eta 0:01:46\n",
      "   --------- ------------------------------ 95.7/385.0 MB 2.8 MB/s eta 0:01:46\n",
      "   --------- ------------------------------ 95.9/385.0 MB 2.8 MB/s eta 0:01:46\n",
      "   --------- ------------------------------ 96.0/385.0 MB 2.8 MB/s eta 0:01:45\n",
      "   --------- ------------------------------ 96.1/385.0 MB 2.8 MB/s eta 0:01:45\n",
      "   ---------- ----------------------------- 96.3/385.0 MB 2.8 MB/s eta 0:01:45\n",
      "   ---------- ----------------------------- 96.5/385.0 MB 2.8 MB/s eta 0:01:45\n",
      "   ---------- ----------------------------- 96.6/385.0 MB 2.8 MB/s eta 0:01:44\n",
      "   ---------- ----------------------------- 96.7/385.0 MB 2.8 MB/s eta 0:01:44\n",
      "   ---------- ----------------------------- 96.9/385.0 MB 2.8 MB/s eta 0:01:43\n",
      "   ---------- ----------------------------- 97.0/385.0 MB 2.8 MB/s eta 0:01:44\n",
      "   ---------- ----------------------------- 97.1/385.0 MB 2.8 MB/s eta 0:01:45\n",
      "   ---------- ----------------------------- 97.3/385.0 MB 2.8 MB/s eta 0:01:44\n",
      "   ---------- ----------------------------- 97.5/385.0 MB 2.8 MB/s eta 0:01:44\n",
      "   ---------- ----------------------------- 97.6/385.0 MB 2.8 MB/s eta 0:01:44\n",
      "   ---------- ----------------------------- 97.7/385.0 MB 2.8 MB/s eta 0:01:44\n",
      "   ---------- ----------------------------- 97.9/385.0 MB 2.8 MB/s eta 0:01:44\n",
      "   ---------- ----------------------------- 98.1/385.0 MB 2.8 MB/s eta 0:01:43\n",
      "   ---------- ----------------------------- 98.2/385.0 MB 2.8 MB/s eta 0:01:43\n",
      "   ---------- ----------------------------- 98.4/385.0 MB 2.8 MB/s eta 0:01:43\n",
      "   ---------- ----------------------------- 98.5/385.0 MB 2.8 MB/s eta 0:01:43\n",
      "   ---------- ----------------------------- 98.6/385.0 MB 2.8 MB/s eta 0:01:42\n",
      "   ---------- ----------------------------- 98.8/385.0 MB 2.8 MB/s eta 0:01:42\n",
      "   ---------- ----------------------------- 99.0/385.0 MB 2.8 MB/s eta 0:01:42\n",
      "   ---------- ----------------------------- 99.2/385.0 MB 2.8 MB/s eta 0:01:41\n",
      "   ---------- ----------------------------- 99.3/385.0 MB 2.9 MB/s eta 0:01:39\n",
      "   ---------- ----------------------------- 99.5/385.0 MB 2.9 MB/s eta 0:01:40\n",
      "   ---------- ----------------------------- 99.6/385.0 MB 2.9 MB/s eta 0:01:39\n",
      "   ---------- ----------------------------- 99.8/385.0 MB 2.9 MB/s eta 0:01:39\n",
      "   ---------- ----------------------------- 99.9/385.0 MB 2.9 MB/s eta 0:01:38\n",
      "   ---------- ----------------------------- 100.0/385.0 MB 2.9 MB/s eta 0:01:38\n",
      "   ---------- ----------------------------- 100.2/385.0 MB 2.9 MB/s eta 0:01:37\n",
      "   ---------- ----------------------------- 100.2/385.0 MB 3.0 MB/s eta 0:01:37\n",
      "   ---------- ----------------------------- 100.4/385.0 MB 3.0 MB/s eta 0:01:37\n",
      "   ---------- ----------------------------- 100.5/385.0 MB 3.0 MB/s eta 0:01:36\n",
      "   ---------- ----------------------------- 100.6/385.0 MB 2.9 MB/s eta 0:01:37\n",
      "   ---------- ----------------------------- 100.7/385.0 MB 3.0 MB/s eta 0:01:36\n",
      "   ---------- ----------------------------- 100.9/385.0 MB 3.0 MB/s eta 0:01:36\n",
      "   ---------- ----------------------------- 101.0/385.0 MB 3.0 MB/s eta 0:01:35\n",
      "   ---------- ----------------------------- 101.2/385.0 MB 3.0 MB/s eta 0:01:35\n",
      "   ---------- ----------------------------- 101.4/385.0 MB 3.0 MB/s eta 0:01:34\n",
      "   ---------- ----------------------------- 101.6/385.0 MB 3.0 MB/s eta 0:01:34\n",
      "   ---------- ----------------------------- 101.7/385.0 MB 3.1 MB/s eta 0:01:33\n",
      "   ---------- ----------------------------- 101.9/385.0 MB 3.1 MB/s eta 0:01:32\n",
      "   ---------- ----------------------------- 102.1/385.0 MB 3.1 MB/s eta 0:01:32\n",
      "   ---------- ----------------------------- 102.3/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 102.4/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 102.6/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 102.8/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 102.9/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 103.1/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 103.2/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 103.3/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 103.4/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 103.6/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 103.7/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 103.9/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 104.1/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 104.3/385.0 MB 3.2 MB/s eta 0:01:29\n",
      "   ---------- ----------------------------- 104.4/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 104.5/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 104.6/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 104.7/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 104.9/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 105.0/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 105.2/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 105.3/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 105.5/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 105.6/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ---------- ----------------------------- 105.7/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ----------- ---------------------------- 105.9/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ----------- ---------------------------- 106.0/385.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ----------- ---------------------------- 106.1/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ----------- ---------------------------- 106.1/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ----------- ---------------------------- 106.3/385.0 MB 3.1 MB/s eta 0:01:31\n",
      "   ----------- ---------------------------- 106.4/385.0 MB 3.1 MB/s eta 0:01:32\n",
      "   ----------- ---------------------------- 106.5/385.0 MB 3.1 MB/s eta 0:01:32\n",
      "   ----------- ---------------------------- 106.6/385.0 MB 3.0 MB/s eta 0:01:32\n",
      "   ----------- ---------------------------- 106.7/385.0 MB 3.0 MB/s eta 0:01:33\n",
      "   ----------- ---------------------------- 106.9/385.0 MB 3.0 MB/s eta 0:01:33\n",
      "   ----------- ---------------------------- 106.9/385.0 MB 3.0 MB/s eta 0:01:34\n",
      "   ----------- ---------------------------- 107.0/385.0 MB 2.9 MB/s eta 0:01:35\n",
      "   ----------- ---------------------------- 107.0/385.0 MB 2.9 MB/s eta 0:01:35\n",
      "   ----------- ---------------------------- 107.2/385.0 MB 2.9 MB/s eta 0:01:35\n",
      "   ----------- ---------------------------- 107.3/385.0 MB 2.9 MB/s eta 0:01:36\n",
      "   ----------- ---------------------------- 107.4/385.0 MB 2.9 MB/s eta 0:01:35\n",
      "   ----------- ---------------------------- 107.5/385.0 MB 2.9 MB/s eta 0:01:36\n",
      "   ----------- ---------------------------- 107.6/385.0 MB 2.9 MB/s eta 0:01:36\n",
      "   ----------- ---------------------------- 107.7/385.0 MB 2.9 MB/s eta 0:01:37\n",
      "   ----------- ---------------------------- 107.8/385.0 MB 2.9 MB/s eta 0:01:37\n",
      "   ----------- ---------------------------- 108.0/385.0 MB 2.9 MB/s eta 0:01:37\n",
      "   ----------- ---------------------------- 108.1/385.0 MB 2.9 MB/s eta 0:01:37\n",
      "   ----------- ---------------------------- 108.2/385.0 MB 2.9 MB/s eta 0:01:37\n",
      "   ----------- ---------------------------- 108.3/385.0 MB 2.9 MB/s eta 0:01:37\n",
      "   ----------- ---------------------------- 108.4/385.0 MB 2.9 MB/s eta 0:01:37\n",
      "   ----------- ---------------------------- 108.6/385.0 MB 2.8 MB/s eta 0:01:38\n",
      "   ----------- ---------------------------- 108.6/385.0 MB 2.8 MB/s eta 0:01:38\n",
      "   ----------- ---------------------------- 108.7/385.0 MB 2.8 MB/s eta 0:01:38\n",
      "   ----------- ---------------------------- 108.8/385.0 MB 2.8 MB/s eta 0:01:39\n",
      "   ----------- ---------------------------- 109.0/385.0 MB 2.8 MB/s eta 0:01:39\n",
      "   ----------- ---------------------------- 109.1/385.0 MB 2.8 MB/s eta 0:01:40\n",
      "   ----------- ---------------------------- 109.2/385.0 MB 2.8 MB/s eta 0:01:40\n",
      "   ----------- ---------------------------- 109.3/385.0 MB 2.8 MB/s eta 0:01:41\n",
      "   ----------- ---------------------------- 109.4/385.0 MB 2.7 MB/s eta 0:01:42\n",
      "   ----------- ---------------------------- 109.5/385.0 MB 2.7 MB/s eta 0:01:42\n",
      "   ----------- ---------------------------- 109.6/385.0 MB 2.7 MB/s eta 0:01:41\n",
      "   ----------- ---------------------------- 109.7/385.0 MB 2.7 MB/s eta 0:01:42\n",
      "   ----------- ---------------------------- 109.9/385.0 MB 2.7 MB/s eta 0:01:42\n",
      "   ----------- ---------------------------- 110.0/385.0 MB 2.7 MB/s eta 0:01:42\n",
      "   ----------- ---------------------------- 110.1/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 110.2/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 110.2/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 110.4/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 110.5/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 110.6/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 110.8/385.0 MB 2.7 MB/s eta 0:01:44\n",
      "   ----------- ---------------------------- 110.9/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 111.0/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 111.2/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 111.2/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 111.4/385.0 MB 2.7 MB/s eta 0:01:43\n",
      "   ----------- ---------------------------- 111.5/385.0 MB 2.7 MB/s eta 0:01:44\n",
      "   ----------- ---------------------------- 111.6/385.0 MB 2.6 MB/s eta 0:01:44\n",
      "   ----------- ---------------------------- 111.7/385.0 MB 2.6 MB/s eta 0:01:44\n",
      "   ----------- ---------------------------- 111.8/385.0 MB 2.6 MB/s eta 0:01:44\n",
      "   ----------- ---------------------------- 112.0/385.0 MB 2.6 MB/s eta 0:01:45\n",
      "   ----------- ---------------------------- 112.0/385.0 MB 2.6 MB/s eta 0:01:46\n",
      "   ----------- ---------------------------- 112.0/385.0 MB 2.6 MB/s eta 0:01:46\n",
      "   ----------- ---------------------------- 112.0/385.0 MB 2.6 MB/s eta 0:01:46\n",
      "   ----------- ---------------------------- 112.0/385.0 MB 2.6 MB/s eta 0:01:46\n",
      "   ----------- ---------------------------- 112.0/385.0 MB 2.6 MB/s eta 0:01:46\n",
      "   ----------- ---------------------------- 112.0/385.0 MB 2.6 MB/s eta 0:01:46\n",
      "   ----------- ---------------------------- 112.0/385.0 MB 2.6 MB/s eta 0:01:46\n",
      "   ----------- ---------------------------- 112.1/385.0 MB 2.4 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 112.1/385.0 MB 2.4 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 112.1/385.0 MB 2.4 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 112.1/385.0 MB 2.4 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 112.1/385.0 MB 2.4 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 112.1/385.0 MB 2.4 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 112.1/385.0 MB 2.4 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 112.1/385.0 MB 2.4 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 112.2/385.0 MB 2.2 MB/s eta 0:02:03\n",
      "   ----------- ---------------------------- 112.3/385.0 MB 2.2 MB/s eta 0:02:04\n",
      "   ----------- ---------------------------- 112.3/385.0 MB 2.2 MB/s eta 0:02:05\n",
      "   ----------- ---------------------------- 112.4/385.0 MB 2.2 MB/s eta 0:02:05\n",
      "   ----------- ---------------------------- 112.5/385.0 MB 2.2 MB/s eta 0:02:06\n",
      "   ----------- ---------------------------- 112.6/385.0 MB 2.2 MB/s eta 0:02:07\n",
      "   ----------- ---------------------------- 112.7/385.0 MB 2.2 MB/s eta 0:02:07\n",
      "   ----------- ---------------------------- 112.8/385.0 MB 2.1 MB/s eta 0:02:08\n",
      "   ----------- ---------------------------- 112.9/385.0 MB 2.1 MB/s eta 0:02:08\n",
      "   ----------- ---------------------------- 113.0/385.0 MB 2.1 MB/s eta 0:02:08\n",
      "   ----------- ---------------------------- 113.1/385.0 MB 2.1 MB/s eta 0:02:09\n",
      "   ----------- ---------------------------- 113.2/385.0 MB 2.1 MB/s eta 0:02:09\n",
      "   ----------- ---------------------------- 113.3/385.0 MB 2.1 MB/s eta 0:02:10\n",
      "   ----------- ---------------------------- 113.4/385.0 MB 2.1 MB/s eta 0:02:10\n",
      "   ----------- ---------------------------- 113.5/385.0 MB 2.1 MB/s eta 0:02:10\n",
      "   ----------- ---------------------------- 113.6/385.0 MB 2.1 MB/s eta 0:02:09\n",
      "   ----------- ---------------------------- 113.8/385.0 MB 2.1 MB/s eta 0:02:09\n",
      "   ----------- ---------------------------- 113.8/385.0 MB 2.1 MB/s eta 0:02:10\n",
      "   ----------- ---------------------------- 114.0/385.0 MB 2.1 MB/s eta 0:02:10\n",
      "   ----------- ---------------------------- 114.1/385.0 MB 2.1 MB/s eta 0:02:10\n",
      "   ----------- ---------------------------- 114.2/385.0 MB 2.1 MB/s eta 0:02:10\n",
      "   ----------- ---------------------------- 114.3/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 114.5/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 114.6/385.0 MB 2.1 MB/s eta 0:02:11\n",
      "   ----------- ---------------------------- 114.7/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 114.8/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 114.9/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 115.1/385.0 MB 2.1 MB/s eta 0:02:11\n",
      "   ----------- ---------------------------- 115.2/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 115.2/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 115.2/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 115.2/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 115.2/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 115.2/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 115.2/385.0 MB 2.1 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 115.3/385.0 MB 1.9 MB/s eta 0:02:19\n",
      "   ----------- ---------------------------- 115.3/385.0 MB 1.9 MB/s eta 0:02:19\n",
      "   ----------- ---------------------------- 115.3/385.0 MB 1.9 MB/s eta 0:02:19\n",
      "   ----------- ---------------------------- 115.4/385.0 MB 1.9 MB/s eta 0:02:22\n",
      "   ----------- ---------------------------- 115.4/385.0 MB 1.9 MB/s eta 0:02:23\n",
      "   ----------- ---------------------------- 115.5/385.0 MB 1.9 MB/s eta 0:02:23\n",
      "   ----------- ---------------------------- 115.5/385.0 MB 1.9 MB/s eta 0:02:25\n",
      "   ------------ --------------------------- 115.6/385.0 MB 1.9 MB/s eta 0:02:26\n",
      "   ------------ --------------------------- 115.6/385.0 MB 1.9 MB/s eta 0:02:26\n",
      "   ------------ --------------------------- 115.7/385.0 MB 1.8 MB/s eta 0:02:27\n",
      "   ------------ --------------------------- 115.7/385.0 MB 1.8 MB/s eta 0:02:28\n",
      "   ------------ --------------------------- 115.8/385.0 MB 1.8 MB/s eta 0:02:28\n",
      "   ------------ --------------------------- 115.8/385.0 MB 1.8 MB/s eta 0:02:29\n",
      "   ------------ --------------------------- 115.9/385.0 MB 1.8 MB/s eta 0:02:30\n",
      "   ------------ --------------------------- 115.9/385.0 MB 1.8 MB/s eta 0:02:31\n",
      "   ------------ --------------------------- 116.0/385.0 MB 1.8 MB/s eta 0:02:32\n",
      "   ------------ --------------------------- 116.0/385.0 MB 1.8 MB/s eta 0:02:32\n",
      "   ------------ --------------------------- 116.1/385.0 MB 1.8 MB/s eta 0:02:33\n",
      "   ------------ --------------------------- 116.1/385.0 MB 1.8 MB/s eta 0:02:33\n",
      "   ------------ --------------------------- 116.2/385.0 MB 1.8 MB/s eta 0:02:34\n",
      "   ------------ --------------------------- 116.3/385.0 MB 1.7 MB/s eta 0:02:34\n",
      "   ------------ --------------------------- 116.3/385.0 MB 1.8 MB/s eta 0:02:33\n",
      "   ------------ --------------------------- 116.4/385.0 MB 1.8 MB/s eta 0:02:34\n",
      "   ------------ --------------------------- 116.5/385.0 MB 1.7 MB/s eta 0:02:35\n",
      "   ------------ --------------------------- 116.5/385.0 MB 1.7 MB/s eta 0:02:36\n",
      "   ------------ --------------------------- 116.6/385.0 MB 1.7 MB/s eta 0:02:37\n",
      "   ------------ --------------------------- 116.7/385.0 MB 1.7 MB/s eta 0:02:37\n",
      "   ------------ --------------------------- 116.7/385.0 MB 1.7 MB/s eta 0:02:37\n",
      "   ------------ --------------------------- 116.8/385.0 MB 1.7 MB/s eta 0:02:37\n",
      "   ------------ --------------------------- 116.9/385.0 MB 1.7 MB/s eta 0:02:37\n",
      "   ------------ --------------------------- 117.0/385.0 MB 1.7 MB/s eta 0:02:37\n",
      "   ------------ --------------------------- 117.1/385.0 MB 1.7 MB/s eta 0:02:38\n",
      "   ------------ --------------------------- 117.2/385.0 MB 1.7 MB/s eta 0:02:38\n",
      "   ------------ --------------------------- 117.2/385.0 MB 1.7 MB/s eta 0:02:38\n",
      "   ------------ --------------------------- 117.3/385.0 MB 1.7 MB/s eta 0:02:38\n",
      "   ------------ --------------------------- 117.3/385.0 MB 1.7 MB/s eta 0:02:39\n",
      "   ------------ --------------------------- 117.4/385.0 MB 1.7 MB/s eta 0:02:39\n",
      "   ------------ --------------------------- 117.5/385.0 MB 1.7 MB/s eta 0:02:39\n",
      "   ------------ --------------------------- 117.6/385.0 MB 1.7 MB/s eta 0:02:39\n",
      "   ------------ --------------------------- 117.7/385.0 MB 1.7 MB/s eta 0:02:39\n",
      "   ------------ --------------------------- 117.8/385.0 MB 1.7 MB/s eta 0:02:39\n",
      "   ------------ --------------------------- 117.9/385.0 MB 1.7 MB/s eta 0:02:39\n",
      "   ------------ --------------------------- 118.0/385.0 MB 1.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 118.1/385.0 MB 1.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 118.2/385.0 MB 1.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 118.3/385.0 MB 1.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 118.4/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 118.5/385.0 MB 1.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 118.6/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 118.7/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 118.8/385.0 MB 1.7 MB/s eta 0:02:42\n",
      "   ------------ --------------------------- 118.9/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 119.0/385.0 MB 1.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 119.1/385.0 MB 1.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 119.1/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 119.3/385.0 MB 1.7 MB/s eta 0:02:40\n",
      "   ------------ --------------------------- 119.3/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 119.5/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 119.6/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 119.6/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 119.6/385.0 MB 1.7 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 119.7/385.0 MB 1.6 MB/s eta 0:02:43\n",
      "   ------------ --------------------------- 119.7/385.0 MB 1.6 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 119.8/385.0 MB 1.6 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 119.9/385.0 MB 1.6 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 120.0/385.0 MB 1.6 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 120.1/385.0 MB 1.6 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 120.2/385.0 MB 1.6 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 120.2/385.0 MB 1.6 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 120.3/385.0 MB 1.6 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 120.4/385.0 MB 1.6 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 120.5/385.0 MB 1.6 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 120.5/385.0 MB 1.6 MB/s eta 0:02:47\n",
      "   ------------ --------------------------- 120.6/385.0 MB 1.6 MB/s eta 0:02:47\n",
      "   ------------ --------------------------- 120.7/385.0 MB 1.6 MB/s eta 0:02:48\n",
      "   ------------ --------------------------- 120.8/385.0 MB 1.6 MB/s eta 0:02:48\n",
      "   ------------ --------------------------- 120.9/385.0 MB 1.6 MB/s eta 0:02:48\n",
      "   ------------ --------------------------- 120.9/385.0 MB 1.6 MB/s eta 0:02:50\n",
      "   ------------ --------------------------- 121.0/385.0 MB 1.6 MB/s eta 0:02:50\n",
      "   ------------ --------------------------- 121.1/385.0 MB 1.6 MB/s eta 0:02:50\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.6 MB/s eta 0:02:51\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.6 MB/s eta 0:02:51\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.6 MB/s eta 0:02:51\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.6 MB/s eta 0:02:51\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.6 MB/s eta 0:02:51\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.6 MB/s eta 0:02:51\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.6 MB/s eta 0:02:51\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.5 MB/s eta 0:02:58\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.5 MB/s eta 0:02:58\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.5 MB/s eta 0:02:58\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.5 MB/s eta 0:02:58\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.5 MB/s eta 0:02:58\n",
      "   ------------ --------------------------- 121.2/385.0 MB 1.5 MB/s eta 0:02:58\n",
      "   ------------ --------------------------- 121.3/385.0 MB 1.4 MB/s eta 0:03:05\n",
      "   ------------ --------------------------- 121.3/385.0 MB 1.4 MB/s eta 0:03:07\n",
      "   ------------ --------------------------- 121.3/385.0 MB 1.4 MB/s eta 0:03:07\n",
      "   ------------ --------------------------- 121.3/385.0 MB 1.4 MB/s eta 0:03:08\n",
      "   ------------ --------------------------- 121.4/385.0 MB 1.4 MB/s eta 0:03:09\n",
      "   ------------ --------------------------- 121.5/385.0 MB 1.4 MB/s eta 0:03:09\n",
      "   ------------ --------------------------- 121.5/385.0 MB 1.4 MB/s eta 0:03:10\n",
      "   ------------ --------------------------- 121.6/385.0 MB 1.4 MB/s eta 0:03:10\n",
      "   ------------ --------------------------- 121.7/385.0 MB 1.4 MB/s eta 0:03:10\n",
      "   ------------ --------------------------- 121.8/385.0 MB 1.4 MB/s eta 0:03:10\n",
      "   ------------ --------------------------- 121.9/385.0 MB 1.4 MB/s eta 0:03:11\n",
      "   ------------ --------------------------- 122.0/385.0 MB 1.4 MB/s eta 0:03:11\n",
      "   ------------ --------------------------- 122.1/385.0 MB 1.4 MB/s eta 0:03:10\n",
      "   ------------ --------------------------- 122.2/385.0 MB 1.4 MB/s eta 0:03:11\n",
      "   ------------ --------------------------- 122.3/385.0 MB 1.4 MB/s eta 0:03:03\n",
      "   ------------ --------------------------- 122.5/385.0 MB 1.5 MB/s eta 0:02:52\n",
      "   ------------ --------------------------- 122.7/385.0 MB 1.5 MB/s eta 0:02:51\n",
      "   ------------ --------------------------- 122.7/385.0 MB 1.5 MB/s eta 0:02:51\n",
      "   ------------ --------------------------- 122.9/385.0 MB 1.5 MB/s eta 0:02:50\n",
      "   ------------ --------------------------- 123.0/385.0 MB 1.5 MB/s eta 0:02:50\n",
      "   ------------ --------------------------- 123.1/385.0 MB 1.5 MB/s eta 0:02:50\n",
      "   ------------ --------------------------- 123.3/385.0 MB 1.6 MB/s eta 0:02:49\n",
      "   ------------ --------------------------- 123.5/385.0 MB 1.6 MB/s eta 0:02:47\n",
      "   ------------ --------------------------- 123.7/385.0 MB 1.6 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 123.9/385.0 MB 1.6 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 124.1/385.0 MB 1.6 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 124.3/385.0 MB 1.6 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 124.5/385.0 MB 1.6 MB/s eta 0:02:42\n",
      "   ------------ --------------------------- 124.8/385.0 MB 1.6 MB/s eta 0:02:41\n",
      "   ------------ --------------------------- 125.1/385.0 MB 1.6 MB/s eta 0:02:39\n",
      "   ------------- -------------------------- 125.3/385.0 MB 1.6 MB/s eta 0:02:38\n",
      "   ------------- -------------------------- 125.5/385.0 MB 1.7 MB/s eta 0:02:30\n",
      "   ------------- -------------------------- 125.5/385.0 MB 1.7 MB/s eta 0:02:30\n",
      "   ------------- -------------------------- 126.0/385.0 MB 1.9 MB/s eta 0:02:18\n",
      "   ------------- -------------------------- 126.1/385.0 MB 1.9 MB/s eta 0:02:16\n",
      "   ------------- -------------------------- 126.4/385.0 MB 2.0 MB/s eta 0:02:12\n",
      "   ------------- -------------------------- 126.6/385.0 MB 2.0 MB/s eta 0:02:10\n",
      "   ------------- -------------------------- 126.8/385.0 MB 2.0 MB/s eta 0:02:08\n",
      "   ------------- -------------------------- 127.0/385.0 MB 2.1 MB/s eta 0:02:05\n",
      "   ------------- -------------------------- 127.2/385.0 MB 2.1 MB/s eta 0:02:03\n",
      "   ------------- -------------------------- 127.4/385.0 MB 2.1 MB/s eta 0:02:02\n",
      "   ------------- -------------------------- 127.5/385.0 MB 2.1 MB/s eta 0:02:00\n",
      "   ------------- -------------------------- 127.8/385.0 MB 2.2 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 128.0/385.0 MB 2.2 MB/s eta 0:01:57\n",
      "   ------------- -------------------------- 128.2/385.0 MB 2.3 MB/s eta 0:01:55\n",
      "   ------------- -------------------------- 128.4/385.0 MB 2.3 MB/s eta 0:01:53\n",
      "   ------------- -------------------------- 128.6/385.0 MB 2.3 MB/s eta 0:01:51\n",
      "   ------------- -------------------------- 128.8/385.0 MB 2.3 MB/s eta 0:01:50\n",
      "   ------------- -------------------------- 129.1/385.0 MB 2.4 MB/s eta 0:01:48\n",
      "   ------------- -------------------------- 129.3/385.0 MB 2.4 MB/s eta 0:01:46\n",
      "   ------------- -------------------------- 129.5/385.0 MB 2.4 MB/s eta 0:01:45\n",
      "   ------------- -------------------------- 129.7/385.0 MB 2.5 MB/s eta 0:01:43\n",
      "   ------------- -------------------------- 130.0/385.0 MB 2.6 MB/s eta 0:01:39\n",
      "   ------------- -------------------------- 130.2/385.0 MB 2.6 MB/s eta 0:01:37\n",
      "   ------------- -------------------------- 130.4/385.0 MB 2.7 MB/s eta 0:01:36\n",
      "   ------------- -------------------------- 130.5/385.0 MB 2.7 MB/s eta 0:01:34\n",
      "   ------------- -------------------------- 130.8/385.0 MB 2.8 MB/s eta 0:01:31\n",
      "   ------------- -------------------------- 130.9/385.0 MB 2.8 MB/s eta 0:01:30\n",
      "   ------------- -------------------------- 131.3/385.0 MB 3.0 MB/s eta 0:01:26\n",
      "   ------------- -------------------------- 131.5/385.0 MB 3.8 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 131.8/385.0 MB 4.0 MB/s eta 0:01:04\n",
      "   ------------- -------------------------- 132.0/385.0 MB 4.1 MB/s eta 0:01:02\n",
      "   ------------- -------------------------- 132.3/385.0 MB 4.3 MB/s eta 0:01:00\n",
      "   ------------- -------------------------- 132.6/385.0 MB 4.4 MB/s eta 0:00:58\n",
      "   ------------- -------------------------- 132.8/385.0 MB 4.5 MB/s eta 0:00:57\n",
      "   ------------- -------------------------- 133.0/385.0 MB 4.5 MB/s eta 0:00:56\n",
      "   ------------- -------------------------- 133.3/385.0 MB 4.6 MB/s eta 0:00:55\n",
      "   ------------- -------------------------- 133.5/385.0 MB 4.7 MB/s eta 0:00:54\n",
      "   ------------- -------------------------- 133.7/385.0 MB 4.6 MB/s eta 0:00:55\n",
      "   ------------- -------------------------- 133.9/385.0 MB 4.6 MB/s eta 0:00:55\n",
      "   ------------- -------------------------- 134.0/385.0 MB 4.6 MB/s eta 0:00:55\n",
      "   ------------- -------------------------- 134.0/385.0 MB 4.6 MB/s eta 0:00:55\n",
      "   ------------- -------------------------- 134.3/385.0 MB 4.6 MB/s eta 0:00:55\n",
      "   ------------- -------------------------- 134.4/385.0 MB 4.5 MB/s eta 0:00:56\n",
      "   ------------- -------------------------- 134.6/385.0 MB 4.5 MB/s eta 0:00:56\n",
      "   ------------- -------------------------- 134.8/385.0 MB 4.5 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 134.9/385.0 MB 4.5 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 135.0/385.0 MB 4.4 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 135.2/385.0 MB 4.4 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 135.4/385.0 MB 4.4 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 135.6/385.0 MB 4.3 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 135.8/385.0 MB 4.4 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 136.0/385.0 MB 4.4 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 136.1/385.0 MB 4.3 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 136.3/385.0 MB 4.3 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 136.5/385.0 MB 4.3 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 136.7/385.0 MB 4.3 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 136.8/385.0 MB 4.2 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 137.0/385.0 MB 4.2 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 137.2/385.0 MB 4.2 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 137.2/385.0 MB 4.2 MB/s eta 0:01:00\n",
      "   -------------- ------------------------- 137.2/385.0 MB 4.1 MB/s eta 0:01:01\n",
      "   -------------- ------------------------- 137.6/385.0 MB 4.1 MB/s eta 0:01:00\n",
      "   -------------- ------------------------- 137.7/385.0 MB 4.1 MB/s eta 0:01:00\n",
      "   -------------- ------------------------- 137.9/385.0 MB 4.1 MB/s eta 0:01:01\n",
      "   -------------- ------------------------- 138.1/385.0 MB 4.1 MB/s eta 0:01:01\n",
      "   -------------- ------------------------- 138.2/385.0 MB 4.1 MB/s eta 0:01:01\n",
      "   -------------- ------------------------- 138.3/385.0 MB 4.0 MB/s eta 0:01:02\n",
      "   -------------- ------------------------- 138.3/385.0 MB 4.0 MB/s eta 0:01:02\n",
      "   -------------- ------------------------- 138.3/385.0 MB 4.0 MB/s eta 0:01:02\n",
      "   -------------- ------------------------- 138.3/385.0 MB 4.0 MB/s eta 0:01:02\n",
      "   -------------- ------------------------- 138.3/385.0 MB 4.0 MB/s eta 0:01:02\n",
      "   -------------- ------------------------- 138.3/385.0 MB 4.0 MB/s eta 0:01:02\n",
      "   -------------- ------------------------- 138.3/385.0 MB 3.6 MB/s eta 0:01:08\n",
      "   -------------- ------------------------- 138.4/385.0 MB 3.6 MB/s eta 0:01:08\n",
      "   -------------- ------------------------- 138.4/385.0 MB 3.6 MB/s eta 0:01:08\n",
      "   -------------- ------------------------- 138.5/385.0 MB 3.5 MB/s eta 0:01:11\n",
      "   -------------- ------------------------- 138.6/385.0 MB 3.5 MB/s eta 0:01:12\n",
      "   -------------- ------------------------- 138.7/385.0 MB 3.4 MB/s eta 0:01:12\n",
      "   -------------- ------------------------- 138.8/385.0 MB 3.4 MB/s eta 0:01:13\n",
      "   -------------- ------------------------- 138.8/385.0 MB 3.4 MB/s eta 0:01:13\n",
      "   -------------- ------------------------- 139.0/385.0 MB 3.4 MB/s eta 0:01:14\n",
      "   -------------- ------------------------- 139.0/385.0 MB 3.3 MB/s eta 0:01:15\n",
      "   -------------- ------------------------- 139.1/385.0 MB 3.3 MB/s eta 0:01:15\n",
      "   -------------- ------------------------- 139.2/385.0 MB 3.2 MB/s eta 0:01:16\n",
      "   -------------- ------------------------- 139.2/385.0 MB 3.2 MB/s eta 0:01:16\n",
      "   -------------- ------------------------- 139.3/385.0 MB 3.2 MB/s eta 0:01:17\n",
      "   -------------- ------------------------- 139.4/385.0 MB 3.1 MB/s eta 0:01:19\n",
      "   -------------- ------------------------- 139.5/385.0 MB 3.1 MB/s eta 0:01:19\n",
      "   -------------- ------------------------- 139.6/385.0 MB 3.1 MB/s eta 0:01:20\n",
      "   -------------- ------------------------- 139.7/385.0 MB 3.1 MB/s eta 0:01:21\n",
      "   -------------- ------------------------- 139.7/385.0 MB 3.0 MB/s eta 0:01:22\n",
      "   -------------- ------------------------- 139.8/385.0 MB 3.0 MB/s eta 0:01:22\n",
      "   -------------- ------------------------- 139.9/385.0 MB 3.0 MB/s eta 0:01:23\n",
      "   -------------- ------------------------- 140.0/385.0 MB 2.9 MB/s eta 0:01:24\n",
      "   -------------- ------------------------- 140.0/385.0 MB 2.9 MB/s eta 0:01:24\n",
      "   -------------- ------------------------- 140.1/385.0 MB 2.9 MB/s eta 0:01:25\n",
      "   -------------- ------------------------- 140.2/385.0 MB 2.9 MB/s eta 0:01:26\n",
      "   -------------- ------------------------- 140.3/385.0 MB 2.9 MB/s eta 0:01:26\n",
      "   -------------- ------------------------- 140.4/385.0 MB 2.8 MB/s eta 0:01:27\n",
      "   -------------- ------------------------- 140.5/385.0 MB 2.8 MB/s eta 0:01:28\n",
      "   -------------- ------------------------- 140.6/385.0 MB 2.8 MB/s eta 0:01:28\n",
      "   -------------- ------------------------- 140.7/385.0 MB 2.8 MB/s eta 0:01:29\n",
      "   -------------- ------------------------- 140.8/385.0 MB 2.7 MB/s eta 0:01:30\n",
      "   -------------- ------------------------- 140.8/385.0 MB 2.7 MB/s eta 0:01:30\n",
      "   -------------- ------------------------- 140.9/385.0 MB 2.7 MB/s eta 0:01:30\n",
      "   -------------- ------------------------- 141.0/385.0 MB 2.7 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 141.1/385.0 MB 2.7 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 141.2/385.0 MB 2.7 MB/s eta 0:01:32\n",
      "   -------------- ------------------------- 141.3/385.0 MB 2.6 MB/s eta 0:01:33\n",
      "   -------------- ------------------------- 141.3/385.0 MB 2.6 MB/s eta 0:01:34\n",
      "   -------------- ------------------------- 141.3/385.0 MB 2.6 MB/s eta 0:01:34\n",
      "   -------------- ------------------------- 141.3/385.0 MB 2.6 MB/s eta 0:01:34\n",
      "   -------------- ------------------------- 141.3/385.0 MB 2.6 MB/s eta 0:01:34\n",
      "   -------------- ------------------------- 141.3/385.0 MB 2.6 MB/s eta 0:01:34\n",
      "   -------------- ------------------------- 141.3/385.0 MB 2.6 MB/s eta 0:01:34\n",
      "   -------------- ------------------------- 141.3/385.0 MB 2.6 MB/s eta 0:01:34\n",
      "   -------------- ------------------------- 141.4/385.0 MB 2.4 MB/s eta 0:01:41\n",
      "   -------------- ------------------------- 141.4/385.0 MB 2.4 MB/s eta 0:01:41\n",
      "   -------------- ------------------------- 141.5/385.0 MB 2.4 MB/s eta 0:01:43\n",
      "   -------------- ------------------------- 141.5/385.0 MB 2.4 MB/s eta 0:01:44\n",
      "   -------------- ------------------------- 141.6/385.0 MB 2.3 MB/s eta 0:01:45\n",
      "   -------------- ------------------------- 141.7/385.0 MB 2.3 MB/s eta 0:01:46\n",
      "   -------------- ------------------------- 141.8/385.0 MB 2.3 MB/s eta 0:01:46\n",
      "   -------------- ------------------------- 141.9/385.0 MB 2.3 MB/s eta 0:01:47\n",
      "   -------------- ------------------------- 141.9/385.0 MB 2.2 MB/s eta 0:01:49\n",
      "   -------------- ------------------------- 142.0/385.0 MB 2.2 MB/s eta 0:01:49\n",
      "   -------------- ------------------------- 142.1/385.0 MB 2.2 MB/s eta 0:01:50\n",
      "   -------------- ------------------------- 142.2/385.0 MB 2.2 MB/s eta 0:01:50\n",
      "   -------------- ------------------------- 142.2/385.0 MB 2.2 MB/s eta 0:01:51\n",
      "   -------------- ------------------------- 142.3/385.0 MB 2.2 MB/s eta 0:01:52\n",
      "   -------------- ------------------------- 142.4/385.0 MB 2.2 MB/s eta 0:01:53\n",
      "   -------------- ------------------------- 142.4/385.0 MB 2.1 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 142.5/385.0 MB 2.1 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 142.6/385.0 MB 2.1 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 142.7/385.0 MB 2.1 MB/s eta 0:01:56\n",
      "   -------------- ------------------------- 142.7/385.0 MB 2.1 MB/s eta 0:01:56\n",
      "   -------------- ------------------------- 142.8/385.0 MB 2.1 MB/s eta 0:01:57\n",
      "   -------------- ------------------------- 142.9/385.0 MB 2.1 MB/s eta 0:01:58\n",
      "   -------------- ------------------------- 143.0/385.0 MB 2.0 MB/s eta 0:01:59\n",
      "   -------------- ------------------------- 143.1/385.0 MB 2.0 MB/s eta 0:02:00\n",
      "   -------------- ------------------------- 143.1/385.0 MB 2.0 MB/s eta 0:02:00\n",
      "   -------------- ------------------------- 143.2/385.0 MB 2.0 MB/s eta 0:02:00\n",
      "   -------------- ------------------------- 143.3/385.0 MB 2.0 MB/s eta 0:02:01\n",
      "   -------------- ------------------------- 143.4/385.0 MB 2.0 MB/s eta 0:02:02\n",
      "   -------------- ------------------------- 143.5/385.0 MB 2.0 MB/s eta 0:02:02\n",
      "   -------------- ------------------------- 143.6/385.0 MB 2.0 MB/s eta 0:02:03\n",
      "   -------------- ------------------------- 143.7/385.0 MB 2.0 MB/s eta 0:02:04\n",
      "   -------------- ------------------------- 143.8/385.0 MB 1.9 MB/s eta 0:02:04\n",
      "   -------------- ------------------------- 143.9/385.0 MB 1.9 MB/s eta 0:02:05\n",
      "   -------------- ------------------------- 144.0/385.0 MB 1.9 MB/s eta 0:02:06\n",
      "   -------------- ------------------------- 144.0/385.0 MB 1.9 MB/s eta 0:02:06\n",
      "   -------------- ------------------------- 144.1/385.0 MB 1.9 MB/s eta 0:02:06\n",
      "   -------------- ------------------------- 144.2/385.0 MB 1.9 MB/s eta 0:02:07\n",
      "   -------------- ------------------------- 144.3/385.0 MB 1.9 MB/s eta 0:02:06\n",
      "   -------------- ------------------------- 144.4/385.0 MB 1.9 MB/s eta 0:02:07\n",
      "   --------------- ------------------------ 144.5/385.0 MB 1.9 MB/s eta 0:02:07\n",
      "   --------------- ------------------------ 144.5/385.0 MB 1.9 MB/s eta 0:02:08\n",
      "   --------------- ------------------------ 144.6/385.0 MB 1.9 MB/s eta 0:02:09\n",
      "   --------------- ------------------------ 144.8/385.0 MB 1.9 MB/s eta 0:02:09\n",
      "   --------------- ------------------------ 144.8/385.0 MB 1.9 MB/s eta 0:02:09\n",
      "   --------------- ------------------------ 144.9/385.0 MB 1.9 MB/s eta 0:02:10\n",
      "   --------------- ------------------------ 145.1/385.0 MB 1.8 MB/s eta 0:02:10\n",
      "   --------------- ------------------------ 145.2/385.0 MB 1.8 MB/s eta 0:02:11\n",
      "   --------------- ------------------------ 145.2/385.0 MB 1.8 MB/s eta 0:02:11\n",
      "   --------------- ------------------------ 145.3/385.0 MB 1.8 MB/s eta 0:02:11\n",
      "   --------------- ------------------------ 145.4/385.0 MB 1.8 MB/s eta 0:02:12\n",
      "   --------------- ------------------------ 145.5/385.0 MB 1.8 MB/s eta 0:02:13\n",
      "   --------------- ------------------------ 145.6/385.0 MB 1.8 MB/s eta 0:02:13\n",
      "   --------------- ------------------------ 145.7/385.0 MB 1.8 MB/s eta 0:02:13\n",
      "   --------------- ------------------------ 145.8/385.0 MB 1.8 MB/s eta 0:02:14\n",
      "   --------------- ------------------------ 145.9/385.0 MB 1.8 MB/s eta 0:02:14\n",
      "   --------------- ------------------------ 146.0/385.0 MB 1.8 MB/s eta 0:02:15\n",
      "   --------------- ------------------------ 146.1/385.0 MB 1.8 MB/s eta 0:02:15\n",
      "   --------------- ------------------------ 146.2/385.0 MB 1.8 MB/s eta 0:02:16\n",
      "   --------------- ------------------------ 146.2/385.0 MB 1.8 MB/s eta 0:02:16\n",
      "   --------------- ------------------------ 146.2/385.0 MB 1.8 MB/s eta 0:02:16\n",
      "   --------------- ------------------------ 146.2/385.0 MB 1.8 MB/s eta 0:02:16\n",
      "   --------------- ------------------------ 146.2/385.0 MB 1.8 MB/s eta 0:02:16\n",
      "   --------------- ------------------------ 146.2/385.0 MB 1.8 MB/s eta 0:02:16\n",
      "   --------------- ------------------------ 146.2/385.0 MB 1.8 MB/s eta 0:02:16\n",
      "   --------------- ------------------------ 146.3/385.0 MB 1.7 MB/s eta 0:02:22\n",
      "   --------------- ------------------------ 146.3/385.0 MB 1.7 MB/s eta 0:02:22\n",
      "   --------------- ------------------------ 146.3/385.0 MB 1.7 MB/s eta 0:02:22\n",
      "   --------------- ------------------------ 146.4/385.0 MB 1.6 MB/s eta 0:02:26\n",
      "   --------------- ------------------------ 146.4/385.0 MB 1.6 MB/s eta 0:02:27\n",
      "   --------------- ------------------------ 146.5/385.0 MB 1.6 MB/s eta 0:02:27\n",
      "   --------------- ------------------------ 146.6/385.0 MB 1.6 MB/s eta 0:02:27\n",
      "   --------------- ------------------------ 146.6/385.0 MB 1.6 MB/s eta 0:02:28\n",
      "   --------------- ------------------------ 146.6/385.0 MB 1.6 MB/s eta 0:02:30\n",
      "   --------------- ------------------------ 146.7/385.0 MB 1.6 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 146.7/385.0 MB 1.6 MB/s eta 0:02:30\n",
      "   --------------- ------------------------ 146.8/385.0 MB 1.6 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 146.9/385.0 MB 1.6 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 146.9/385.0 MB 1.6 MB/s eta 0:02:33\n",
      "   --------------- ------------------------ 147.0/385.0 MB 1.6 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 147.0/385.0 MB 1.6 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 147.1/385.0 MB 1.5 MB/s eta 0:02:35\n",
      "   --------------- ------------------------ 147.2/385.0 MB 1.5 MB/s eta 0:02:35\n",
      "   --------------- ------------------------ 147.3/385.0 MB 1.5 MB/s eta 0:02:36\n",
      "   --------------- ------------------------ 147.4/385.0 MB 1.5 MB/s eta 0:02:37\n",
      "   --------------- ------------------------ 147.4/385.0 MB 1.5 MB/s eta 0:02:37\n",
      "   --------------- ------------------------ 147.5/385.0 MB 1.5 MB/s eta 0:02:36\n",
      "   --------------- ------------------------ 147.5/385.0 MB 1.5 MB/s eta 0:02:37\n",
      "   --------------- ------------------------ 147.6/385.0 MB 1.5 MB/s eta 0:02:37\n",
      "   --------------- ------------------------ 147.6/385.0 MB 1.5 MB/s eta 0:02:38\n",
      "   --------------- ------------------------ 147.7/385.0 MB 1.5 MB/s eta 0:02:40\n",
      "   --------------- ------------------------ 147.8/385.0 MB 1.5 MB/s eta 0:02:40\n",
      "   --------------- ------------------------ 147.9/385.0 MB 1.5 MB/s eta 0:02:41\n",
      "   --------------- ------------------------ 147.9/385.0 MB 1.5 MB/s eta 0:02:42\n",
      "   --------------- ------------------------ 148.0/385.0 MB 1.5 MB/s eta 0:02:42\n",
      "   --------------- ------------------------ 148.1/385.0 MB 1.5 MB/s eta 0:02:43\n",
      "   --------------- ------------------------ 148.1/385.0 MB 1.5 MB/s eta 0:02:43\n",
      "   --------------- ------------------------ 148.2/385.0 MB 1.5 MB/s eta 0:02:44\n",
      "   --------------- ------------------------ 148.3/385.0 MB 1.4 MB/s eta 0:02:44\n",
      "   --------------- ------------------------ 148.4/385.0 MB 1.4 MB/s eta 0:02:44\n",
      "   --------------- ------------------------ 148.5/385.0 MB 1.4 MB/s eta 0:02:45\n",
      "   --------------- ------------------------ 148.5/385.0 MB 1.5 MB/s eta 0:02:39\n",
      "   --------------- ------------------------ 148.6/385.0 MB 1.5 MB/s eta 0:02:37\n",
      "   --------------- ------------------------ 148.7/385.0 MB 1.5 MB/s eta 0:02:38\n",
      "   --------------- ------------------------ 148.8/385.0 MB 1.5 MB/s eta 0:02:37\n",
      "   --------------- ------------------------ 148.9/385.0 MB 1.5 MB/s eta 0:02:38\n",
      "   --------------- ------------------------ 149.0/385.0 MB 1.5 MB/s eta 0:02:38\n",
      "   --------------- ------------------------ 149.1/385.0 MB 1.5 MB/s eta 0:02:37\n",
      "   --------------- ------------------------ 149.2/385.0 MB 1.5 MB/s eta 0:02:37\n",
      "   --------------- ------------------------ 149.3/385.0 MB 1.5 MB/s eta 0:02:36\n",
      "   --------------- ------------------------ 149.4/385.0 MB 1.5 MB/s eta 0:02:36\n",
      "   --------------- ------------------------ 149.5/385.0 MB 1.5 MB/s eta 0:02:35\n",
      "   --------------- ------------------------ 149.6/385.0 MB 1.5 MB/s eta 0:02:35\n",
      "   --------------- ------------------------ 149.7/385.0 MB 1.5 MB/s eta 0:02:35\n",
      "   --------------- ------------------------ 149.9/385.0 MB 1.5 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 149.9/385.0 MB 1.5 MB/s eta 0:02:34\n",
      "   --------------- ------------------------ 150.0/385.0 MB 1.5 MB/s eta 0:02:33\n",
      "   --------------- ------------------------ 150.2/385.0 MB 1.5 MB/s eta 0:02:33\n",
      "   --------------- ------------------------ 150.3/385.0 MB 1.5 MB/s eta 0:02:33\n",
      "   --------------- ------------------------ 150.4/385.0 MB 1.6 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 150.4/385.0 MB 1.6 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 150.5/385.0 MB 1.6 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 150.6/385.0 MB 1.6 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 150.7/385.0 MB 1.5 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 150.8/385.0 MB 1.5 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 150.9/385.0 MB 1.5 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 151.0/385.0 MB 1.5 MB/s eta 0:02:32\n",
      "   --------------- ------------------------ 151.1/385.0 MB 1.6 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 151.2/385.0 MB 1.6 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 151.3/385.0 MB 1.6 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 151.3/385.0 MB 1.6 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 151.4/385.0 MB 1.6 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 151.5/385.0 MB 1.6 MB/s eta 0:02:31\n",
      "   --------------- ------------------------ 151.6/385.0 MB 1.6 MB/s eta 0:02:25\n",
      "   --------------- ------------------------ 151.7/385.0 MB 1.6 MB/s eta 0:02:23\n",
      "   --------------- ------------------------ 151.8/385.0 MB 1.6 MB/s eta 0:02:23\n",
      "   --------------- ------------------------ 151.9/385.0 MB 1.6 MB/s eta 0:02:22\n",
      "   --------------- ------------------------ 152.0/385.0 MB 1.7 MB/s eta 0:02:21\n",
      "   --------------- ------------------------ 152.0/385.0 MB 1.7 MB/s eta 0:02:21\n",
      "   --------------- ------------------------ 152.2/385.0 MB 1.7 MB/s eta 0:02:21\n",
      "   --------------- ------------------------ 152.2/385.0 MB 1.7 MB/s eta 0:02:21\n",
      "   --------------- ------------------------ 152.4/385.0 MB 1.7 MB/s eta 0:02:21\n",
      "   --------------- ------------------------ 152.5/385.0 MB 1.7 MB/s eta 0:02:20\n",
      "   --------------- ------------------------ 152.6/385.0 MB 1.7 MB/s eta 0:02:20\n",
      "   --------------- ------------------------ 152.6/385.0 MB 1.7 MB/s eta 0:02:19\n",
      "   --------------- ------------------------ 152.8/385.0 MB 1.7 MB/s eta 0:02:19\n",
      "   --------------- ------------------------ 152.8/385.0 MB 1.7 MB/s eta 0:02:19\n",
      "   --------------- ------------------------ 152.9/385.0 MB 1.7 MB/s eta 0:02:18\n",
      "   --------------- ------------------------ 153.0/385.0 MB 1.7 MB/s eta 0:02:18\n",
      "   --------------- ------------------------ 153.1/385.0 MB 1.7 MB/s eta 0:02:17\n",
      "   --------------- ------------------------ 153.2/385.0 MB 1.7 MB/s eta 0:02:17\n",
      "   --------------- ------------------------ 153.3/385.0 MB 1.7 MB/s eta 0:02:17\n",
      "   --------------- ------------------------ 153.3/385.0 MB 1.7 MB/s eta 0:02:18\n",
      "   --------------- ------------------------ 153.4/385.0 MB 1.7 MB/s eta 0:02:17\n",
      "   --------------- ------------------------ 153.5/385.0 MB 1.7 MB/s eta 0:02:18\n",
      "   --------------- ------------------------ 153.7/385.0 MB 1.7 MB/s eta 0:02:17\n",
      "   --------------- ------------------------ 153.7/385.0 MB 1.7 MB/s eta 0:02:16\n",
      "   --------------- ------------------------ 153.9/385.0 MB 1.7 MB/s eta 0:02:17\n",
      "   --------------- ------------------------ 153.9/385.0 MB 1.7 MB/s eta 0:02:17\n",
      "   --------------- ------------------------ 154.0/385.0 MB 1.7 MB/s eta 0:02:18\n",
      "   ---------------- ----------------------- 154.1/385.0 MB 1.7 MB/s eta 0:02:17\n",
      "   ---------------- ----------------------- 154.2/385.0 MB 1.7 MB/s eta 0:02:16\n",
      "   ---------------- ----------------------- 154.3/385.0 MB 1.7 MB/s eta 0:02:16\n",
      "   ---------------- ----------------------- 154.3/385.0 MB 1.7 MB/s eta 0:02:17\n",
      "   ---------------- ----------------------- 154.5/385.0 MB 1.7 MB/s eta 0:02:16\n",
      "   ---------------- ----------------------- 154.6/385.0 MB 1.7 MB/s eta 0:02:16\n",
      "   ---------------- ----------------------- 154.7/385.0 MB 1.7 MB/s eta 0:02:15\n",
      "   ---------------- ----------------------- 154.8/385.0 MB 1.7 MB/s eta 0:02:15\n",
      "   ---------------- ----------------------- 154.9/385.0 MB 1.7 MB/s eta 0:02:15\n",
      "   ---------------- ----------------------- 155.0/385.0 MB 1.7 MB/s eta 0:02:15\n",
      "   ---------------- ----------------------- 155.1/385.0 MB 1.7 MB/s eta 0:02:15\n",
      "   ---------------- ----------------------- 155.2/385.0 MB 1.7 MB/s eta 0:02:15\n",
      "   ---------------- ----------------------- 155.3/385.0 MB 1.7 MB/s eta 0:02:15\n",
      "   ---------------- ----------------------- 155.4/385.0 MB 1.7 MB/s eta 0:02:14\n",
      "   ---------------- ----------------------- 155.5/385.0 MB 1.7 MB/s eta 0:02:14\n",
      "   ---------------- ----------------------- 155.6/385.0 MB 1.7 MB/s eta 0:02:14\n",
      "   ---------------- ----------------------- 155.7/385.0 MB 1.7 MB/s eta 0:02:14\n",
      "   ---------------- ----------------------- 155.8/385.0 MB 1.7 MB/s eta 0:02:14\n",
      "   ---------------- ----------------------- 155.9/385.0 MB 1.7 MB/s eta 0:02:13\n",
      "   ---------------- ----------------------- 156.0/385.0 MB 1.7 MB/s eta 0:02:13\n",
      "   ---------------- ----------------------- 156.2/385.0 MB 1.7 MB/s eta 0:02:13\n",
      "   ---------------- ----------------------- 156.3/385.0 MB 1.7 MB/s eta 0:02:13\n",
      "   ---------------- ----------------------- 156.4/385.0 MB 1.7 MB/s eta 0:02:12\n",
      "   ---------------- ----------------------- 156.5/385.0 MB 1.9 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 156.7/385.0 MB 1.9 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 156.8/385.0 MB 1.9 MB/s eta 0:02:01\n",
      "   ---------------- ----------------------- 156.9/385.0 MB 1.9 MB/s eta 0:01:59\n",
      "   ---------------- ----------------------- 157.0/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 157.1/385.0 MB 2.0 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 157.1/385.0 MB 2.0 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 157.1/385.0 MB 2.0 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 157.1/385.0 MB 2.0 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 157.1/385.0 MB 2.0 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 157.1/385.0 MB 2.0 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 157.1/385.0 MB 2.0 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 157.3/385.0 MB 1.9 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 157.3/385.0 MB 1.9 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 157.3/385.0 MB 1.8 MB/s eta 0:02:04\n",
      "   ---------------- ----------------------- 157.4/385.0 MB 1.9 MB/s eta 0:02:03\n",
      "   ---------------- ----------------------- 157.5/385.0 MB 1.9 MB/s eta 0:02:03\n",
      "   ---------------- ----------------------- 157.6/385.0 MB 1.9 MB/s eta 0:02:03\n",
      "   ---------------- ----------------------- 157.6/385.0 MB 1.9 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 157.7/385.0 MB 1.9 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 157.8/385.0 MB 1.9 MB/s eta 0:02:01\n",
      "   ---------------- ----------------------- 157.8/385.0 MB 1.9 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 157.9/385.0 MB 1.9 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 158.0/385.0 MB 1.9 MB/s eta 0:02:01\n",
      "   ---------------- ----------------------- 158.1/385.0 MB 1.9 MB/s eta 0:02:01\n",
      "   ---------------- ----------------------- 158.2/385.0 MB 1.9 MB/s eta 0:02:00\n",
      "   ---------------- ----------------------- 158.3/385.0 MB 1.9 MB/s eta 0:02:00\n",
      "   ---------------- ----------------------- 158.4/385.0 MB 1.9 MB/s eta 0:02:00\n",
      "   ---------------- ----------------------- 158.5/385.0 MB 1.9 MB/s eta 0:02:00\n",
      "   ---------------- ----------------------- 158.6/385.0 MB 1.9 MB/s eta 0:01:59\n",
      "   ---------------- ----------------------- 158.7/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 158.8/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 158.9/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 159.0/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 159.1/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 159.2/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 159.3/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 159.4/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 159.5/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 159.6/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 159.7/385.0 MB 1.9 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 159.8/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 159.9/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 160.0/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 160.1/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 160.2/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 160.3/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 160.4/385.0 MB 1.9 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 160.5/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 160.6/385.0 MB 1.9 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 160.7/385.0 MB 1.9 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 160.8/385.0 MB 1.9 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 161.0/385.0 MB 2.0 MB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 161.1/385.0 MB 1.9 MB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 161.2/385.0 MB 2.0 MB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 161.3/385.0 MB 2.0 MB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 161.5/385.0 MB 2.0 MB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 161.6/385.0 MB 2.0 MB/s eta 0:01:53\n",
      "   ---------------- ----------------------- 161.7/385.0 MB 2.0 MB/s eta 0:01:53\n",
      "   ---------------- ----------------------- 161.8/385.0 MB 2.0 MB/s eta 0:01:52\n",
      "   ---------------- ----------------------- 162.0/385.0 MB 2.0 MB/s eta 0:01:52\n",
      "   ---------------- ----------------------- 162.1/385.0 MB 2.0 MB/s eta 0:01:52\n",
      "   ---------------- ----------------------- 162.2/385.0 MB 2.0 MB/s eta 0:01:51\n",
      "   ---------------- ----------------------- 162.3/385.0 MB 2.0 MB/s eta 0:01:51\n",
      "   ---------------- ----------------------- 162.5/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ---------------- ----------------------- 162.6/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ---------------- ----------------------- 162.7/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ---------------- ----------------------- 162.8/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ---------------- ----------------------- 163.0/385.0 MB 2.1 MB/s eta 0:01:49\n",
      "   ---------------- ----------------------- 163.1/385.0 MB 2.1 MB/s eta 0:01:48\n",
      "   ---------------- ----------------------- 163.2/385.0 MB 2.1 MB/s eta 0:01:48\n",
      "   ---------------- ----------------------- 163.4/385.0 MB 2.1 MB/s eta 0:01:47\n",
      "   ---------------- ----------------------- 163.5/385.0 MB 2.1 MB/s eta 0:01:47\n",
      "   ---------------- ----------------------- 163.6/385.0 MB 2.1 MB/s eta 0:01:46\n",
      "   ----------------- ---------------------- 163.7/385.0 MB 2.1 MB/s eta 0:01:46\n",
      "   ----------------- ---------------------- 163.8/385.0 MB 2.1 MB/s eta 0:01:45\n",
      "   ----------------- ---------------------- 164.0/385.0 MB 2.1 MB/s eta 0:01:46\n",
      "   ----------------- ---------------------- 164.0/385.0 MB 2.1 MB/s eta 0:01:45\n",
      "   ----------------- ---------------------- 164.1/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 164.3/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 164.5/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 164.6/385.0 MB 2.2 MB/s eta 0:01:42\n",
      "   ----------------- ---------------------- 164.7/385.0 MB 2.2 MB/s eta 0:01:42\n",
      "   ----------------- ---------------------- 164.9/385.0 MB 2.2 MB/s eta 0:01:42\n",
      "   ----------------- ---------------------- 165.0/385.0 MB 2.2 MB/s eta 0:01:41\n",
      "   ----------------- ---------------------- 165.2/385.0 MB 2.2 MB/s eta 0:01:41\n",
      "   ----------------- ---------------------- 165.3/385.0 MB 2.2 MB/s eta 0:01:41\n",
      "   ----------------- ---------------------- 165.5/385.0 MB 2.2 MB/s eta 0:01:40\n",
      "   ----------------- ---------------------- 165.6/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 165.8/385.0 MB 2.2 MB/s eta 0:01:38\n",
      "   ----------------- ---------------------- 165.9/385.0 MB 2.3 MB/s eta 0:01:38\n",
      "   ----------------- ---------------------- 166.1/385.0 MB 2.3 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 166.2/385.0 MB 2.3 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 166.2/385.0 MB 2.3 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 166.2/385.0 MB 2.3 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 166.2/385.0 MB 2.3 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 166.2/385.0 MB 2.3 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 166.2/385.0 MB 2.3 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 166.2/385.0 MB 2.3 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 166.3/385.0 MB 2.1 MB/s eta 0:01:43\n",
      "   ----------------- ---------------------- 166.3/385.0 MB 2.1 MB/s eta 0:01:43\n",
      "   ----------------- ---------------------- 166.3/385.0 MB 2.1 MB/s eta 0:01:43\n",
      "   ----------------- ---------------------- 166.3/385.0 MB 2.1 MB/s eta 0:01:43\n",
      "   ----------------- ---------------------- 166.3/385.0 MB 2.1 MB/s eta 0:01:43\n",
      "   ----------------- ---------------------- 166.3/385.0 MB 2.1 MB/s eta 0:01:43\n",
      "   ----------------- ---------------------- 166.3/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 166.3/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 166.4/385.0 MB 2.0 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 166.5/385.0 MB 2.0 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 166.6/385.0 MB 2.0 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 166.7/385.0 MB 2.0 MB/s eta 0:01:52\n",
      "   ----------------- ---------------------- 166.8/385.0 MB 2.0 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 166.9/385.0 MB 2.0 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 167.0/385.0 MB 2.0 MB/s eta 0:01:52\n",
      "   ----------------- ---------------------- 167.1/385.0 MB 2.0 MB/s eta 0:01:52\n",
      "   ----------------- ---------------------- 167.2/385.0 MB 2.0 MB/s eta 0:01:52\n",
      "   ----------------- ---------------------- 167.3/385.0 MB 2.0 MB/s eta 0:01:52\n",
      "   ----------------- ---------------------- 167.4/385.0 MB 2.1 MB/s eta 0:01:46\n",
      "   ----------------- ---------------------- 167.5/385.0 MB 2.1 MB/s eta 0:01:43\n",
      "   ----------------- ---------------------- 167.6/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 167.7/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 167.8/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 167.9/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 168.1/385.0 MB 2.1 MB/s eta 0:01:42\n",
      "   ----------------- ---------------------- 168.2/385.0 MB 2.1 MB/s eta 0:01:42\n",
      "   ----------------- ---------------------- 168.3/385.0 MB 2.1 MB/s eta 0:01:42\n",
      "   ----------------- ---------------------- 168.4/385.0 MB 2.1 MB/s eta 0:01:42\n",
      "   ----------------- ---------------------- 168.5/385.0 MB 2.1 MB/s eta 0:01:42\n",
      "   ----------------- ---------------------- 168.6/385.0 MB 2.1 MB/s eta 0:01:41\n",
      "   ----------------- ---------------------- 168.7/385.0 MB 2.2 MB/s eta 0:01:41\n",
      "   ----------------- ---------------------- 168.8/385.0 MB 2.2 MB/s eta 0:01:41\n",
      "   ----------------- ---------------------- 169.0/385.0 MB 2.2 MB/s eta 0:01:40\n",
      "   ----------------- ---------------------- 169.2/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 169.3/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 169.4/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 169.5/385.0 MB 2.2 MB/s eta 0:01:38\n",
      "   ----------------- ---------------------- 169.5/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 169.5/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 169.5/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 169.5/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 169.5/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 169.5/385.0 MB 2.2 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 169.6/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 169.6/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 169.6/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 169.6/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 169.6/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 169.6/385.0 MB 2.1 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 169.7/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 169.7/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 169.8/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 169.9/385.0 MB 1.9 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 170.0/385.0 MB 1.9 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 170.1/385.0 MB 1.9 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 170.2/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 170.3/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 170.4/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 170.5/385.0 MB 1.9 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 170.6/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 170.8/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 170.9/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 171.0/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 171.1/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 171.3/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 171.4/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 171.5/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 171.6/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 171.8/385.0 MB 2.0 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 171.9/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 172.0/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 172.1/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 172.2/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 172.3/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 172.5/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 172.6/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 172.7/385.0 MB 1.9 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 172.8/385.0 MB 2.0 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 172.9/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ----------------- ---------------------- 173.0/385.0 MB 1.9 MB/s eta 0:01:50\n",
      "   ----------------- ---------------------- 173.2/385.0 MB 1.9 MB/s eta 0:01:50\n",
      "   ------------------ --------------------- 173.3/385.0 MB 1.9 MB/s eta 0:01:50\n",
      "   ------------------ --------------------- 173.4/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 173.5/385.0 MB 1.9 MB/s eta 0:01:50\n",
      "   ------------------ --------------------- 173.7/385.0 MB 1.9 MB/s eta 0:01:50\n",
      "   ------------------ --------------------- 173.8/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 173.9/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 174.0/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 174.2/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 174.3/385.0 MB 2.0 MB/s eta 0:01:48\n",
      "   ------------------ --------------------- 174.4/385.0 MB 2.0 MB/s eta 0:01:48\n",
      "   ------------------ --------------------- 174.5/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 174.7/385.0 MB 1.9 MB/s eta 0:01:48\n",
      "   ------------------ --------------------- 174.8/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 175.0/385.0 MB 1.9 MB/s eta 0:01:48\n",
      "   ------------------ --------------------- 175.1/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 175.2/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 175.3/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 175.5/385.0 MB 1.9 MB/s eta 0:01:48\n",
      "   ------------------ --------------------- 175.6/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 175.7/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 175.9/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 176.0/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 176.1/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 176.3/385.0 MB 1.9 MB/s eta 0:01:49\n",
      "   ------------------ --------------------- 176.3/385.0 MB 1.9 MB/s eta 0:01:50\n",
      "   ------------------ --------------------- 176.5/385.0 MB 2.0 MB/s eta 0:01:43\n",
      "   ------------------ --------------------- 176.5/385.0 MB 2.0 MB/s eta 0:01:43\n",
      "   ------------------ --------------------- 176.6/385.0 MB 2.1 MB/s eta 0:01:38\n",
      "   ------------------ --------------------- 176.6/385.0 MB 2.1 MB/s eta 0:01:38\n",
      "   ------------------ --------------------- 176.8/385.0 MB 2.1 MB/s eta 0:01:38\n",
      "   ------------------ --------------------- 176.9/385.0 MB 2.1 MB/s eta 0:01:37\n",
      "   ------------------ --------------------- 177.0/385.0 MB 2.2 MB/s eta 0:01:37\n",
      "   ------------------ --------------------- 177.2/385.0 MB 2.2 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 177.3/385.0 MB 2.2 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 177.5/385.0 MB 2.2 MB/s eta 0:01:35\n",
      "   ------------------ --------------------- 177.6/385.0 MB 2.2 MB/s eta 0:01:35\n",
      "   ------------------ --------------------- 177.7/385.0 MB 2.2 MB/s eta 0:01:35\n",
      "   ------------------ --------------------- 177.9/385.0 MB 2.2 MB/s eta 0:01:34\n",
      "   ------------------ --------------------- 178.1/385.0 MB 2.2 MB/s eta 0:01:33\n",
      "   ------------------ --------------------- 178.1/385.0 MB 2.2 MB/s eta 0:01:33\n",
      "   ------------------ --------------------- 178.3/385.0 MB 2.2 MB/s eta 0:01:33\n",
      "   ------------------ --------------------- 178.4/385.0 MB 2.2 MB/s eta 0:01:33\n",
      "   ------------------ --------------------- 178.5/385.0 MB 2.2 MB/s eta 0:01:33\n",
      "   ------------------ --------------------- 178.7/385.0 MB 2.2 MB/s eta 0:01:32\n",
      "   ------------------ --------------------- 178.8/385.0 MB 2.2 MB/s eta 0:01:32\n",
      "   ------------------ --------------------- 178.9/385.0 MB 2.2 MB/s eta 0:01:32\n",
      "   ------------------ --------------------- 179.1/385.0 MB 2.3 MB/s eta 0:01:31\n",
      "   ------------------ --------------------- 179.2/385.0 MB 2.2 MB/s eta 0:01:32\n",
      "   ------------------ --------------------- 179.4/385.0 MB 2.2 MB/s eta 0:01:32\n",
      "   ------------------ --------------------- 179.5/385.0 MB 2.2 MB/s eta 0:01:32\n",
      "   ------------------ --------------------- 179.7/385.0 MB 2.3 MB/s eta 0:01:31\n",
      "   ------------------ --------------------- 179.8/385.0 MB 2.4 MB/s eta 0:01:25\n",
      "   ------------------ --------------------- 180.0/385.0 MB 2.6 MB/s eta 0:01:19\n",
      "   ------------------ --------------------- 180.1/385.0 MB 2.7 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 180.3/385.0 MB 2.7 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 180.4/385.0 MB 2.7 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 180.6/385.0 MB 2.7 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 180.7/385.0 MB 2.7 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 180.9/385.0 MB 2.7 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 181.1/385.0 MB 2.7 MB/s eta 0:01:15\n",
      "   ------------------ --------------------- 181.2/385.0 MB 2.7 MB/s eta 0:01:15\n",
      "   ------------------ --------------------- 181.4/385.0 MB 2.8 MB/s eta 0:01:15\n",
      "   ------------------ --------------------- 181.4/385.0 MB 2.8 MB/s eta 0:01:15\n",
      "   ------------------ --------------------- 181.7/385.0 MB 2.8 MB/s eta 0:01:14\n",
      "   ------------------ --------------------- 181.8/385.0 MB 2.8 MB/s eta 0:01:14\n",
      "   ------------------ --------------------- 181.9/385.0 MB 2.8 MB/s eta 0:01:14\n",
      "   ------------------ --------------------- 182.1/385.0 MB 2.8 MB/s eta 0:01:14\n",
      "   ------------------ --------------------- 182.2/385.0 MB 2.8 MB/s eta 0:01:14\n",
      "   ------------------ --------------------- 182.3/385.0 MB 2.8 MB/s eta 0:01:14\n",
      "   ------------------ --------------------- 182.4/385.0 MB 2.8 MB/s eta 0:01:13\n",
      "   ------------------ --------------------- 182.5/385.0 MB 2.8 MB/s eta 0:01:13\n",
      "   ------------------ --------------------- 182.7/385.0 MB 2.8 MB/s eta 0:01:13\n",
      "   ------------------ --------------------- 182.8/385.0 MB 2.8 MB/s eta 0:01:13\n",
      "   ------------------- -------------------- 182.9/385.0 MB 2.8 MB/s eta 0:01:13\n",
      "   ------------------- -------------------- 183.1/385.0 MB 2.8 MB/s eta 0:01:13\n",
      "   ------------------- -------------------- 183.2/385.0 MB 2.8 MB/s eta 0:01:13\n",
      "   ------------------- -------------------- 183.3/385.0 MB 2.8 MB/s eta 0:01:13\n",
      "   ------------------- -------------------- 183.5/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 183.6/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 183.7/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 183.8/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 183.9/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.1/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.2/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.4/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.5/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.8 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.6/385.0 MB 2.6 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 184.7/385.0 MB 2.0 MB/s eta 0:01:39\n",
      "   ------------------- -------------------- 184.7/385.0 MB 2.0 MB/s eta 0:01:39\n",
      "   ------------------- -------------------- 184.8/385.0 MB 2.0 MB/s eta 0:01:40\n",
      "   ------------------- -------------------- 184.8/385.0 MB 2.0 MB/s eta 0:01:40\n",
      "   ------------------- -------------------- 184.9/385.0 MB 2.0 MB/s eta 0:01:41\n",
      "   ------------------- -------------------- 185.0/385.0 MB 2.0 MB/s eta 0:01:41\n",
      "   ------------------- -------------------- 185.1/385.0 MB 2.0 MB/s eta 0:01:41\n",
      "   ------------------- -------------------- 185.2/385.0 MB 2.0 MB/s eta 0:01:41\n",
      "   ------------------- -------------------- 185.3/385.0 MB 2.0 MB/s eta 0:01:41\n",
      "   ------------------- -------------------- 185.4/385.0 MB 2.0 MB/s eta 0:01:41\n",
      "   ------------------- -------------------- 185.5/385.0 MB 2.0 MB/s eta 0:01:42\n",
      "   ------------------- -------------------- 185.5/385.0 MB 2.0 MB/s eta 0:01:42\n",
      "   ------------------- -------------------- 185.7/385.0 MB 1.9 MB/s eta 0:01:43\n",
      "   ------------------- -------------------- 185.8/385.0 MB 2.0 MB/s eta 0:01:42\n",
      "   ------------------- -------------------- 185.8/385.0 MB 1.9 MB/s eta 0:01:43\n",
      "   ------------------- -------------------- 185.9/385.0 MB 1.9 MB/s eta 0:01:43\n",
      "   ------------------- -------------------- 186.0/385.0 MB 1.9 MB/s eta 0:01:44\n",
      "   ------------------- -------------------- 186.0/385.0 MB 1.9 MB/s eta 0:01:44\n",
      "   ------------------- -------------------- 186.1/385.0 MB 1.9 MB/s eta 0:01:45\n",
      "   ------------------- -------------------- 186.1/385.0 MB 1.9 MB/s eta 0:01:45\n",
      "   ------------------- -------------------- 186.2/385.0 MB 1.9 MB/s eta 0:01:46\n",
      "   ------------------- -------------------- 186.2/385.0 MB 1.9 MB/s eta 0:01:46\n",
      "   ------------------- -------------------- 186.3/385.0 MB 1.9 MB/s eta 0:01:47\n",
      "   ------------------- -------------------- 186.3/385.0 MB 1.8 MB/s eta 0:01:48\n",
      "   ------------------- -------------------- 186.4/385.0 MB 1.8 MB/s eta 0:01:48\n",
      "   ------------------- -------------------- 186.4/385.0 MB 1.8 MB/s eta 0:01:49\n",
      "   ------------------- -------------------- 186.6/385.0 MB 1.8 MB/s eta 0:01:49\n",
      "   ------------------- -------------------- 186.7/385.0 MB 1.8 MB/s eta 0:01:49\n",
      "   ------------------- -------------------- 186.8/385.0 MB 1.8 MB/s eta 0:01:48\n",
      "   ------------------- -------------------- 186.8/385.0 MB 1.8 MB/s eta 0:01:49\n",
      "   ------------------- -------------------- 186.8/385.0 MB 1.8 MB/s eta 0:01:50\n",
      "   ------------------- -------------------- 187.0/385.0 MB 1.8 MB/s eta 0:01:48\n",
      "   ------------------- -------------------- 187.1/385.0 MB 1.8 MB/s eta 0:01:49\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.8 MB/s eta 0:01:49\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.8 MB/s eta 0:01:50\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.8 MB/s eta 0:01:50\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.8 MB/s eta 0:01:50\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.8 MB/s eta 0:01:50\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.8 MB/s eta 0:01:50\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.8 MB/s eta 0:01:50\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.7 MB/s eta 0:01:56\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.7 MB/s eta 0:01:56\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.7 MB/s eta 0:01:56\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.7 MB/s eta 0:01:56\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.7 MB/s eta 0:01:56\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.7 MB/s eta 0:01:56\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.7 MB/s eta 0:01:56\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.6 MB/s eta 0:02:03\n",
      "   ------------------- -------------------- 187.2/385.0 MB 1.6 MB/s eta 0:02:03\n",
      "   ------------------- -------------------- 187.3/385.0 MB 1.6 MB/s eta 0:02:05\n",
      "   ------------------- -------------------- 187.4/385.0 MB 1.6 MB/s eta 0:02:07\n",
      "   ------------------- -------------------- 187.4/385.0 MB 1.6 MB/s eta 0:02:07\n",
      "   ------------------- -------------------- 187.5/385.0 MB 1.6 MB/s eta 0:02:08\n",
      "   ------------------- -------------------- 187.6/385.0 MB 1.5 MB/s eta 0:02:08\n",
      "   ------------------- -------------------- 187.6/385.0 MB 1.5 MB/s eta 0:02:08\n",
      "   ------------------- -------------------- 187.7/385.0 MB 1.5 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 187.8/385.0 MB 1.5 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 187.9/385.0 MB 1.5 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 188.0/385.0 MB 1.5 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 188.1/385.0 MB 1.5 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 188.1/385.0 MB 1.5 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 188.2/385.0 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 188.3/385.0 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 188.4/385.0 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 188.6/385.0 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 188.6/385.0 MB 1.5 MB/s eta 0:02:12\n",
      "   ------------------- -------------------- 188.8/385.0 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 188.9/385.0 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 189.1/385.0 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 189.2/385.0 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------------- -------------------- 189.3/385.0 MB 1.5 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 189.5/385.0 MB 1.5 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 189.7/385.0 MB 1.5 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 189.9/385.0 MB 1.5 MB/s eta 0:02:10\n",
      "   ------------------- -------------------- 190.1/385.0 MB 1.5 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 190.2/385.0 MB 1.5 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 190.5/385.0 MB 1.5 MB/s eta 0:02:09\n",
      "   ------------------- -------------------- 190.8/385.0 MB 1.5 MB/s eta 0:02:08\n",
      "   ------------------- -------------------- 191.0/385.0 MB 1.5 MB/s eta 0:02:08\n",
      "   ------------------- -------------------- 191.2/385.0 MB 1.5 MB/s eta 0:02:07\n",
      "   ------------------- -------------------- 191.4/385.0 MB 1.5 MB/s eta 0:02:07\n",
      "   ------------------- -------------------- 191.7/385.0 MB 1.6 MB/s eta 0:02:05\n",
      "   ------------------- -------------------- 191.9/385.0 MB 1.6 MB/s eta 0:02:05\n",
      "   ------------------- -------------------- 192.2/385.0 MB 1.6 MB/s eta 0:02:04\n",
      "   ------------------- -------------------- 192.5/385.0 MB 1.6 MB/s eta 0:02:03\n",
      "   -------------------- ------------------- 192.8/385.0 MB 1.6 MB/s eta 0:02:01\n",
      "   -------------------- ------------------- 193.1/385.0 MB 1.6 MB/s eta 0:02:00\n",
      "   -------------------- ------------------- 193.6/385.0 MB 1.6 MB/s eta 0:01:57\n",
      "   -------------------- ------------------- 194.0/385.0 MB 1.7 MB/s eta 0:01:55\n",
      "   -------------------- ------------------- 194.3/385.0 MB 1.7 MB/s eta 0:01:53\n",
      "   -------------------- ------------------- 194.5/385.0 MB 1.7 MB/s eta 0:01:53\n",
      "   -------------------- ------------------- 195.3/385.0 MB 2.4 MB/s eta 0:01:20\n",
      "   -------------------- ------------------- 195.6/385.0 MB 2.4 MB/s eta 0:01:19\n",
      "   -------------------- ------------------- 195.9/385.0 MB 2.5 MB/s eta 0:01:16\n",
      "   -------------------- ------------------- 196.2/385.0 MB 2.6 MB/s eta 0:01:13\n",
      "   -------------------- ------------------- 196.5/385.0 MB 2.8 MB/s eta 0:01:09\n",
      "   -------------------- ------------------- 196.8/385.0 MB 2.9 MB/s eta 0:01:06\n",
      "   -------------------- ------------------- 197.1/385.0 MB 3.0 MB/s eta 0:01:03\n",
      "   -------------------- ------------------- 197.5/385.0 MB 4.3 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 197.9/385.0 MB 4.6 MB/s eta 0:00:41\n",
      "   -------------------- ------------------- 198.1/385.0 MB 4.8 MB/s eta 0:00:40\n",
      "   -------------------- ------------------- 198.4/385.0 MB 5.1 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 198.5/385.0 MB 5.2 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 198.5/385.0 MB 5.2 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 199.2/385.0 MB 5.7 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 199.5/385.0 MB 5.8 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 199.7/385.0 MB 5.9 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 199.9/385.0 MB 6.0 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 200.1/385.0 MB 6.0 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 200.4/385.0 MB 6.0 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 200.6/385.0 MB 6.0 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 200.8/385.0 MB 6.0 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 201.1/385.0 MB 6.1 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 201.4/385.0 MB 6.1 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 201.5/385.0 MB 6.1 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 201.5/385.0 MB 6.1 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 201.5/385.0 MB 6.1 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 201.5/385.0 MB 6.1 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 201.5/385.0 MB 6.1 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 201.5/385.0 MB 6.1 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 201.5/385.0 MB 6.1 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 5.1 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 201.6/385.0 MB 3.2 MB/s eta 0:00:58\n",
      "   -------------------- ------------------- 201.7/385.0 MB 3.1 MB/s eta 0:00:59\n",
      "   -------------------- ------------------- 201.8/385.0 MB 3.1 MB/s eta 0:01:00\n",
      "   -------------------- ------------------- 201.9/385.0 MB 3.1 MB/s eta 0:01:00\n",
      "   -------------------- ------------------- 202.0/385.0 MB 3.1 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 202.2/385.0 MB 3.0 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 202.3/385.0 MB 3.0 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 202.5/385.0 MB 3.0 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 202.6/385.0 MB 3.0 MB/s eta 0:01:02\n",
      "   --------------------- ------------------ 202.8/385.0 MB 3.0 MB/s eta 0:01:02\n",
      "   --------------------- ------------------ 203.0/385.0 MB 2.9 MB/s eta 0:01:03\n",
      "   --------------------- ------------------ 203.2/385.0 MB 2.9 MB/s eta 0:01:03\n",
      "   --------------------- ------------------ 203.3/385.0 MB 2.9 MB/s eta 0:01:03\n",
      "   --------------------- ------------------ 203.5/385.0 MB 2.9 MB/s eta 0:01:03\n",
      "   --------------------- ------------------ 203.7/385.0 MB 2.9 MB/s eta 0:01:04\n",
      "   --------------------- ------------------ 203.9/385.0 MB 2.8 MB/s eta 0:01:04\n",
      "   --------------------- ------------------ 204.1/385.0 MB 2.8 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 204.2/385.0 MB 2.8 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 204.5/385.0 MB 2.8 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 204.6/385.0 MB 2.8 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 204.8/385.0 MB 2.8 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 205.1/385.0 MB 2.8 MB/s eta 0:01:05\n",
      "   --------------------- ------------------ 205.2/385.0 MB 2.8 MB/s eta 0:01:06\n",
      "   --------------------- ------------------ 205.4/385.0 MB 2.7 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 205.5/385.0 MB 2.7 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 205.8/385.0 MB 2.7 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 206.0/385.0 MB 2.7 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 206.3/385.0 MB 2.7 MB/s eta 0:01:07\n",
      "   --------------------- ------------------ 206.5/385.0 MB 2.7 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 206.7/385.0 MB 2.7 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 206.9/385.0 MB 2.6 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 207.2/385.0 MB 2.6 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 207.3/385.0 MB 2.6 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 207.3/385.0 MB 2.6 MB/s eta 0:01:08\n",
      "   --------------------- ------------------ 207.5/385.0 MB 2.6 MB/s eta 0:01:10\n",
      "   --------------------- ------------------ 207.8/385.0 MB 2.6 MB/s eta 0:01:10\n",
      "   --------------------- ------------------ 208.0/385.0 MB 2.5 MB/s eta 0:01:10\n",
      "   --------------------- ------------------ 208.1/385.0 MB 2.5 MB/s eta 0:01:10\n",
      "   --------------------- ------------------ 208.3/385.0 MB 2.5 MB/s eta 0:01:10\n",
      "   --------------------- ------------------ 208.4/385.0 MB 2.5 MB/s eta 0:01:11\n",
      "   --------------------- ------------------ 208.6/385.0 MB 2.5 MB/s eta 0:01:11\n",
      "   --------------------- ------------------ 208.7/385.0 MB 2.5 MB/s eta 0:01:10\n",
      "   --------------------- ------------------ 208.8/385.0 MB 2.5 MB/s eta 0:01:11\n",
      "   --------------------- ------------------ 209.0/385.0 MB 2.5 MB/s eta 0:01:11\n",
      "   --------------------- ------------------ 209.2/385.0 MB 2.5 MB/s eta 0:01:12\n",
      "   --------------------- ------------------ 209.3/385.0 MB 2.4 MB/s eta 0:01:13\n",
      "   --------------------- ------------------ 209.5/385.0 MB 2.4 MB/s eta 0:01:13\n",
      "   --------------------- ------------------ 209.6/385.0 MB 2.4 MB/s eta 0:01:13\n",
      "   --------------------- ------------------ 209.8/385.0 MB 2.4 MB/s eta 0:01:13\n",
      "   --------------------- ------------------ 209.9/385.0 MB 2.4 MB/s eta 0:01:14\n",
      "   --------------------- ------------------ 210.1/385.0 MB 2.4 MB/s eta 0:01:14\n",
      "   --------------------- ------------------ 210.3/385.0 MB 2.4 MB/s eta 0:01:14\n",
      "   --------------------- ------------------ 210.5/385.0 MB 2.4 MB/s eta 0:01:14\n",
      "   --------------------- ------------------ 210.6/385.0 MB 2.4 MB/s eta 0:01:14\n",
      "   --------------------- ------------------ 210.8/385.0 MB 2.4 MB/s eta 0:01:14\n",
      "   --------------------- ------------------ 211.0/385.0 MB 2.4 MB/s eta 0:01:14\n",
      "   --------------------- ------------------ 211.1/385.0 MB 2.3 MB/s eta 0:01:15\n",
      "   --------------------- ------------------ 211.3/385.0 MB 2.3 MB/s eta 0:01:15\n",
      "   --------------------- ------------------ 211.4/385.0 MB 2.3 MB/s eta 0:01:15\n",
      "   --------------------- ------------------ 211.6/385.0 MB 2.3 MB/s eta 0:01:15\n",
      "   --------------------- ------------------ 211.8/385.0 MB 2.5 MB/s eta 0:01:10\n",
      "   ---------------------- ----------------- 211.9/385.0 MB 3.6 MB/s eta 0:00:49\n",
      "   ---------------------- ----------------- 212.1/385.0 MB 3.7 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 212.3/385.0 MB 3.6 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 212.4/385.0 MB 3.7 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 212.6/385.0 MB 3.7 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 212.8/385.0 MB 3.7 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 213.0/385.0 MB 3.7 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 213.1/385.0 MB 3.7 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 213.3/385.0 MB 3.7 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 213.5/385.0 MB 3.7 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 213.7/385.0 MB 3.7 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 213.7/385.0 MB 3.7 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 214.0/385.0 MB 3.7 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 214.0/385.0 MB 3.6 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 214.2/385.0 MB 3.6 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 214.2/385.0 MB 3.6 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 214.2/385.0 MB 3.6 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 214.2/385.0 MB 3.6 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 214.3/385.0 MB 3.5 MB/s eta 0:00:50\n",
      "   ---------------------- ----------------- 214.3/385.0 MB 3.5 MB/s eta 0:00:50\n",
      "   ---------------------- ----------------- 214.3/385.0 MB 3.3 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 214.3/385.0 MB 3.3 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 214.4/385.0 MB 3.2 MB/s eta 0:00:53\n",
      "   ---------------------- ----------------- 214.5/385.0 MB 3.2 MB/s eta 0:00:53\n",
      "   ---------------------- ----------------- 214.6/385.0 MB 3.2 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 214.6/385.0 MB 3.2 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 214.8/385.0 MB 3.1 MB/s eta 0:00:55\n",
      "   ---------------------- ----------------- 214.8/385.0 MB 3.1 MB/s eta 0:00:55\n",
      "   ---------------------- ----------------- 215.0/385.0 MB 3.1 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 215.1/385.0 MB 3.1 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 215.2/385.0 MB 3.0 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 215.3/385.0 MB 3.0 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 215.4/385.0 MB 3.0 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 215.4/385.0 MB 3.0 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 215.6/385.0 MB 3.0 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 215.7/385.0 MB 3.0 MB/s eta 0:00:58\n",
      "   ---------------------- ----------------- 215.8/385.0 MB 3.0 MB/s eta 0:00:58\n",
      "   ---------------------- ----------------- 215.9/385.0 MB 2.9 MB/s eta 0:00:58\n",
      "   ---------------------- ----------------- 216.0/385.0 MB 2.9 MB/s eta 0:00:59\n",
      "   ---------------------- ----------------- 216.1/385.0 MB 2.9 MB/s eta 0:00:59\n",
      "   ---------------------- ----------------- 216.2/385.0 MB 2.9 MB/s eta 0:01:00\n",
      "   ---------------------- ----------------- 216.3/385.0 MB 2.9 MB/s eta 0:01:00\n",
      "   ---------------------- ----------------- 216.4/385.0 MB 2.8 MB/s eta 0:01:00\n",
      "   ---------------------- ----------------- 216.5/385.0 MB 2.8 MB/s eta 0:01:00\n",
      "   ---------------------- ----------------- 216.6/385.0 MB 2.8 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 216.7/385.0 MB 2.8 MB/s eta 0:01:01\n",
      "   ---------------------- ----------------- 216.8/385.0 MB 2.7 MB/s eta 0:01:02\n",
      "   ---------------------- ----------------- 216.9/385.0 MB 2.7 MB/s eta 0:01:02\n",
      "   ---------------------- ----------------- 217.0/385.0 MB 2.7 MB/s eta 0:01:02\n",
      "   ---------------------- ----------------- 217.2/385.0 MB 2.7 MB/s eta 0:01:03\n",
      "   ---------------------- ----------------- 217.2/385.0 MB 2.7 MB/s eta 0:01:03\n",
      "   ---------------------- ----------------- 217.3/385.0 MB 2.7 MB/s eta 0:01:03\n",
      "   ---------------------- ----------------- 217.4/385.0 MB 2.7 MB/s eta 0:01:03\n",
      "   ---------------------- ----------------- 217.5/385.0 MB 2.7 MB/s eta 0:01:02\n",
      "   ---------------------- ----------------- 217.6/385.0 MB 2.7 MB/s eta 0:01:03\n",
      "   ---------------------- ----------------- 217.7/385.0 MB 2.7 MB/s eta 0:01:04\n",
      "   ---------------------- ----------------- 217.8/385.0 MB 2.6 MB/s eta 0:01:05\n",
      "   ---------------------- ----------------- 218.0/385.0 MB 2.6 MB/s eta 0:01:05\n",
      "   ---------------------- ----------------- 218.1/385.0 MB 2.6 MB/s eta 0:01:05\n",
      "   ---------------------- ----------------- 218.2/385.0 MB 2.6 MB/s eta 0:01:06\n",
      "   ---------------------- ----------------- 218.3/385.0 MB 2.6 MB/s eta 0:01:05\n",
      "   ---------------------- ----------------- 218.4/385.0 MB 2.6 MB/s eta 0:01:06\n",
      "   ---------------------- ----------------- 218.5/385.0 MB 2.5 MB/s eta 0:01:06\n",
      "   ---------------------- ----------------- 218.6/385.0 MB 2.5 MB/s eta 0:01:06\n",
      "   ---------------------- ----------------- 218.7/385.0 MB 2.5 MB/s eta 0:01:06\n",
      "   ---------------------- ----------------- 218.8/385.0 MB 2.5 MB/s eta 0:01:06\n",
      "   ---------------------- ----------------- 218.9/385.0 MB 2.5 MB/s eta 0:01:06\n",
      "   ---------------------- ----------------- 219.0/385.0 MB 2.5 MB/s eta 0:01:07\n",
      "   ---------------------- ----------------- 219.1/385.0 MB 2.5 MB/s eta 0:01:07\n",
      "   ---------------------- ----------------- 219.2/385.0 MB 2.5 MB/s eta 0:01:07\n",
      "   ---------------------- ----------------- 219.3/385.0 MB 2.5 MB/s eta 0:01:07\n",
      "   ---------------------- ----------------- 219.4/385.0 MB 2.5 MB/s eta 0:01:07\n",
      "   ---------------------- ----------------- 219.5/385.0 MB 2.5 MB/s eta 0:01:07\n",
      "   ---------------------- ----------------- 219.7/385.0 MB 2.5 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 219.8/385.0 MB 2.5 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 219.8/385.0 MB 2.5 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 220.0/385.0 MB 2.4 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 220.1/385.0 MB 2.4 MB/s eta 0:01:09\n",
      "   ---------------------- ----------------- 220.2/385.0 MB 2.4 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 220.4/385.0 MB 2.4 MB/s eta 0:01:09\n",
      "   ---------------------- ----------------- 220.4/385.0 MB 2.4 MB/s eta 0:01:09\n",
      "   ---------------------- ----------------- 220.4/385.0 MB 2.4 MB/s eta 0:01:09\n",
      "   ---------------------- ----------------- 220.4/385.0 MB 2.4 MB/s eta 0:01:09\n",
      "   ---------------------- ----------------- 220.5/385.0 MB 2.3 MB/s eta 0:01:11\n",
      "   ---------------------- ----------------- 220.5/385.0 MB 2.3 MB/s eta 0:01:11\n",
      "   ---------------------- ----------------- 220.5/385.0 MB 2.3 MB/s eta 0:01:11\n",
      "   ---------------------- ----------------- 220.5/385.0 MB 2.3 MB/s eta 0:01:11\n",
      "   ---------------------- ----------------- 220.5/385.0 MB 2.3 MB/s eta 0:01:11\n",
      "   ---------------------- ----------------- 220.5/385.0 MB 2.2 MB/s eta 0:01:14\n",
      "   ---------------------- ----------------- 220.6/385.0 MB 2.2 MB/s eta 0:01:15\n",
      "   ---------------------- ----------------- 220.7/385.0 MB 2.2 MB/s eta 0:01:15\n",
      "   ---------------------- ----------------- 220.8/385.0 MB 2.2 MB/s eta 0:01:15\n",
      "   ---------------------- ----------------- 220.9/385.0 MB 2.2 MB/s eta 0:01:16\n",
      "   ---------------------- ----------------- 221.0/385.0 MB 2.2 MB/s eta 0:01:16\n",
      "   ---------------------- ----------------- 221.1/385.0 MB 2.2 MB/s eta 0:01:16\n",
      "   ---------------------- ----------------- 221.2/385.0 MB 2.2 MB/s eta 0:01:17\n",
      "   ---------------------- ----------------- 221.2/385.0 MB 2.1 MB/s eta 0:01:17\n",
      "   ---------------------- ----------------- 221.2/385.0 MB 2.1 MB/s eta 0:01:17\n",
      "   ---------------------- ----------------- 221.2/385.0 MB 2.1 MB/s eta 0:01:17\n",
      "   ---------------------- ----------------- 221.2/385.0 MB 2.1 MB/s eta 0:01:17\n",
      "   ---------------------- ----------------- 221.2/385.0 MB 2.1 MB/s eta 0:01:17\n",
      "   ---------------------- ----------------- 221.2/385.0 MB 2.1 MB/s eta 0:01:17\n",
      "   ---------------------- ----------------- 221.4/385.0 MB 2.0 MB/s eta 0:01:21\n",
      "   ---------------------- ----------------- 221.4/385.0 MB 2.0 MB/s eta 0:01:21\n",
      "   ----------------------- ---------------- 221.5/385.0 MB 2.0 MB/s eta 0:01:22\n",
      "   ----------------------- ---------------- 221.5/385.0 MB 2.0 MB/s eta 0:01:22\n",
      "   ----------------------- ---------------- 221.6/385.0 MB 2.0 MB/s eta 0:01:23\n",
      "   ----------------------- ---------------- 221.7/385.0 MB 2.0 MB/s eta 0:01:23\n",
      "   ----------------------- ---------------- 221.8/385.0 MB 2.0 MB/s eta 0:01:23\n",
      "   ----------------------- ---------------- 221.8/385.0 MB 2.0 MB/s eta 0:01:24\n",
      "   ----------------------- ---------------- 221.9/385.0 MB 1.9 MB/s eta 0:01:24\n",
      "   ----------------------- ---------------- 222.0/385.0 MB 1.9 MB/s eta 0:01:24\n",
      "   ----------------------- ---------------- 222.1/385.0 MB 1.9 MB/s eta 0:01:25\n",
      "   ----------------------- ---------------- 222.1/385.0 MB 1.9 MB/s eta 0:01:25\n",
      "   ----------------------- ---------------- 222.2/385.0 MB 1.9 MB/s eta 0:01:26\n",
      "   ----------------------- ---------------- 222.3/385.0 MB 1.9 MB/s eta 0:01:26\n",
      "   ----------------------- ---------------- 222.4/385.0 MB 1.9 MB/s eta 0:01:26\n",
      "   ----------------------- ---------------- 222.5/385.0 MB 1.9 MB/s eta 0:01:26\n",
      "   ----------------------- ---------------- 222.6/385.0 MB 1.9 MB/s eta 0:01:27\n",
      "   ----------------------- ---------------- 222.6/385.0 MB 1.9 MB/s eta 0:01:27\n",
      "   ----------------------- ---------------- 222.7/385.0 MB 1.9 MB/s eta 0:01:28\n",
      "   ----------------------- ---------------- 222.8/385.0 MB 1.8 MB/s eta 0:01:28\n",
      "   ----------------------- ---------------- 222.8/385.0 MB 1.8 MB/s eta 0:01:28\n",
      "   ----------------------- ---------------- 222.9/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 223.0/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 223.1/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 223.2/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 223.2/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 223.3/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 223.4/385.0 MB 1.8 MB/s eta 0:01:31\n",
      "   ----------------------- ---------------- 223.5/385.0 MB 1.8 MB/s eta 0:01:31\n",
      "   ----------------------- ---------------- 223.6/385.0 MB 1.8 MB/s eta 0:01:31\n",
      "   ----------------------- ---------------- 223.7/385.0 MB 1.8 MB/s eta 0:01:32\n",
      "   ----------------------- ---------------- 223.8/385.0 MB 1.8 MB/s eta 0:01:32\n",
      "   ----------------------- ---------------- 223.8/385.0 MB 1.8 MB/s eta 0:01:33\n",
      "   ----------------------- ---------------- 223.9/385.0 MB 1.8 MB/s eta 0:01:32\n",
      "   ----------------------- ---------------- 224.0/385.0 MB 1.8 MB/s eta 0:01:32\n",
      "   ----------------------- ---------------- 224.1/385.0 MB 1.7 MB/s eta 0:01:33\n",
      "   ----------------------- ---------------- 224.2/385.0 MB 1.7 MB/s eta 0:01:34\n",
      "   ----------------------- ---------------- 224.3/385.0 MB 1.7 MB/s eta 0:01:34\n",
      "   ----------------------- ---------------- 224.3/385.0 MB 1.7 MB/s eta 0:01:34\n",
      "   ----------------------- ---------------- 224.5/385.0 MB 1.8 MB/s eta 0:01:32\n",
      "   ----------------------- ---------------- 224.5/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ----------------------- ---------------- 224.6/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 224.7/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 224.8/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 224.9/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.0/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.1/385.0 MB 1.8 MB/s eta 0:01:28\n",
      "   ----------------------- ---------------- 225.2/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.3/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.4/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.5/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.6/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.7/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.7/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.8/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 225.9/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.0/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.1/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.2/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.3/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.4/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.5/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.6/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.7/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.8/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 226.9/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.0/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.1/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.2/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.3/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.4/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.5/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.6/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.6/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.7/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.8/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 227.9/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 228.0/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 228.1/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 228.1/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 228.2/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 228.3/385.0 MB 1.7 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 228.4/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 228.5/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 228.6/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 228.7/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 228.8/385.0 MB 1.7 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 228.9/385.0 MB 1.7 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 229.1/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 229.2/385.0 MB 1.8 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 229.3/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 229.4/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 229.5/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 229.6/385.0 MB 1.7 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 229.7/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 229.8/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 229.9/385.0 MB 1.7 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 230.0/385.0 MB 1.7 MB/s eta 0:01:30\n",
      "   ----------------------- ---------------- 230.1/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 230.2/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 230.3/385.0 MB 1.8 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 230.4/385.0 MB 1.7 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 230.5/385.0 MB 1.7 MB/s eta 0:01:29\n",
      "   ----------------------- ---------------- 230.7/385.0 MB 1.8 MB/s eta 0:01:27\n",
      "   ----------------------- ---------------- 230.8/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ----------------------- ---------------- 230.9/385.0 MB 1.9 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.0/385.0 MB 1.9 MB/s eta 0:01:23\n",
      "   ------------------------ --------------- 231.1/385.0 MB 1.9 MB/s eta 0:01:23\n",
      "   ------------------------ --------------- 231.1/385.0 MB 1.9 MB/s eta 0:01:23\n",
      "   ------------------------ --------------- 231.1/385.0 MB 1.9 MB/s eta 0:01:23\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.8 MB/s eta 0:01:24\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------------ --------------- 231.2/385.0 MB 1.6 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 231.3/385.0 MB 1.6 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 231.3/385.0 MB 1.6 MB/s eta 0:01:37\n",
      "   ------------------------ --------------- 231.4/385.0 MB 1.6 MB/s eta 0:01:38\n",
      "   ------------------------ --------------- 231.5/385.0 MB 1.6 MB/s eta 0:01:34\n",
      "   ------------------------ --------------- 231.6/385.0 MB 1.6 MB/s eta 0:01:34\n",
      "   ------------------------ --------------- 231.6/385.0 MB 1.6 MB/s eta 0:01:34\n",
      "   ------------------------ --------------- 231.7/385.0 MB 1.6 MB/s eta 0:01:34\n",
      "   ------------------------ --------------- 231.8/385.0 MB 1.7 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 231.9/385.0 MB 1.7 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 232.0/385.0 MB 1.6 MB/s eta 0:01:34\n",
      "   ------------------------ --------------- 232.1/385.0 MB 1.7 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 232.2/385.0 MB 1.7 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 232.2/385.0 MB 1.7 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 232.3/385.0 MB 1.7 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 232.4/385.0 MB 1.7 MB/s eta 0:01:33\n",
      "   ------------------------ --------------- 232.5/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 232.6/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 232.7/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 232.8/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 232.9/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.0/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.1/385.0 MB 1.7 MB/s eta 0:01:31\n",
      "   ------------------------ --------------- 233.2/385.0 MB 1.7 MB/s eta 0:01:30\n",
      "   ------------------------ --------------- 233.2/385.0 MB 1.7 MB/s eta 0:01:31\n",
      "   ------------------------ --------------- 233.2/385.0 MB 1.7 MB/s eta 0:01:31\n",
      "   ------------------------ --------------- 233.2/385.0 MB 1.7 MB/s eta 0:01:31\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.3/385.0 MB 1.7 MB/s eta 0:01:32\n",
      "   ------------------------ --------------- 233.4/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 233.4/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 233.5/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 233.6/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 233.6/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 233.7/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 233.7/385.0 MB 1.4 MB/s eta 0:01:49\n",
      "   ------------------------ --------------- 233.8/385.0 MB 1.4 MB/s eta 0:01:49\n",
      "   ------------------------ --------------- 233.9/385.0 MB 1.4 MB/s eta 0:01:49\n",
      "   ------------------------ --------------- 234.0/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.1/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.1/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.2/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.3/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.4/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.5/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.6/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.7/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.8/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.8/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 234.9/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 235.0/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 235.1/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 235.2/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 235.3/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 235.4/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 235.5/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 235.6/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 235.7/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 235.7/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 235.8/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 236.0/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 236.0/385.0 MB 1.4 MB/s eta 0:01:48\n",
      "   ------------------------ --------------- 236.2/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 236.2/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 236.3/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 236.4/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 236.5/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 236.6/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 236.7/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 236.8/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 236.9/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 237.0/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 237.1/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 237.2/385.0 MB 1.4 MB/s eta 0:01:46\n",
      "   ------------------------ --------------- 237.3/385.0 MB 1.4 MB/s eta 0:01:47\n",
      "   ------------------------ --------------- 237.5/385.0 MB 1.4 MB/s eta 0:01:46\n",
      "   ------------------------ --------------- 237.6/385.0 MB 1.4 MB/s eta 0:01:46\n",
      "   ------------------------ --------------- 237.7/385.0 MB 1.4 MB/s eta 0:01:46\n",
      "   ------------------------ --------------- 237.8/385.0 MB 1.4 MB/s eta 0:01:45\n",
      "   ------------------------ --------------- 238.0/385.0 MB 1.4 MB/s eta 0:01:45\n",
      "   ------------------------ --------------- 238.1/385.0 MB 1.4 MB/s eta 0:01:44\n",
      "   ------------------------ --------------- 238.2/385.0 MB 1.4 MB/s eta 0:01:44\n",
      "   ------------------------ --------------- 238.3/385.0 MB 1.4 MB/s eta 0:01:44\n",
      "   ------------------------ --------------- 238.4/385.0 MB 1.4 MB/s eta 0:01:44\n",
      "   ------------------------ --------------- 238.5/385.0 MB 1.4 MB/s eta 0:01:43\n",
      "   ------------------------ --------------- 238.6/385.0 MB 1.4 MB/s eta 0:01:43\n",
      "   ------------------------ --------------- 238.7/385.0 MB 1.4 MB/s eta 0:01:43\n",
      "   ------------------------ --------------- 238.9/385.0 MB 1.4 MB/s eta 0:01:43\n",
      "   ------------------------ --------------- 239.0/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 239.1/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 239.2/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 239.3/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 239.5/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 239.5/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 239.6/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 239.8/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 239.8/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 240.0/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 240.1/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 240.2/385.0 MB 1.4 MB/s eta 0:01:42\n",
      "   ------------------------ --------------- 240.3/385.0 MB 1.4 MB/s eta 0:01:41\n",
      "   ------------------------ --------------- 240.4/385.0 MB 1.4 MB/s eta 0:01:41\n",
      "   ------------------------ --------------- 240.5/385.0 MB 1.4 MB/s eta 0:01:41\n",
      "   ------------------------- -------------- 240.7/385.0 MB 1.4 MB/s eta 0:01:41\n",
      "   ------------------------- -------------- 240.8/385.0 MB 1.4 MB/s eta 0:01:41\n",
      "   ------------------------- -------------- 241.0/385.0 MB 1.4 MB/s eta 0:01:41\n",
      "   ------------------------- -------------- 241.1/385.0 MB 1.4 MB/s eta 0:01:40\n",
      "   ------------------------- -------------- 241.3/385.0 MB 1.4 MB/s eta 0:01:40\n",
      "   ------------------------- -------------- 241.4/385.0 MB 1.5 MB/s eta 0:01:38\n",
      "   ------------------------- -------------- 241.6/385.0 MB 1.7 MB/s eta 0:01:25\n",
      "   ------------------------- -------------- 241.6/385.0 MB 1.7 MB/s eta 0:01:25\n",
      "   ------------------------- -------------- 241.6/385.0 MB 1.7 MB/s eta 0:01:25\n",
      "   ------------------------- -------------- 241.6/385.0 MB 1.7 MB/s eta 0:01:25\n",
      "   ------------------------- -------------- 241.7/385.0 MB 1.7 MB/s eta 0:01:27\n",
      "   ------------------------- -------------- 241.7/385.0 MB 1.7 MB/s eta 0:01:27\n",
      "   ------------------------- -------------- 241.7/385.0 MB 1.6 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 241.8/385.0 MB 1.6 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 241.8/385.0 MB 1.6 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 241.9/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 241.9/385.0 MB 1.6 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 242.0/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.0/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.1/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.1/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 242.2/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.3/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.4/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.5/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 242.5/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.6/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.7/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.8/385.0 MB 1.6 MB/s eta 0:01:29\n",
      "   ------------------------- -------------- 242.8/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 242.9/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 243.0/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 243.1/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 243.2/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 243.2/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 243.3/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 243.4/385.0 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------------- -------------- 243.5/385.0 MB 1.6 MB/s eta 0:01:28\n",
      "   ------------------------- -------------- 243.6/385.0 MB 1.9 MB/s eta 0:01:14\n",
      "   ------------------------- -------------- 243.7/385.0 MB 1.9 MB/s eta 0:01:13\n",
      "   ------------------------- -------------- 243.8/385.0 MB 1.9 MB/s eta 0:01:13\n",
      "   ------------------------- -------------- 243.8/385.0 MB 1.9 MB/s eta 0:01:13\n",
      "   ------------------------- -------------- 243.9/385.0 MB 1.9 MB/s eta 0:01:13\n",
      "   ------------------------- -------------- 244.0/385.0 MB 2.0 MB/s eta 0:01:12\n",
      "   ------------------------- -------------- 244.1/385.0 MB 2.0 MB/s eta 0:01:12\n",
      "   ------------------------- -------------- 244.3/385.0 MB 2.0 MB/s eta 0:01:12\n",
      "   ------------------------- -------------- 244.3/385.0 MB 2.0 MB/s eta 0:01:12\n",
      "   ------------------------- -------------- 244.4/385.0 MB 2.0 MB/s eta 0:01:12\n",
      "   ------------------------- -------------- 244.6/385.0 MB 2.0 MB/s eta 0:01:11\n",
      "   ------------------------- -------------- 244.6/385.0 MB 2.0 MB/s eta 0:01:12\n",
      "   ------------------------- -------------- 244.7/385.0 MB 2.0 MB/s eta 0:01:11\n",
      "   ------------------------- -------------- 244.8/385.0 MB 2.0 MB/s eta 0:01:11\n",
      "   ------------------------- -------------- 245.0/385.0 MB 2.0 MB/s eta 0:01:11\n",
      "   ------------------------- -------------- 245.1/385.0 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------------------- -------------- 245.2/385.0 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------------------- -------------- 245.3/385.0 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------------------- -------------- 245.4/385.0 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------------------- -------------- 245.5/385.0 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------------------- -------------- 245.6/385.0 MB 2.0 MB/s eta 0:01:09\n",
      "   ------------------------- -------------- 245.7/385.0 MB 2.0 MB/s eta 0:01:09\n",
      "   ------------------------- -------------- 245.8/385.0 MB 2.0 MB/s eta 0:01:09\n",
      "   ------------------------- -------------- 246.0/385.0 MB 2.0 MB/s eta 0:01:09\n",
      "   ------------------------- -------------- 246.1/385.0 MB 2.0 MB/s eta 0:01:09\n",
      "   ------------------------- -------------- 246.2/385.0 MB 2.0 MB/s eta 0:01:08\n",
      "   ------------------------- -------------- 246.3/385.0 MB 2.1 MB/s eta 0:01:08\n",
      "   ------------------------- -------------- 246.4/385.0 MB 2.1 MB/s eta 0:01:08\n",
      "   ------------------------- -------------- 246.5/385.0 MB 2.1 MB/s eta 0:01:08\n",
      "   ------------------------- -------------- 246.6/385.0 MB 2.1 MB/s eta 0:01:08\n",
      "   ------------------------- -------------- 246.8/385.0 MB 2.1 MB/s eta 0:01:07\n",
      "   ------------------------- -------------- 246.9/385.0 MB 2.1 MB/s eta 0:01:07\n",
      "   ------------------------- -------------- 247.0/385.0 MB 2.1 MB/s eta 0:01:07\n",
      "   ------------------------- -------------- 247.2/385.0 MB 2.1 MB/s eta 0:01:07\n",
      "   ------------------------- -------------- 247.3/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 247.4/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 247.5/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 247.6/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 247.7/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 247.8/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 248.0/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 248.1/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 248.2/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 248.3/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 248.5/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 248.6/385.0 MB 2.1 MB/s eta 0:01:06\n",
      "   ------------------------- -------------- 248.7/385.0 MB 2.1 MB/s eta 0:01:05\n",
      "   ------------------------- -------------- 248.9/385.0 MB 2.1 MB/s eta 0:01:05\n",
      "   ------------------------- -------------- 249.0/385.0 MB 2.1 MB/s eta 0:01:05\n",
      "   ------------------------- -------------- 249.1/385.0 MB 2.1 MB/s eta 0:01:05\n",
      "   ------------------------- -------------- 249.2/385.0 MB 2.1 MB/s eta 0:01:05\n",
      "   ------------------------- -------------- 249.4/385.0 MB 2.1 MB/s eta 0:01:04\n",
      "   ------------------------- -------------- 249.5/385.0 MB 2.1 MB/s eta 0:01:04\n",
      "   ------------------------- -------------- 249.7/385.0 MB 2.1 MB/s eta 0:01:04\n",
      "   ------------------------- -------------- 249.8/385.0 MB 2.1 MB/s eta 0:01:04\n",
      "   ------------------------- -------------- 249.9/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   ------------------------- -------------- 250.0/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   ------------------------- -------------- 250.1/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   ------------------------- -------------- 250.2/385.0 MB 2.1 MB/s eta 0:01:04\n",
      "   -------------------------- ------------- 250.3/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 250.4/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 250.6/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 250.7/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 250.8/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 250.9/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 251.1/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 251.2/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 251.3/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 251.4/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 251.5/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 251.6/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 251.8/385.0 MB 2.1 MB/s eta 0:01:03\n",
      "   -------------------------- ------------- 251.9/385.0 MB 2.2 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 252.1/385.0 MB 2.2 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 252.2/385.0 MB 2.3 MB/s eta 0:00:59\n",
      "   -------------------------- ------------- 252.3/385.0 MB 2.3 MB/s eta 0:00:58\n",
      "   -------------------------- ------------- 252.4/385.0 MB 2.3 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 252.5/385.0 MB 2.4 MB/s eta 0:00:57\n",
      "   -------------------------- ------------- 252.7/385.0 MB 2.4 MB/s eta 0:00:56\n",
      "   -------------------------- ------------- 252.8/385.0 MB 2.4 MB/s eta 0:00:56\n",
      "   -------------------------- ------------- 252.9/385.0 MB 2.4 MB/s eta 0:00:56\n",
      "   -------------------------- ------------- 253.1/385.0 MB 2.4 MB/s eta 0:00:55\n",
      "   -------------------------- ------------- 253.2/385.0 MB 2.4 MB/s eta 0:00:54\n",
      "   -------------------------- ------------- 253.3/385.0 MB 2.5 MB/s eta 0:00:54\n",
      "   -------------------------- ------------- 253.4/385.0 MB 2.5 MB/s eta 0:00:54\n",
      "   -------------------------- ------------- 253.5/385.0 MB 2.5 MB/s eta 0:00:54\n",
      "   -------------------------- ------------- 253.6/385.0 MB 2.5 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 253.8/385.0 MB 2.5 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 253.9/385.0 MB 2.5 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 254.0/385.0 MB 2.5 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 254.2/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 254.3/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 254.4/385.0 MB 2.6 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 254.6/385.0 MB 2.6 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 254.7/385.0 MB 2.6 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 254.8/385.0 MB 2.6 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 254.9/385.0 MB 2.6 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 255.0/385.0 MB 2.6 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 255.0/385.0 MB 2.6 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 255.0/385.0 MB 2.6 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 255.0/385.0 MB 2.6 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.5 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 255.1/385.0 MB 2.2 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 255.2/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 255.2/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 255.3/385.0 MB 2.1 MB/s eta 0:01:02\n",
      "   -------------------------- ------------- 255.4/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 255.5/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 255.6/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 255.8/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 255.9/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 256.0/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 256.1/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 256.2/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 256.4/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 256.5/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 256.6/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 256.7/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 256.8/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 257.0/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 257.1/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 257.2/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 257.3/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 257.4/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 257.5/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 257.6/385.0 MB 2.1 MB/s eta 0:01:01\n",
      "   -------------------------- ------------- 257.8/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 257.9/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 258.1/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 258.1/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 258.2/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 258.4/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 258.5/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 258.6/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 258.7/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 258.8/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 259.0/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 259.1/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 259.3/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 259.4/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 259.5/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 259.6/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   -------------------------- ------------- 259.8/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 259.9/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 260.0/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 260.2/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 260.3/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 260.4/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 260.5/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 260.7/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 260.8/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 260.9/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 261.1/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 261.2/385.0 MB 2.1 MB/s eta 0:00:58\n",
      "   --------------------------- ------------ 261.3/385.0 MB 2.1 MB/s eta 0:00:58\n",
      "   --------------------------- ------------ 261.3/385.0 MB 2.1 MB/s eta 0:00:58\n",
      "   --------------------------- ------------ 261.5/385.0 MB 2.1 MB/s eta 0:00:58\n",
      "   --------------------------- ------------ 261.6/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 261.7/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 261.8/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 261.9/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 262.0/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 262.1/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 262.2/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 262.3/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 262.4/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 262.5/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 262.6/385.0 MB 2.1 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 262.7/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 262.7/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 262.9/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 263.0/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 263.1/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 263.1/385.0 MB 2.1 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 263.2/385.0 MB 2.0 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 263.2/385.0 MB 2.0 MB/s eta 0:01:00\n",
      "   --------------------------- ------------ 263.3/385.0 MB 2.0 MB/s eta 0:01:01\n",
      "   --------------------------- ------------ 263.4/385.0 MB 2.0 MB/s eta 0:01:01\n",
      "   --------------------------- ------------ 263.5/385.0 MB 2.0 MB/s eta 0:01:01\n",
      "   --------------------------- ------------ 263.6/385.0 MB 2.0 MB/s eta 0:01:01\n",
      "   --------------------------- ------------ 263.6/385.0 MB 2.0 MB/s eta 0:01:02\n",
      "   --------------------------- ------------ 263.7/385.0 MB 2.0 MB/s eta 0:01:02\n",
      "   --------------------------- ------------ 263.8/385.0 MB 2.0 MB/s eta 0:01:02\n",
      "   --------------------------- ------------ 263.8/385.0 MB 2.0 MB/s eta 0:01:02\n",
      "   --------------------------- ------------ 263.9/385.0 MB 2.0 MB/s eta 0:01:02\n",
      "   --------------------------- ------------ 264.0/385.0 MB 2.0 MB/s eta 0:01:02\n",
      "   --------------------------- ------------ 264.0/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 264.1/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 264.2/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 264.3/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 264.4/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 264.5/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 264.6/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 264.7/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 264.8/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 264.8/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 264.9/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 265.0/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 265.1/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 265.1/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 265.2/385.0 MB 1.9 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 265.3/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 265.4/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 265.5/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 265.6/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 265.7/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 265.8/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 265.8/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 265.9/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 266.0/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 266.2/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 266.2/385.0 MB 2.2 MB/s eta 0:00:55\n",
      "   --------------------------- ------------ 266.3/385.0 MB 2.2 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.4/385.0 MB 2.2 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.5/385.0 MB 2.2 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.6/385.0 MB 2.1 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.7/385.0 MB 2.1 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.7/385.0 MB 2.1 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.7/385.0 MB 2.1 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.7/385.0 MB 2.1 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.7/385.0 MB 2.1 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.7/385.0 MB 2.1 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.7/385.0 MB 2.1 MB/s eta 0:00:56\n",
      "   --------------------------- ------------ 266.8/385.0 MB 2.0 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 266.8/385.0 MB 2.0 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 266.8/385.0 MB 2.0 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 266.8/385.0 MB 2.0 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 266.8/385.0 MB 2.0 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 266.8/385.0 MB 2.0 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 266.8/385.0 MB 2.0 MB/s eta 0:00:59\n",
      "   --------------------------- ------------ 266.9/385.0 MB 1.9 MB/s eta 0:01:02\n",
      "   --------------------------- ------------ 267.0/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 267.0/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 267.1/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 267.1/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 267.3/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 267.3/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 267.4/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 267.5/385.0 MB 1.9 MB/s eta 0:01:03\n",
      "   --------------------------- ------------ 267.6/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 267.7/385.0 MB 1.9 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 267.7/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 267.8/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 267.9/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 268.0/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 268.1/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 268.2/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 268.3/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 268.4/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 268.5/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 268.6/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 268.7/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   --------------------------- ------------ 268.8/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 268.9/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 269.0/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 269.1/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 269.2/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 269.3/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 269.4/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   --------------------------- ------------ 269.5/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 269.6/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 269.7/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 269.8/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 269.9/385.0 MB 1.8 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 269.9/385.0 MB 1.8 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.0/385.0 MB 1.8 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.1/385.0 MB 1.8 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.2/385.0 MB 1.8 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.3/385.0 MB 1.8 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.4/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.5/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.6/385.0 MB 1.8 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.7/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.8/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 270.9/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 271.0/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 271.1/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 271.2/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 271.3/385.0 MB 1.7 MB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 271.4/385.0 MB 1.7 MB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 271.5/385.0 MB 1.7 MB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 271.5/385.0 MB 1.7 MB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 271.7/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 271.8/385.0 MB 1.7 MB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 271.9/385.0 MB 1.7 MB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 272.0/385.0 MB 1.7 MB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 272.1/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 272.3/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 272.4/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 272.5/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 272.6/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 272.7/385.0 MB 1.7 MB/s eta 0:01:06\n",
      "   ---------------------------- ----------- 272.8/385.0 MB 1.7 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 273.0/385.0 MB 1.7 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 273.1/385.0 MB 1.7 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 273.2/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 273.3/385.0 MB 1.8 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 273.5/385.0 MB 1.8 MB/s eta 0:01:03\n",
      "   ---------------------------- ----------- 273.6/385.0 MB 1.8 MB/s eta 0:01:03\n",
      "   ---------------------------- ----------- 273.8/385.0 MB 1.8 MB/s eta 0:01:02\n",
      "   ---------------------------- ----------- 273.9/385.0 MB 1.8 MB/s eta 0:01:02\n",
      "   ---------------------------- ----------- 274.0/385.0 MB 1.8 MB/s eta 0:01:02\n",
      "   ---------------------------- ----------- 274.1/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 274.1/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 274.1/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 274.1/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 274.1/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 274.1/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 274.1/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 274.2/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 274.2/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 274.2/385.0 MB 1.7 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 274.3/385.0 MB 1.7 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 274.4/385.0 MB 1.7 MB/s eta 0:01:05\n",
      "   ---------------------------- ----------- 274.6/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 274.7/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 274.8/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 274.8/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 274.9/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 275.0/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 275.1/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 275.2/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 275.3/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 275.4/385.0 MB 1.7 MB/s eta 0:01:04\n",
      "   ---------------------------- ----------- 275.5/385.0 MB 1.7 MB/s eta 0:01:03\n",
      "   ---------------------------- ----------- 275.6/385.0 MB 1.8 MB/s eta 0:01:03\n",
      "   ---------------------------- ----------- 275.7/385.0 MB 1.8 MB/s eta 0:01:03\n",
      "   ---------------------------- ----------- 275.9/385.0 MB 1.8 MB/s eta 0:01:02\n",
      "   ---------------------------- ----------- 276.0/385.0 MB 1.8 MB/s eta 0:01:02\n",
      "   ---------------------------- ----------- 276.1/385.0 MB 1.8 MB/s eta 0:01:02\n",
      "   ---------------------------- ----------- 276.2/385.0 MB 1.8 MB/s eta 0:01:02\n",
      "   ---------------------------- ----------- 276.3/385.0 MB 1.8 MB/s eta 0:01:02\n",
      "   ---------------------------- ----------- 276.4/385.0 MB 1.8 MB/s eta 0:01:02\n",
      "   ---------------------------- ----------- 276.5/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 276.6/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 276.8/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 276.9/385.0 MB 1.8 MB/s eta 0:01:01\n",
      "   ---------------------------- ----------- 277.0/385.0 MB 1.9 MB/s eta 0:00:58\n",
      "   ---------------------------- ----------- 277.1/385.0 MB 2.0 MB/s eta 0:00:54\n",
      "   ---------------------------- ----------- 277.3/385.0 MB 2.0 MB/s eta 0:00:54\n",
      "   ---------------------------- ----------- 277.4/385.0 MB 2.1 MB/s eta 0:00:53\n",
      "   ---------------------------- ----------- 277.5/385.0 MB 2.1 MB/s eta 0:00:53\n",
      "   ---------------------------- ----------- 277.6/385.0 MB 2.1 MB/s eta 0:00:53\n",
      "   ---------------------------- ----------- 277.8/385.0 MB 2.1 MB/s eta 0:00:52\n",
      "   ---------------------------- ----------- 277.9/385.0 MB 2.1 MB/s eta 0:00:52\n",
      "   ---------------------------- ----------- 278.0/385.0 MB 2.1 MB/s eta 0:00:52\n",
      "   ---------------------------- ----------- 278.2/385.0 MB 2.1 MB/s eta 0:00:51\n",
      "   ---------------------------- ----------- 278.3/385.0 MB 2.1 MB/s eta 0:00:51\n",
      "   ---------------------------- ----------- 278.4/385.0 MB 2.1 MB/s eta 0:00:51\n",
      "   ---------------------------- ----------- 278.5/385.0 MB 2.1 MB/s eta 0:00:51\n",
      "   ---------------------------- ----------- 278.7/385.0 MB 2.1 MB/s eta 0:00:50\n",
      "   ---------------------------- ----------- 278.8/385.0 MB 2.1 MB/s eta 0:00:50\n",
      "   ---------------------------- ----------- 278.9/385.0 MB 2.1 MB/s eta 0:00:50\n",
      "   ---------------------------- ----------- 279.0/385.0 MB 2.1 MB/s eta 0:00:50\n",
      "   ----------------------------- ---------- 279.2/385.0 MB 2.2 MB/s eta 0:00:50\n",
      "   ----------------------------- ---------- 279.3/385.0 MB 2.2 MB/s eta 0:00:50\n",
      "   ----------------------------- ---------- 279.4/385.0 MB 2.2 MB/s eta 0:00:49\n",
      "   ----------------------------- ---------- 279.5/385.0 MB 2.2 MB/s eta 0:00:49\n",
      "   ----------------------------- ---------- 279.6/385.0 MB 2.2 MB/s eta 0:00:49\n",
      "   ----------------------------- ---------- 279.7/385.0 MB 2.2 MB/s eta 0:00:49\n",
      "   ----------------------------- ---------- 279.8/385.0 MB 2.2 MB/s eta 0:00:49\n",
      "   ----------------------------- ---------- 280.0/385.0 MB 2.2 MB/s eta 0:00:48\n",
      "   ----------------------------- ---------- 280.1/385.0 MB 2.2 MB/s eta 0:00:48\n",
      "   ----------------------------- ---------- 280.2/385.0 MB 2.2 MB/s eta 0:00:48\n",
      "   ----------------------------- ---------- 280.4/385.0 MB 2.2 MB/s eta 0:00:48\n",
      "   ----------------------------- ---------- 280.5/385.0 MB 2.2 MB/s eta 0:00:47\n",
      "   ----------------------------- ---------- 280.6/385.0 MB 2.2 MB/s eta 0:00:47\n",
      "   ----------------------------- ---------- 280.8/385.0 MB 2.2 MB/s eta 0:00:47\n",
      "   ----------------------------- ---------- 280.9/385.0 MB 2.3 MB/s eta 0:00:47\n",
      "   ----------------------------- ---------- 281.0/385.0 MB 2.3 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 281.1/385.0 MB 2.3 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 281.3/385.0 MB 2.3 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 281.5/385.0 MB 2.3 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 281.6/385.0 MB 2.3 MB/s eta 0:00:45\n",
      "   ----------------------------- ---------- 281.8/385.0 MB 2.3 MB/s eta 0:00:45\n",
      "   ----------------------------- ---------- 281.9/385.0 MB 2.3 MB/s eta 0:00:45\n",
      "   ----------------------------- ---------- 282.1/385.0 MB 2.3 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 282.2/385.0 MB 2.4 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 282.3/385.0 MB 2.4 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 282.5/385.0 MB 2.4 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 282.6/385.0 MB 2.4 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 282.7/385.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 282.9/385.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 283.1/385.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 283.2/385.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 283.3/385.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 283.4/385.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 283.5/385.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 283.7/385.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 283.9/385.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 284.0/385.0 MB 2.4 MB/s eta 0:00:42\n",
      "   ----------------------------- ---------- 284.2/385.0 MB 2.4 MB/s eta 0:00:42\n",
      "   ----------------------------- ---------- 284.4/385.0 MB 2.6 MB/s eta 0:00:39\n",
      "   ----------------------------- ---------- 284.5/385.0 MB 2.7 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 284.6/385.0 MB 2.7 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 284.8/385.0 MB 2.7 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 284.9/385.0 MB 2.7 MB/s eta 0:00:37\n",
      "   ----------------------------- ---------- 285.1/385.0 MB 2.7 MB/s eta 0:00:37\n",
      "   ----------------------------- ---------- 285.2/385.0 MB 2.8 MB/s eta 0:00:37\n",
      "   ----------------------------- ---------- 285.4/385.0 MB 2.8 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 285.5/385.0 MB 2.8 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 285.6/385.0 MB 2.8 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 285.7/385.0 MB 2.8 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 285.7/385.0 MB 2.8 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 286.0/385.0 MB 2.8 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 286.1/385.0 MB 2.8 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 286.2/385.0 MB 2.8 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 286.4/385.0 MB 2.8 MB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 286.5/385.0 MB 2.8 MB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 286.6/385.0 MB 2.8 MB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 286.6/385.0 MB 2.8 MB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 286.6/385.0 MB 2.8 MB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 286.6/385.0 MB 2.8 MB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 286.6/385.0 MB 2.8 MB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 286.6/385.0 MB 2.8 MB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 286.6/385.0 MB 2.8 MB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 286.7/385.0 MB 2.3 MB/s eta 0:00:42\n",
      "   ----------------------------- ---------- 286.8/385.0 MB 2.3 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 286.8/385.0 MB 2.3 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 287.0/385.0 MB 2.3 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 287.1/385.0 MB 2.3 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 287.1/385.0 MB 2.3 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 287.2/385.0 MB 2.3 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 287.3/385.0 MB 2.3 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 287.4/385.0 MB 2.3 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 287.5/385.0 MB 2.3 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 287.6/385.0 MB 2.3 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 287.7/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 287.8/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 287.9/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 288.0/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 288.1/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 288.2/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 288.3/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 288.5/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 288.6/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 288.6/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 288.7/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 288.8/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 289.0/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 289.1/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 289.2/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 289.3/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 289.4/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 289.5/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 289.7/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 289.8/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 289.9/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 290.0/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 290.2/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 290.3/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 290.4/385.0 MB 2.2 MB/s eta 0:00:43\n",
      "   ------------------------------ --------- 290.5/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 290.6/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 290.7/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 290.8/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 290.9/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 291.0/385.0 MB 2.2 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 291.1/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 291.2/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 291.3/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 291.4/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 291.5/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 291.6/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 291.7/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 291.8/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 292.0/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 292.1/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 292.2/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 292.3/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 292.4/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 292.6/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 292.7/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 292.8/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 293.0/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 293.1/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 293.2/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 293.3/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 293.5/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 293.6/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 293.8/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 293.8/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 294.0/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 294.1/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 294.2/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 294.3/385.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 294.5/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 294.6/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 294.8/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 294.9/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 294.9/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 295.1/385.0 MB 2.0 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 295.2/385.0 MB 2.0 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 295.4/385.0 MB 2.0 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 295.5/385.0 MB 2.0 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 295.7/385.0 MB 2.0 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 295.8/385.0 MB 2.0 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 295.9/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 296.1/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 296.3/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 296.5/385.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 296.6/385.0 MB 2.1 MB/s eta 0:00:43\n",
      "   ------------------------------ --------- 296.8/385.0 MB 2.1 MB/s eta 0:00:43\n",
      "   ------------------------------ --------- 296.9/385.0 MB 2.2 MB/s eta 0:00:40\n",
      "   ------------------------------ --------- 297.0/385.0 MB 2.5 MB/s eta 0:00:36\n",
      "   ------------------------------ --------- 297.2/385.0 MB 2.5 MB/s eta 0:00:36\n",
      "   ------------------------------ --------- 297.4/385.0 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------------------ --------- 297.5/385.0 MB 2.6 MB/s eta 0:00:35\n",
      "   ------------------------------ --------- 297.6/385.0 MB 2.6 MB/s eta 0:00:35\n",
      "   ------------------------------ --------- 297.6/385.0 MB 2.6 MB/s eta 0:00:35\n",
      "   ------------------------------ --------- 297.8/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------ --------- 297.9/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------ --------- 298.0/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------ --------- 298.1/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------ --------- 298.3/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------ --------- 298.4/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------- -------- 298.5/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------- -------- 298.6/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------- -------- 298.8/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------- -------- 298.9/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------- -------- 299.0/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 299.1/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------- -------- 299.2/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------- -------- 299.3/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 299.4/385.0 MB 2.6 MB/s eta 0:00:34\n",
      "   ------------------------------- -------- 299.5/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 299.7/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 299.8/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 299.9/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 300.0/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 300.2/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 300.3/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 300.4/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 300.5/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 300.7/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 300.8/385.0 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------------------- -------- 301.0/385.0 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------------------- -------- 301.1/385.0 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------------------- -------- 301.3/385.0 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------------------------- -------- 301.5/385.0 MB 2.7 MB/s eta 0:00:31\n",
      "   ------------------------------- -------- 301.6/385.0 MB 2.7 MB/s eta 0:00:31\n",
      "   ------------------------------- -------- 301.7/385.0 MB 2.7 MB/s eta 0:00:31\n",
      "   ------------------------------- -------- 301.9/385.0 MB 2.7 MB/s eta 0:00:31\n",
      "   ------------------------------- -------- 302.0/385.0 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------------------------- -------- 302.1/385.0 MB 2.7 MB/s eta 0:00:31\n",
      "   ------------------------------- -------- 302.3/385.0 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------------------------- -------- 302.4/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 302.6/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 302.7/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 302.8/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 303.0/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 303.1/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 303.2/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 303.4/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 303.5/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 303.6/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 303.8/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 304.0/385.0 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------------------------- -------- 304.1/385.0 MB 2.8 MB/s eta 0:00:29\n",
      "   ------------------------------- -------- 304.3/385.0 MB 2.8 MB/s eta 0:00:29\n",
      "   ------------------------------- -------- 304.4/385.0 MB 2.8 MB/s eta 0:00:29\n",
      "   ------------------------------- -------- 304.5/385.0 MB 2.8 MB/s eta 0:00:29\n",
      "   ------------------------------- -------- 304.7/385.0 MB 2.8 MB/s eta 0:00:29\n",
      "   ------------------------------- -------- 304.9/385.0 MB 2.8 MB/s eta 0:00:29\n",
      "   ------------------------------- -------- 305.1/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 305.2/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 305.4/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 305.6/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 305.7/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 305.9/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 306.0/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 306.2/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 306.4/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 306.5/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 306.6/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 306.8/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 306.9/385.0 MB 2.9 MB/s eta 0:00:28\n",
      "   ------------------------------- -------- 307.1/385.0 MB 2.9 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 307.3/385.0 MB 2.9 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 307.4/385.0 MB 2.9 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 307.6/385.0 MB 2.9 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 307.7/385.0 MB 2.9 MB/s eta 0:00:27\n",
      "   ------------------------------- -------- 307.9/385.0 MB 2.9 MB/s eta 0:00:27\n",
      "   -------------------------------- ------- 308.1/385.0 MB 2.9 MB/s eta 0:00:27\n",
      "   -------------------------------- ------- 308.3/385.0 MB 3.0 MB/s eta 0:00:26\n",
      "   -------------------------------- ------- 308.5/385.0 MB 3.0 MB/s eta 0:00:26\n",
      "   -------------------------------- ------- 308.7/385.0 MB 3.0 MB/s eta 0:00:26\n",
      "   -------------------------------- ------- 308.9/385.0 MB 3.1 MB/s eta 0:00:25\n",
      "   -------------------------------- ------- 309.1/385.0 MB 3.1 MB/s eta 0:00:25\n",
      "   -------------------------------- ------- 309.2/385.0 MB 3.1 MB/s eta 0:00:25\n",
      "   -------------------------------- ------- 309.3/385.0 MB 3.1 MB/s eta 0:00:25\n",
      "   -------------------------------- ------- 309.5/385.0 MB 3.1 MB/s eta 0:00:25\n",
      "   -------------------------------- ------- 309.5/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 309.5/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 309.9/385.0 MB 3.2 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 310.0/385.0 MB 3.2 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 310.1/385.0 MB 3.2 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 310.3/385.0 MB 3.2 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 310.4/385.0 MB 3.2 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 310.5/385.0 MB 3.2 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 310.6/385.0 MB 3.2 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 310.7/385.0 MB 3.2 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 310.9/385.0 MB 3.2 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 311.0/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 311.1/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 311.2/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 311.4/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 311.6/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 311.7/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 311.8/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 311.9/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 312.0/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 312.2/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 312.3/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 312.5/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 312.6/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 312.8/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 312.9/385.0 MB 3.1 MB/s eta 0:00:24\n",
      "   -------------------------------- ------- 313.1/385.0 MB 3.1 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 313.3/385.0 MB 3.1 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 313.4/385.0 MB 3.1 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 313.6/385.0 MB 3.2 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 313.7/385.0 MB 3.2 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 313.9/385.0 MB 3.2 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 314.0/385.0 MB 3.2 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 314.2/385.0 MB 3.2 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 314.3/385.0 MB 3.2 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 314.5/385.0 MB 3.2 MB/s eta 0:00:23\n",
      "   -------------------------------- ------- 314.7/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 314.9/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 315.0/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 315.2/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 315.3/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 315.5/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 315.7/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 315.9/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 316.0/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 316.2/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 316.4/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 316.6/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 316.7/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 316.9/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 317.0/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   -------------------------------- ------- 317.2/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   -------------------------------- ------- 317.4/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   -------------------------------- ------- 317.5/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   -------------------------------- ------- 317.5/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 317.7/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 318.1/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 318.2/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 318.4/385.0 MB 3.2 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 318.5/385.0 MB 3.1 MB/s eta 0:00:22\n",
      "   --------------------------------- ------ 318.8/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 318.9/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 319.0/385.0 MB 3.1 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 319.2/385.0 MB 3.1 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 319.4/385.0 MB 3.1 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 319.6/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 319.7/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 319.9/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 320.0/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 320.2/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 320.3/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 320.5/385.0 MB 3.2 MB/s eta 0:00:21\n",
      "   --------------------------------- ------ 320.7/385.0 MB 3.2 MB/s eta 0:00:20\n",
      "   --------------------------------- ------ 320.9/385.0 MB 3.3 MB/s eta 0:00:20\n",
      "   --------------------------------- ------ 321.1/385.0 MB 3.3 MB/s eta 0:00:20\n",
      "   --------------------------------- ------ 321.2/385.0 MB 3.3 MB/s eta 0:00:20\n",
      "   --------------------------------- ------ 321.4/385.0 MB 3.3 MB/s eta 0:00:20\n",
      "   --------------------------------- ------ 321.6/385.0 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 321.7/385.0 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 321.9/385.0 MB 3.3 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 322.1/385.0 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 322.2/385.0 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 322.4/385.0 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 322.5/385.0 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 322.7/385.0 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 322.9/385.0 MB 3.4 MB/s eta 0:00:19\n",
      "   --------------------------------- ------ 323.2/385.0 MB 3.5 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 323.4/385.0 MB 3.5 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 323.5/385.0 MB 3.5 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 323.7/385.0 MB 3.5 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 323.9/385.0 MB 3.5 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 324.1/385.0 MB 3.5 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 324.3/385.0 MB 3.6 MB/s eta 0:00:18\n",
      "   --------------------------------- ------ 324.6/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 324.8/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 325.0/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 325.1/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 325.3/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 325.5/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 325.6/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 325.8/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 326.0/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 326.1/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 326.3/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 326.6/385.0 MB 3.6 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 326.8/385.0 MB 3.7 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 327.0/385.0 MB 3.7 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 327.2/385.0 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 327.3/385.0 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 327.5/385.0 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 327.8/385.0 MB 3.7 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 328.0/385.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 328.1/385.0 MB 3.8 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 328.3/385.0 MB 3.8 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 328.5/385.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 328.7/385.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 328.9/385.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 329.1/385.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 329.3/385.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 329.5/385.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 329.7/385.0 MB 3.9 MB/s eta 0:00:15\n",
      "   ---------------------------------- ----- 329.9/385.0 MB 3.9 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 330.1/385.0 MB 3.9 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 330.3/385.0 MB 3.9 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 330.5/385.0 MB 4.0 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 330.7/385.0 MB 4.0 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 330.9/385.0 MB 4.0 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 331.1/385.0 MB 4.0 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 331.4/385.0 MB 4.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 331.6/385.0 MB 4.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 331.8/385.0 MB 4.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 332.0/385.0 MB 4.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 332.3/385.0 MB 4.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 332.4/385.0 MB 4.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 332.7/385.0 MB 4.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 332.9/385.0 MB 4.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 333.1/385.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 333.2/385.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 333.2/385.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 333.2/385.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 333.2/385.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 333.2/385.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 333.2/385.0 MB 4.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 333.3/385.0 MB 3.8 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 333.3/385.0 MB 3.8 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 333.3/385.0 MB 3.8 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 333.3/385.0 MB 3.8 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 333.3/385.0 MB 3.8 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 333.3/385.0 MB 3.8 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 333.3/385.0 MB 3.8 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 333.4/385.0 MB 3.4 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 333.5/385.0 MB 3.4 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 333.7/385.0 MB 3.4 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 333.8/385.0 MB 3.4 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 334.0/385.0 MB 3.4 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 334.2/385.0 MB 3.4 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 334.3/385.0 MB 3.4 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 334.4/385.0 MB 3.3 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 334.6/385.0 MB 3.3 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 334.8/385.0 MB 3.3 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 334.9/385.0 MB 3.3 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 335.1/385.0 MB 3.3 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 335.1/385.0 MB 3.3 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 335.3/385.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 335.3/385.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 335.4/385.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 335.5/385.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 335.7/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 335.9/385.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 336.0/385.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 336.2/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 336.4/385.0 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 336.6/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 336.7/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 336.9/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 337.1/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 337.4/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 337.6/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 337.7/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 337.9/385.0 MB 3.1 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 338.0/385.0 MB 3.1 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 338.1/385.0 MB 3.1 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 338.1/385.0 MB 3.1 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 338.1/385.0 MB 3.1 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 338.1/385.0 MB 3.1 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 338.1/385.0 MB 3.1 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 338.1/385.0 MB 3.1 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 338.1/385.0 MB 3.1 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 338.1/385.0 MB 3.1 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 338.3/385.0 MB 2.8 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 338.3/385.0 MB 2.8 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 338.4/385.0 MB 2.8 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 338.5/385.0 MB 2.7 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 338.5/385.0 MB 2.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 338.6/385.0 MB 2.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 338.7/385.0 MB 2.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 338.8/385.0 MB 2.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 338.9/385.0 MB 2.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 339.0/385.0 MB 2.7 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 339.1/385.0 MB 2.6 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 339.2/385.0 MB 2.6 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 339.3/385.0 MB 2.6 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 339.4/385.0 MB 2.6 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 339.5/385.0 MB 2.6 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 339.7/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 339.8/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 339.9/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 340.0/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 340.1/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 340.3/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 340.4/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 340.6/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 340.7/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 340.9/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 341.0/385.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 341.1/385.0 MB 2.4 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 341.2/385.0 MB 2.4 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 341.4/385.0 MB 2.4 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 341.5/385.0 MB 2.4 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 341.6/385.0 MB 2.4 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 341.8/385.0 MB 2.4 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 341.9/385.0 MB 2.4 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 342.0/385.0 MB 2.4 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 342.1/385.0 MB 2.3 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 342.3/385.0 MB 2.3 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 342.5/385.0 MB 2.3 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 342.6/385.0 MB 2.3 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 342.7/385.0 MB 2.3 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 342.8/385.0 MB 2.3 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 343.0/385.0 MB 2.3 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 343.3/385.0 MB 2.3 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 343.4/385.0 MB 2.5 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 343.6/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 343.7/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 343.9/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 344.1/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 344.2/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 344.3/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 344.5/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 344.7/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 344.8/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 345.0/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 345.1/385.0 MB 2.7 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 345.3/385.0 MB 2.6 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 345.5/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 345.6/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 345.8/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 346.0/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 346.1/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 346.3/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ----------------------------------- ---- 346.5/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 346.6/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 346.7/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 346.9/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 347.0/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 347.2/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 347.4/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 347.6/385.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 347.7/385.0 MB 2.7 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 347.9/385.0 MB 2.7 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 348.0/385.0 MB 2.7 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 348.1/385.0 MB 2.6 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 348.3/385.0 MB 2.7 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 348.5/385.0 MB 2.9 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 348.6/385.0 MB 3.0 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 348.8/385.0 MB 3.0 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 348.9/385.0 MB 3.0 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 348.9/385.0 MB 3.0 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 348.9/385.0 MB 3.0 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 348.9/385.0 MB 3.0 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 348.9/385.0 MB 3.0 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 348.9/385.0 MB 3.0 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 348.9/385.0 MB 3.0 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 349.0/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 349.0/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 349.1/385.0 MB 2.7 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 349.2/385.0 MB 2.8 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 349.3/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 349.4/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 349.4/385.0 MB 2.7 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 349.6/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 349.7/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 349.8/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 350.0/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 350.1/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 350.2/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 350.4/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 350.5/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 350.7/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 350.8/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 351.0/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 351.2/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 351.3/385.0 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 351.4/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 351.6/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 351.8/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 351.9/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 352.0/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 352.2/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 352.2/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 352.4/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 352.4/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 352.6/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 352.7/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 352.8/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 352.9/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 353.1/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 353.3/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 353.4/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 353.6/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 353.7/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 353.9/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 354.1/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 354.3/385.0 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 354.4/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 354.6/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 354.8/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 354.9/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 355.1/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 355.2/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 355.4/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 355.5/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 355.7/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 355.9/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------ --- 356.0/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 356.2/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 356.4/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 356.6/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 356.8/385.0 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 356.9/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 357.1/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 357.3/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 357.5/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 357.7/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 357.8/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 358.0/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 358.1/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 358.3/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 358.4/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 358.6/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 358.8/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 359.0/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 359.1/385.0 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 359.2/385.0 MB 3.1 MB/s eta 0:00:09\n",
      "   ------------------------------------- -- 359.4/385.0 MB 3.1 MB/s eta 0:00:09\n",
      "   ------------------------------------- -- 359.6/385.0 MB 3.2 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 359.7/385.0 MB 3.2 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 359.9/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 360.0/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 360.2/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 360.3/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 360.5/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 360.7/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 360.8/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 361.0/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 361.2/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 361.4/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 361.5/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 361.6/385.0 MB 3.3 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 361.9/385.0 MB 3.3 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 362.1/385.0 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 362.3/385.0 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 362.4/385.0 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 362.6/385.0 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 362.8/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 363.0/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 363.1/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 363.3/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 363.4/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 363.6/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 363.6/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 363.8/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 364.0/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 364.1/385.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 364.3/385.0 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 364.3/385.0 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 364.3/385.0 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 364.3/385.0 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 364.3/385.0 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 364.3/385.0 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 364.3/385.0 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 364.4/385.0 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 364.4/385.0 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 364.4/385.0 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 364.4/385.0 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 364.4/385.0 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 364.4/385.0 MB 3.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 364.4/385.0 MB 2.9 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 364.5/385.0 MB 2.9 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 364.6/385.0 MB 2.9 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 364.7/385.0 MB 2.9 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 364.8/385.0 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 364.9/385.0 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 365.0/385.0 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 365.2/385.0 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 365.3/385.0 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 365.4/385.0 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 365.5/385.0 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 365.6/385.0 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 365.8/385.0 MB 2.8 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 365.8/385.0 MB 2.8 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 365.9/385.0 MB 2.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 366.0/385.0 MB 2.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 366.2/385.0 MB 2.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 366.3/385.0 MB 2.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 366.4/385.0 MB 2.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 366.5/385.0 MB 2.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 366.6/385.0 MB 2.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 366.7/385.0 MB 2.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 366.9/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.0/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.1/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.3/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.4/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.5/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.6/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.7/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.8/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.9/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.9/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.9/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.9/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.9/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.9/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 367.9/385.0 MB 2.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 368.0/385.0 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.0/385.0 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.0/385.0 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.0/385.0 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.0/385.0 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.0/385.0 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.0/385.0 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.0/385.0 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.2/385.0 MB 2.2 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.2/385.0 MB 2.2 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.3/385.0 MB 2.2 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.4/385.0 MB 2.2 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.5/385.0 MB 2.2 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.6/385.0 MB 2.2 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.7/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.8/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.9/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 368.9/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 369.1/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 369.2/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 369.3/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 369.4/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 369.5/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 369.6/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 369.7/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 369.8/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 369.9/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 370.1/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 370.2/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 370.3/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 370.4/385.0 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 370.5/385.0 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 370.6/385.0 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 370.8/385.0 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 370.9/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 371.0/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 371.1/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 371.3/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 371.4/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 371.5/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 371.7/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 371.8/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 371.9/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 372.0/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 372.2/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 372.3/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 372.4/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 372.6/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 372.7/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 372.8/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 373.0/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 373.1/385.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 373.2/385.0 MB 1.9 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 373.4/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.5/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.6/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.7/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.9/385.0 MB 2.0 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.9/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.9/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.9/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.9/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.9/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.9/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 373.9/385.0 MB 1.9 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.0/385.0 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 374.1/385.0 MB 1.6 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 374.1/385.0 MB 1.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 374.2/385.0 MB 1.6 MB/s eta 0:00:08\n",
      "   -------------------------------------- - 374.3/385.0 MB 1.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 374.4/385.0 MB 1.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 374.5/385.0 MB 1.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 374.5/385.0 MB 1.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 374.6/385.0 MB 1.6 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 374.7/385.0 MB 1.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 374.8/385.0 MB 1.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 374.9/385.0 MB 1.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 375.0/385.0 MB 1.7 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 375.1/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 375.3/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 375.4/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.4/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.5/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.5/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.7/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.8/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.8/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.8/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.8/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.8/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.8/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.8/385.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.9/385.0 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.9/385.0 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.9/385.0 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.9/385.0 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.9/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  375.9/385.0 MB 1.5 MB/s eta 0:00:07\n",
      "   ---------------------------------------  375.9/385.0 MB 1.5 MB/s eta 0:00:07\n",
      "   ---------------------------------------  376.0/385.0 MB 1.5 MB/s eta 0:00:07\n",
      "   ---------------------------------------  376.1/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  376.1/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  376.2/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  376.3/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  376.4/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  376.5/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  376.7/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  376.8/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  376.9/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  377.0/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  377.1/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  377.3/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  377.5/385.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------------------------------------  377.7/385.0 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------------------------------------  377.8/385.0 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------------------------------------  378.0/385.0 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------------------------------------  378.1/385.0 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------------------------------------  378.3/385.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------------------------  378.6/385.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------------------------  378.8/385.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------------------------  378.9/385.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------------------------  379.0/385.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------------------------  379.4/385.0 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------------------------------  379.6/385.0 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------------------------------  379.8/385.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  380.0/385.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  380.2/385.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  380.4/385.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  380.5/385.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  380.6/385.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  380.8/385.0 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------------------  381.1/385.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  381.2/385.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  381.3/385.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  381.4/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  381.4/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  381.7/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  381.8/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  382.0/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  382.1/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  382.2/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  382.4/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  382.5/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  382.6/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  382.8/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  382.9/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  383.0/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  383.1/385.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  383.3/385.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  383.4/385.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  383.6/385.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  383.7/385.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  383.9/385.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.1/385.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.1/385.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.1/385.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.4/385.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.5/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.6/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.7/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.9/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.0/385.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 385.0/385.0 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.66.2-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/4.3 MB 2.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.4/4.3 MB 2.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.5/4.3 MB 2.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.6/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.7/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.8/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.9/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.0/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.2/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.3/4.3 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.4/4.3 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.5/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.6/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.7/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.8/4.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.9/4.3 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.0/4.3 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.2/4.3 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.3/4.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.4/4.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.5/4.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.6/4.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.8/4.3 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.9/4.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.1/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.2/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.3/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.5/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.6/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.7/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.8/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.1/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/3.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.3/3.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.4/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.6/3.0 MB 3.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.7/3.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.9/3.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.0/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.2/3.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.3/3.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.4/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.6/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.8/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.9/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.0/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.2/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.3/3.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.4/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.6/3.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.7/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.9/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.0/3.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/26.4 MB 3.9 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.3/26.4 MB 2.8 MB/s eta 0:00:10\n",
      "    --------------------------------------- 0.4/26.4 MB 3.0 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.6/26.4 MB 3.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.7/26.4 MB 3.4 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.9/26.4 MB 3.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.0/26.4 MB 3.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.2/26.4 MB 3.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.3/26.4 MB 3.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.5/26.4 MB 3.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.6/26.4 MB 3.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.8/26.4 MB 3.1 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.9/26.4 MB 3.1 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.9/26.4 MB 3.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.0/26.4 MB 3.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.0/26.4 MB 3.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.3/26.4 MB 2.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.5/26.4 MB 2.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.5/26.4 MB 2.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.5/26.4 MB 2.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.5/26.4 MB 2.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.5/26.4 MB 2.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.5/26.4 MB 2.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.5/26.4 MB 2.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.6/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 2.7/26.4 MB 1.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.7/26.4 MB 1.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.8/26.4 MB 1.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 1.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 1.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 3.0/26.4 MB 1.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 3.1/26.4 MB 1.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 3.2/26.4 MB 1.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 3.3/26.4 MB 1.5 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 3.4/26.4 MB 1.5 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.5/26.4 MB 1.5 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.5/26.4 MB 1.5 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.8/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.9/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 4.0/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 4.0/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 4.0/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 4.1/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 4.2/26.4 MB 1.5 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 4.3/26.4 MB 1.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 4.4/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 4.5/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 4.6/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 4.7/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 4.7/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 4.7/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 4.7/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 4.7/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 4.7/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 4.7/26.4 MB 1.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 4.8/26.4 MB 1.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 4.8/26.4 MB 1.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 4.9/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 4.9/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 5.0/26.4 MB 1.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 5.0/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 5.1/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 5.2/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 5.3/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.3/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.3/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.4/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.5/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.5/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.6/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.7/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.7/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.8/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.9/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 6.0/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 6.1/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 6.1/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 6.2/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 6.3/26.4 MB 1.4 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 6.4/26.4 MB 1.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 6.4/26.4 MB 1.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 6.5/26.4 MB 1.4 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 6.6/26.4 MB 1.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 6.7/26.4 MB 1.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 6.8/26.4 MB 1.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 6.9/26.4 MB 1.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 7.0/26.4 MB 1.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 1.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 7.2/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 7.5/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 7.6/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 7.7/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 7.8/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 7.9/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 7.9/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 8.0/26.4 MB 1.5 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 8.1/26.4 MB 1.5 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 8.2/26.4 MB 1.5 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 8.3/26.4 MB 1.5 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 8.4/26.4 MB 1.5 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 8.5/26.4 MB 1.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 8.6/26.4 MB 1.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 8.7/26.4 MB 1.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 8.8/26.4 MB 1.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 8.9/26.4 MB 1.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 9.0/26.4 MB 1.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 9.1/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 9.2/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 9.3/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 9.4/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 9.5/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 9.6/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 9.7/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 9.8/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 9.9/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 10.0/26.4 MB 1.6 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 10.1/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 10.2/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 10.4/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 10.5/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 10.6/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 10.7/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 10.8/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 10.9/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 11.0/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 11.2/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 11.3/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 11.4/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 11.5/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 11.6/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 11.7/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 11.8/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 11.9/26.4 MB 1.6 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 12.1/26.4 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 12.2/26.4 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 12.3/26.4 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 12.5/26.4 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 12.6/26.4 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 12.7/26.4 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 12.7/26.4 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 12.9/26.4 MB 1.7 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 12.9/26.4 MB 1.8 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 13.0/26.4 MB 1.8 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 13.1/26.4 MB 1.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 13.3/26.4 MB 1.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 13.4/26.4 MB 1.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 13.6/26.4 MB 1.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 13.7/26.4 MB 1.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 13.8/26.4 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 13.9/26.4 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 14.0/26.4 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 14.2/26.4 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 14.3/26.4 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 14.5/26.4 MB 2.0 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 14.6/26.4 MB 2.0 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 14.8/26.4 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 14.8/26.4 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 15.0/26.4 MB 2.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 15.1/26.4 MB 2.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 15.2/26.4 MB 2.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 15.3/26.4 MB 2.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 15.5/26.4 MB 2.2 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 15.5/26.4 MB 2.2 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 15.9/26.4 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 16.0/26.4 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 16.1/26.4 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 16.3/26.4 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 16.4/26.4 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 16.5/26.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 16.7/26.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 16.8/26.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 17.0/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 17.1/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.3/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.4/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.4/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.4/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.4/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.4/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.4/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.4/26.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.5/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.5/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.5/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.5/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.5/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.5/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.5/26.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.5/26.4 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 17.6/26.4 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 17.7/26.4 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 17.7/26.4 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 17.8/26.4 MB 2.1 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 18.0/26.4 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 18.0/26.4 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 18.2/26.4 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 18.3/26.4 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 18.4/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 18.6/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 18.6/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 18.8/26.4 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 19.0/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 19.1/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 19.3/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 19.4/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 19.5/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 19.6/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 19.9/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 20.0/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 20.1/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 20.3/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 20.4/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 20.5/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 20.6/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 20.7/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 20.9/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 21.0/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 21.1/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 21.3/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 21.4/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 21.6/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 21.7/26.4 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 21.9/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.0/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.1/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.2/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.4/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.5/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.7/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.7/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.2/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.3/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.4/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.5/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.6/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.7/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.8/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.9/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 24.0/26.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 24.2/26.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.3/26.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.4/26.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.5/26.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.6/26.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.7/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.8/26.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.9/26.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.0/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.1/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.2/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.3/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.5/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.7/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.7/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.8/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.1/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.7 kB ? eta -:--:--\n",
      "   -------------------------------------- - 122.9/126.7 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 126.7/126.7 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 153.6/413.4 kB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 286.7/413.4 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  409.6/413.4 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 413.4/413.4 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/5.5 MB 2.4 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.2/5.5 MB 3.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.4/5.5 MB 2.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.5/5.5 MB 2.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 2.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 2.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.7/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.9/5.5 MB 2.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.0/5.5 MB 2.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.1/5.5 MB 2.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.2/5.5 MB 2.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.2/5.5 MB 2.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.3/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.5/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.8/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.9/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.0/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.1/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.2/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.3/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.5/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.6/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.7/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.7/5.5 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.8/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.9/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.3/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.3/5.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.5/5.5 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.6/5.5 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.7/5.5 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.8/5.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.0/5.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.3/5.5 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.4/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.8/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.1/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.3/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.2/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml_dtypes 0.5.0\n",
      "    Uninstalling ml_dtypes-0.5.0:\n",
      "      Successfully uninstalled ml_dtypes-0.5.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.2 h5py-3.12.1 libclang-18.1.1 ml-dtypes-0.4.1 opt-einsum-3.4.0 protobuf-4.25.5 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pP-mINCsY8yL",
    "outputId": "c00290da-a0b7-4161-edfc-6318a14b0541"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util import load_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist(flatten=True)\n",
    "\n",
    "plt.figure(figsize=[6, 6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.title(\"Label: %i\" % y_train[i])\n",
    "    plt.imshow(X_train[i].reshape([28, 28]), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfEUIcTtou7x"
   },
   "source": [
    "А вот так уже в почти приличном мире описывают сетки. Приличный мир будет в следующей дз. Здесь строится сетка - классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cPDAygXbY8yQ",
    "outputId": "3dbe3b6e-1752-496b-be71-1de5e4c47c20"
   },
   "outputs": [],
   "source": [
    "# Higher-level API:\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size=40):\n",
    "        super(Net, self).__init__()\n",
    "        # создайте слои нейронки nn.Linear\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], hidden_size) # размером X_train.shape[1], hidden_size - входной слой\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # hidden_size на hidden_size - скрытый слой\n",
    "        self.fc3 = nn.Linear(hidden_size, 10) # подумайте какой размер слоя должен быть на выходе\n",
    "\n",
    "    def forward(self, x):\n",
    "        # применяем ReLU к внутренним слоям\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BSuPd8FrY8yU",
    "outputId": "566c112b-60bc-459e-99b7-7f096a02c5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model outputs: \n",
      " tensor([[-2.3415, -2.2168, -2.3409, -2.2408, -2.2624, -2.2983, -2.3313, -2.2952,\n",
      "         -2.4272, -2.2874],\n",
      "        [-2.3148, -2.2084, -2.3435, -2.2279, -2.2829, -2.2920, -2.3427, -2.3154,\n",
      "         -2.4174, -2.2967],\n",
      "        [-2.3629, -2.2107, -2.3876, -2.2570, -2.2683, -2.2920, -2.2972, -2.2945,\n",
      "         -2.4232, -2.2521],\n",
      "        [-2.3201, -2.2011, -2.3832, -2.2371, -2.2691, -2.2885, -2.3089, -2.3259,\n",
      "         -2.4367, -2.2760],\n",
      "        [-2.3243, -2.2099, -2.4014, -2.2429, -2.2541, -2.3128, -2.3240, -2.3285,\n",
      "         -2.4203, -2.2300],\n",
      "        [-2.3499, -2.2445, -2.3488, -2.2378, -2.2688, -2.2990, -2.3190, -2.2557,\n",
      "         -2.4287, -2.2893],\n",
      "        [-2.3015, -2.2030, -2.4017, -2.2440, -2.2562, -2.3369, -2.2882, -2.3409,\n",
      "         -2.4379, -2.2403],\n",
      "        [-2.2985, -2.2536, -2.3818, -2.2054, -2.2829, -2.3158, -2.3152, -2.3121,\n",
      "         -2.4254, -2.2532],\n",
      "        [-2.3154, -2.2089, -2.3871, -2.2350, -2.2547, -2.3306, -2.3227, -2.3298,\n",
      "         -2.4187, -2.2437],\n",
      "        [-2.3741, -2.2186, -2.3470, -2.2448, -2.2927, -2.2550, -2.3288, -2.2761,\n",
      "         -2.4157, -2.2900]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Probs: \n",
      " tensor([[0.0962, 0.1090, 0.0962, 0.1064, 0.1041, 0.1004, 0.0972, 0.1007, 0.0883,\n",
      "         0.1015],\n",
      "        [0.0988, 0.1099, 0.0960, 0.1078, 0.1020, 0.1011, 0.0961, 0.0987, 0.0892,\n",
      "         0.1006],\n",
      "        [0.0941, 0.1096, 0.0918, 0.1047, 0.1035, 0.1011, 0.1005, 0.1008, 0.0886,\n",
      "         0.1052],\n",
      "        [0.0983, 0.1107, 0.0923, 0.1068, 0.1034, 0.1014, 0.0994, 0.0977, 0.0875,\n",
      "         0.1027],\n",
      "        [0.0979, 0.1097, 0.0906, 0.1062, 0.1050, 0.0990, 0.0979, 0.0974, 0.0889,\n",
      "         0.1075],\n",
      "        [0.0954, 0.1060, 0.0955, 0.1067, 0.1034, 0.1004, 0.0984, 0.1048, 0.0882,\n",
      "         0.1013],\n",
      "        [0.1001, 0.1105, 0.0906, 0.1060, 0.1047, 0.0966, 0.1014, 0.0962, 0.0873,\n",
      "         0.1064],\n",
      "        [0.1004, 0.1050, 0.0924, 0.1102, 0.1020, 0.0987, 0.0987, 0.0991, 0.0884,\n",
      "         0.1051],\n",
      "        [0.0987, 0.1098, 0.0919, 0.1070, 0.1049, 0.0972, 0.0980, 0.0973, 0.0890,\n",
      "         0.1061],\n",
      "        [0.0931, 0.1088, 0.0957, 0.1059, 0.1010, 0.1049, 0.0974, 0.1027, 0.0893,\n",
      "         0.1013]], grad_fn=<SoftmaxBackward0>)\n",
      "Pred: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [3]\n",
      " [1]\n",
      " [3]\n",
      " [1]\n",
      " [1]]\n",
      "Truth: \n",
      " [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# model interface:\n",
    "model = Net()\n",
    "tt = torch.from_numpy(X_train[:10, :].astype(np.float32))\n",
    "output = model(tt)\n",
    "\n",
    "print('Model outputs: \\n', output)\n",
    "probs = torch.softmax(output, dim=-1)\n",
    "print('Probs: \\n', probs)\n",
    "\n",
    "pred = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "print('Pred: \\n', pred.data.numpy())\n",
    "print('Truth: \\n', y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9v9SIlDY8yZ"
   },
   "source": [
    "Тренировка сети\n",
    "\n",
    "Для тренировки сети нам требуется\n",
    "- итератор по данным\n",
    "- функция тренировки (прогон по данным, вычисление и применение градиентов)\n",
    "- функция валидации (прогон по тестовым данным, вычисление метрик)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rVfeDcF-Y8yc"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import trange\n",
    "\n",
    "# функция для итераций по минибатчам\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0nO3Ujnou7y"
   },
   "source": [
    "Обучаем также как и в случае линейной регрессии. Предсказываем результат по данным. Обучаем. В данном случае только функционал ошибки другой, не заморачивайтесь об этом. О вспомогательных функциях тоже не заморачивайтесь. Тут только надо знать что нейросети обучают батчами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qS8wn1JzY8yg"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, batchsize=32):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    for x_batch, y_batch in iterate_minibatches(X_train, y_train, batchsize=batchsize, shuffle=True):\n",
    "        # data preparation\n",
    "        data = torch.from_numpy(x_batch.astype(np.float32))\n",
    "        target = torch.from_numpy(y_batch.astype(np.int64))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # make a step\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    loss_log = []\n",
    "    model.eval()\n",
    "    for x_batch, y_batch in iterate_minibatches(X_val, y_val, batchsize=batchsize, shuffle=True):\n",
    "        # data preparation\n",
    "        data = torch.from_numpy(x_batch.astype(np.float32))\n",
    "        target = torch.from_numpy(y_batch.astype(np.int64))\n",
    "\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8vbRTCJmY8yk"
   },
   "outputs": [],
   "source": [
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    clear_output(True)\n",
    "    step = len(train_history) / len(val_history)\n",
    "    plt.figure()\n",
    "    plt.axhline(0, color='gray')\n",
    "    plt.axvline(0, color='gray')\n",
    "    plt.plot(np.arange(len(train_history)), train_history, color='orange',zorder=1)\n",
    "    plt.scatter(np.arange(step, len(val_history) * step + step, step), val_history,zorder=2)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZWEroE1_Y8yo",
    "outputId": "69fb3aae-3bfc-4ccc-9bd1-2ea71e825156"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGdCAYAAAAFcOm4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/QklEQVR4nO3deXxU5aH/8W+AEBBDFFmSyBa9ihRcMLhgBVQUBaVabUVr1bZqL1ZcClwreltr7S3eX9VrvVWpLWq91rUgYkEkyKpEEQj7IkhIAiSELQkBsj+/Pw4zySQzyewzT/J5v155ZebMWZ55cjLnO+c853kSjDFGAAAAFmsX6wIAAACEikADAACsR6ABAADWI9AAAADrEWgAAID1CDQAAMB6BBoAAGA9Ag0AALBeh1gXwB91dXXau3evkpOTlZCQEOviAAAAPxhjdOTIEaWnp6tdu8ieQ7Ei0Ozdu1d9+vSJdTEAAEAQCgoK1Lt374huw4pAk5ycLMmpkK5du4ZlnVVVVXruueckSZMnT1bHjh3Dsl4AAOAoKytTnz593MfxSLIi0LguM3Xt2jWsgaZTp07u9RJoAACIjGg0F6FRMAAAsB6BBgAAWI9AAwAArEegAQAA1iPQAAAA6xFoAACA9Qg0AADAegQaAABgPQINAACwHoEGAABYj0ADAACsR6ABAADWI9BIUvHnsS4BAAAIAYFGkkrWx7oEAAAgBAQaSZKJdQEAAEAICDQAAMB6BBpJnKEBAMBuBBpJMgQaAABsRqCRxBkaAADsRqCRRKABAMBuBBoAAGA9Ao1EGxoAACxHoJHEJScAAOxGoJFEoAEAwG4EGolLTgAAWI5AAwAArEegkcQlJwAA7EagkUSgAQDAbgQaiTY0AABYjkADAACsR6CRxCUnAADsRqCRuOQEAIDlCDSSOEMDAIDdCDQAAMB6BBoAAGA9Ao1EGxoAACxHoJFEGxoAAOxGoJFEoAEAwG4EGolLTgAAWI5AAwAArEegkcQlJwAA7EagkUSgAQDAbgQaiTY0AABYjkAjiTM0AADYjUADAACsR6CRxBkaAADsRqCRaEMDAIDlCDSSOEMDAIDdCDSSCDQAANiNQAMAAKxHoJFoQwMAgOUINJK45AQAgN0INBJnaAAAsByBRhJnaAAAsFtAgWbatGm66KKLlJycrJ49e+qmm27Stm3bWlxu6dKlyszMVKdOnXTGGWdo+vTpQRcYAACgsYACzdKlS/XAAw/oyy+/VFZWlmpqajR69GgdPXrU5zK5ubkaO3ashg8frpycHD3++ON66KGHNHPmzJALHz6coQEAwGYdApl5/vz5Hs9ff/119ezZU6tXr9aIESO8LjN9+nT17dtXL7zwgiRp4MCBWrVqlZ599lndcsstwZU63GhDAwCA1UJqQ1NaWipJ6tatm895srOzNXr0aI9p1157rVatWqXq6mqvy1RWVqqsrMzjJ7IINAAA2CzoQGOM0aRJk3T55Zdr8ODBPucrKipSr169PKb16tVLNTU1OnDggNdlpk2bppSUFPdPnz59gi2mnwg0AADYLOhAM3HiRK1fv17vvPNOi/MmJCR4PDcnLvE0nu4ydepUlZaWun8KCgqCLSYAAGgDAmpD4/Lggw9qzpw5WrZsmXr37t3svKmpqSoqKvKYVlxcrA4dOui0007zukxSUpKSkpKCKVpw6mqity0AABB2AZ2hMcZo4sSJmjVrlhYtWqSMjIwWlxk2bJiysrI8pi1YsEBDhw5VYmJiYKWNlJ0zYl0CAAAQgoACzQMPPKC33npLb7/9tpKTk1VUVKSioiIdP37cPc/UqVN11113uZ9PmDBBeXl5mjRpkrZs2aLXXntNM2bM0JQpU8L3LgAAQJsWUKB55ZVXVFpaqiuuuEJpaWnun/fee889T2FhofLz893PMzIyNG/ePC1ZskQXXHCBnn76ab344ovxc8s2AACwXkBtaIwf/bW88cYbTaaNHDlSa9asCWRTAAAAfmMsJwAAYD0CDQAAsB6BBgAAWI9AAwAArEegAQAA1iPQAAAA6xFoAACA9Qg0AADAegQaAABgPQINAACwHoEGAABYj0ADAACsR6ABAADWI9AAAADrEWgAAID1CDQAAMB6BBoAAGA9Ag0AALAegQYAAFiPQAMAAKxHoAEAANYj0AAAAOsRaAAAgPUINAAAwHoEGgAAYD0CDQAAsB6BBgAAWI9AAwAArEegAQAA1iPQAAAA6xFoAACA9Qg0AADAegQaAABgPQINAACwHoFGkjqeGusSAACAEBBoJKlLRqxLAAAAQkCgkSSZWBcAAACEgEADAACsR6CRpOO7Y10CAAAQAgKNJFXsj3UJAABACAg0AADAegQaAABgPQINAACwHoEGAABYj0ADAACsR6ABAADWI9AAAADrEWgAAID1CDQAAMB6BBoAAGA9Ag0AALAegQYAAFiPQAMAAKxHoAEAANYj0AAAAOsRaAAAgPUINAAAwHoEGgAAYD0CDQAAsB6BBgAAWI9AAwAArEegAQAA1gs40Cxbtkzjxo1Tenq6EhISNHv27GbnX7JkiRISEpr8bN26NdgyAwAAeOgQ6AJHjx7V+eefr5/+9Ke65ZZb/F5u27Zt6tq1q/t5jx49At00AACAVwEHmjFjxmjMmDEBb6hnz5465ZRTAl4OAACgJVFrQzNkyBClpaVp1KhRWrx4cbPzVlZWqqyszOMHAADAl4gHmrS0NL366quaOXOmZs2apQEDBmjUqFFatmyZz2WmTZumlJQU90+fPn0iXUwAAGCxgC85BWrAgAEaMGCA+/mwYcNUUFCgZ599ViNGjPC6zNSpUzVp0iT387KyMkINAADwKSa3bV966aXavn27z9eTkpLUtWtXjx8AAABfYhJocnJylJaWFotNAwCAVijgS07l5eXasWOH+3lubq7Wrl2rbt26qW/fvpo6dar27NmjN998U5L0wgsvqH///ho0aJCqqqr01ltvaebMmZo5c2b43gUAAGjTAg40q1at0pVXXul+7mrrcvfdd+uNN95QYWGh8vPz3a9XVVVpypQp2rNnjzp37qxBgwZp7ty5Gjt2bBiKDwAAICUYY0ysC9GSsrIypaSkqLS0NGztaaqqqjRt2jRJ0tQz/0sdf1wVlvUCAABHJI7fvjCWEwAAsB6BBgAAWI9AAwAArEegcak5HusSAACAIBFoXErWxboEAAAgSAQal6rSWJcAAAAEiUDj0q59rEsAAACCRKBxSSDQAABgKwKNW0KsCwAAAIJEoAEAANYj0AAAAOsRaNzifkgrAADgA4EGAABYj0ADAACsR6ABAADWI9AAAADrEWgAAID1CDQAAMB6BBoAAGA9Ao2LoR8aAABsRaABAADWI9AAAADrEWhcEhhtGwAAWxFoXGhDAwCAtQg0LsVLYl0CAAAQJAKNS+mWWJcAAAAEiUDjQhsaAACsRaBxoyoAALAVR3E3GgUDAGArAg0AALAegQYAAFiPQOPGJScAAGxFoAEAANYj0LjQUzAAANYi0LgknxnrEgAAgCARaNzoWA8AAFsRaAAAgPUINAAAwHoEGpfNz0h11bEuBQAACAKBpqH8D2JdAgAAEAQCTUM1R2NdAgAAEAQCDQAAsB6BBgAAWI9AAwAArEegAQAA1iPQAAAA6xFoAACA9Qg0AADAegQaAABgPQKNB0bcBgDARgQaAABgPQJNIHb8VZp/kXS8KNYlAQAADRBoPJjmX175c+nQKmn9f0anOAAAwC8EmmAwiCUAAHGFQAMAAKxHoAEAANYj0ATDtNDWBgAARBWBBgAAWI9AAwAArEeg8UBPwQAA2IhAAwAArBdwoFm2bJnGjRun9PR0JSQkaPbs2S0us3TpUmVmZqpTp04644wzNH369GDKGkdoFAwAQDwJONAcPXpU559/vv785z/7NX9ubq7Gjh2r4cOHKycnR48//rgeeughzZw5M+DCAgAAeNMh0AXGjBmjMWPG+D3/9OnT1bdvX73wwguSpIEDB2rVqlV69tlndcsttwS6eQAAgCYi3oYmOztbo0eP9ph27bXXatWqVaquro705gPEpSQAAGwU8BmaQBUVFalXr14e03r16qWamhodOHBAaWlpTZaprKxUZWWl+3lZWVmkiwkAACwWlbucEhI8b4c2J3rabTzdZdq0aUpJSXH/9OnTJ+JlDAxncgAAiCcRDzSpqakqKirymFZcXKwOHTrotNNO87rM1KlTVVpa6v4pKCiIdDEBAIDFIn7JadiwYfr44489pi1YsEBDhw5VYmKi12WSkpKUlJQU6aJ54W/HenTABwBAPAn4DE15ebnWrl2rtWvXSnJuy167dq3y8/MlOWdX7rrrLvf8EyZMUF5eniZNmqQtW7botdde04wZMzRlypTwvINIWjtV+tc5UlVprEsCAACaEXCgWbVqlYYMGaIhQ4ZIkiZNmqQhQ4boN7/5jSSpsLDQHW4kKSMjQ/PmzdOSJUt0wQUX6Omnn9aLL75oxy3bm5+RyrZJO2zvCBAAgNYt4EtOV1xxhbtRrzdvvPFGk2kjR47UmjVrAt1U9G1/Rfq3e5tON3WNJ0SlOAAAwD+M5dTQ4TXSvqWxLgUAAAgQgaaxo7u8TOSMDAAA8YxAAwAArEeg8aX6SKxLgEgxRlr2fWnlv8e6JACAMCHQ+PLPbvWPGzeCbqZRNCxQulnaPVva8WqsSwIACBMCTRMnwoqpiW0xEDn8bQGg1SHQ+MPHmFMAACA+RHzoA+t8+VOputHo3lxiAgAgrnGGxpvVD8e6BAAAIAAEmqBwxqbV4OwbALQKBBq/cNBrtT5Mk3bPiXUpAAAhItCgbavYJy27MdalAACEiEATFO56AgAgnhBo/NI4wHAJCgDanIoD0r7FtL2LUwQav7DzAkCbN/cc6bOrpPz3Y10SeEGgAQDAH5UHnd/cSBCXCDQAAMB6BBp/cL0UAIC4RqAJCgEHAIB4QqCJlZpj0tG8WJeiKVMX6xIAABAwAk2wVv67M5BlsOZkSB/1l0q3hK1IIavYL83qJX39QKxLAgBAQAg0wag+Iu14Vdr5hnS8MLh1VBQ7v/fOC1uxQvbNn6XKA9L2l2NdkgijY0QAaG0INP7YOcOzYXDDyzJcorEQbaAAoLUh0PjjaJ5UON/HixwcAaBt4XM/HhFo/FW6ObD5TR1nbwAAiBICTai89VFjjPTJhdInF1gWamhbAgCwE4EmGAktHPirDkkl66SSDc6dQ4Ha+HunwTEAAPBLh1gXwEpFC8O4skbh6PB6af2vncdn/CSM2wEAoPXiDE3IjFRXI+3+WPrqXmnP3MCXb6jqcNhKFrCWzjwBABCnOEPjt2ZatW97Qcr5D+fxtzOkWw5EpUQIFsENAFobztCEzEh574WwPAdXAABCRaCJhqoSKfsnUmGWHzP7OBOU97607GapuiyMBWusrYQr+pAAgNaGQBOyBDUfBIzTyDf379Li0cFv5ovx0u4PpU1/CH4dAAC0UgSakBkvjWkbPS/f5fl895zgNxfMbeAAALRyBJqwCPBSzbIb6x/XVUlFi6TaivAVxxhp9S+l7X8JcMG2cskJANDacJdTqLz1FByIdVOd331/KF3+fujlkaT9nzt3XknSWf8ewIK0LQEA2IkzNGHRwpkNf/p3yf/gxIMwhIqqktDX4a+6GmnlBKfRcltXskE6vi/WpQCANolAEw6NA4s7nEhacYe05+PolidoQVxyyn1T2vEXp9FyW1a6VZp3nvRhaqxLAgBtEpecQmbUJAh8PaH+8b5Foa1+73zp2O7Q1hGMqsNSx1Nbnq/CxjMSEWgrdGBF+NeJltVWSu060ss1AM7QhMWRbZFb95Ix0sr7wrvOXe9Is/tJh9b4nuef3aSCWeHdbrjUVUsVUeiNubosvI21EV5HC6T3OnF2EIAkAk0YGKnyYBhXF4WGuSt+JB3Ll5b/wHN642+5ayZHvizBmJ8pzeohHdkR5Ar8qOPqcumDFGlmj/CtE+G141Xnd8NLvADaLAKNv6IRNKLNVMe6BMEp2eD8LpgZ+W3UlEduGwAs1QqPB60AgSZUAY+u3YKwtAXgny3qWmPgBQCLEGhCtfqh8K1r31Jp+yv+z1++U/ryp1Lp5vCVAUEi0ABALHGXUzz57IrA5l8yVirbJuXPlG4Nx6CVLQzhEKwvf+b0iHzZW+FZHwAAjXCGJtoOrgrfuspO3F1VcyTIFUThVtfqI9LO16Vd/5COF0Z+ewCANolA469w9XPx6UXhWU9j0biNORimzvvjSDq2V8r/p9OLsVd+/C0D/ntzycmn8p3Somulos9iXRIArRiBxl/x3uizsplRuI/tlgo+bDlQhBraaitDWz5c5g6UPv+htP3l6G0z3vePWPriDqlogbTo6liXBEArRqBplRoFk48ypOU3SzvfaH6x6kbtcAINOPPO9TIxBgd61/vY+0kUN0qg8en43gitmDoHUI9A0yo1+qA3Jy69FGU1v9jm/w5ts0e2N51WsrHBk3jpnp4DYUCMkfZ/Eb+XNQFABBr/eTtYo3lH86SFw2NdiiDFSfiqrZJ2f+SMrRUrhfOlrMulOf1jV4aW1NVIuf9w9jkAbRKBxl/f/jXWJbDP4bWxLkEUhXjWp6JY+iRT+qZRu5+NT0vLbpIWXhna+kOx51/O75qjsStDS7ZPl7J/LH3UP9YlARAjBBo0r7bK6Q25Othbw9uIUBsFr39SOrxGWvWA5/S8t53fJetCW38gSjZGuf1RGOzjDiqgrSPQ2KZ4mfTJhdKBL8OwMj8uq6x7XFp6g7R0XBg2FyeXcfwS5XY2tcciv429nzrtpFoKX/POdTptPLw+8mUCgDChp2DblJ8YYXrhyMCXDeYswrcznN/FSwNfNm5FIlhZ0NB4yXXO71POk9LHtDx/2Rbp1PMiW6aQ2BSQAUQaZ2hsVVcV3vXt8xZYgjhgbHneaaB54Ctp95zgy2OM9MWPnEsxMdGKD5ZH82NdAkTb0QJpx9+k2opYlwSIGM7QtEo+zhY0F4K2PBvYunzJmSy1S/QxaGcAIeHACinvHefxmfc4nQOe1CeEYR4iyJgIdqzXioOVv7b9Wep4qpRxR6xLYq9550nVJVL5t9IF02JdGiAiCDTxrGBWeNcXrVvPfd7dFMBBv+E3yY/6hVKayNr1rvT1/VKvGN6F1JqV75RWP+g8bhJoLLjMFy+qS5zfhQsINGi1uOQUz5bfEtn1H8uXVk+K7Da8Ob5P+uxqKe/96G9bUlgPhCtudw4Wuz8M3zrD5av7pBV3ennBoiDgd/87nMlCFDHUSVwi0LQaQX6gb/sfqfKgf+s8XujcZRWspTc6l45y/sO5zfaL8cGvK+KifYAM8/Zqjkrf/k3a9ZZ0bE9w6wjbhzYf/gAij0DTKvk6OPpqW1Pj3y3VH6Y7d1e1OGqyj+0c+lr68h6pyleAipJjBbHdfkCCDDqxGOU80sp3xboErQDhslUp2SB985JUVxvrksQFAk1r4avL9+y7GzwJ4sOsurTptH2LAl+Py/HdsT9du+zG2G4/WNb2vByms09Zl/t+LR4v+QGRNu88adVE52wsggs0L7/8sjIyMtSpUydlZmZq+fLlPuddsmSJEhISmvxs3bo16ELDC1cfI43lvhn8OmvKvU+PdSAJla1nLLzdwl6e6wyZsOudAFZk6d/veJCXzoDW7vCaWJcgLgQcaN577z098sgjeuKJJ5STk6Phw4drzJgxys9vvm+Lbdu2qbCw0P1z1llnBV1otCTAA1bZZu/TK4pCL0pjtoehSGkYsuqq/V9u5QTnw2zFj5pbedDFAgBbBBxonn/+ed1zzz269957NXDgQL3wwgvq06ePXnnllWaX69mzp1JTU90/7du3D7rQCFLpZmcQxMY+u0ra87H/62mxvU1LB9AwHWCPRrAtTLSHaahrcJv6sd3e5/FWpuqyyJTH1/aiLh7K0JoQbtF6BRRoqqqqtHr1ao0ePdpj+ujRo7VixYpmlx0yZIjS0tI0atQoLV68OPCSomX+fLOf1Svy5QjEV/cFfwlo+0vhLUtMNTxwh/ugE2zDYg5+gBX4X5UUYKA5cOCAamtr1auX50GxV69eKiryfnkiLS1Nr776qmbOnKlZs2ZpwIABGjVqlJYt8337b2VlpcrKyjx+4IdAzrKEoq5KWjNZKswKYuFG/3jf/i0+R3Zu+AFRVysVzHZuf949R6rYH4ENNggdK37sY3TzYM9W8GEHtBnlO/2/bF11OIC+nuJfUD0FJzQ6FW2MaTLNZcCAARowYID7+bBhw1RQUKBnn31WI0aM8LrMtGnT9NRTTwVTtLbt2B7pwMrIb8c1TMLW56Xz/xD6+g6tkgo/lb7zqHRSb+dWxFDGgQq3HdOdOwlcOp8ufd/HZaFAHN8nqU7qnOY5/UC2tPH30pD/9py+e7bTM3H/2+qnheOykKlz6r/bRVKn7qGvD/GLb/KOLc9J7TpKAx6MdUnCa+8n0pKxUo/LpWt836wjyQk9/+zmPL6tyhmyxnIBnaHp3r272rdv3+RsTHFxcZOzNs259NJLtX277274p06dqtLSUvdPQYFN/YbE0OqHpAWXhNb5XVQ0+lDd8Fvpm/+Vlt3sPJ93nvTNi1EvlYeGQWHPvzxfC8fdNnU10oepTt8+tRVNg8nxvU3LITk9E4fq8HqptrL++Y5XnQ/BT+J5ZG0gTCqKpZwpzudlzbFYlyY8XJ8T26c7v/d/3vIyVSXeH1ssoEDTsWNHZWZmKivL81JDVlaWLrvsMr/Xk5OTo7S0NJ+vJyUlqWvXrh4/CEDhp9Hb1rYXwreuQ1+Hb13eFC6QVvn5jexghM901RytfxyRS1jN2DFdWtygHVzBiT5cjhdGtxwIv7pq6Yvbpe1/8f56XDT0jrHa4/WPTSvpkI4zb5KCuOQ0adIk3XnnnRo6dKiGDRumV199Vfn5+ZowYYIk5+zKnj179OabTv8nL7zwgvr3769BgwapqqpKb731lmbOnKmZM2eG952gntf2FxHi7a6pUALVygnBL9uSxdf6P2/DS0xREeyBJsjl/DqL5/qQ5CBojV1vS3nvOj9n/XusS4Ooa9vBJuBAM378eB08eFC/+93vVFhYqMGDB2vevHnq188ZEbmwsNCjT5qqqipNmTJFe/bsUefOnTVo0CDNnTtXY8eODd+7CNXAX0nbfh/rUoTPseb7BIq4UL7p7/DxzRIBCmcICeFDsqo0tOURmJYuHfBNHl61jv0iqEbBv/jFL/SLX/zC62tvvPGGx/NHH31Ujz76aDCbiZ5TBse6BG0LH6peNA4goZ4dCaCOI3UZoniZM/YXIq/mqLT1f6SjMf4yEw8qD0odu0X28pq3IWGs0/rOvDKWk+S0dkeUEGbsE+QH38anw1uMxoqXRHb9vuyd7/Sf1LAdVKyt/420/tfSt3+NdUlia/ccaWZ3adUDfi4Q5OdR4XynMT/iCoFGEgfZKDuaG+sSBOZwThQ2Eied6YV9HRFSvEza/0Vstr1kjNN/0ub/bnneaIl0I3ZbrJvq/N7eXM/1YdqvI9lTebS1krPmBBpE3xHft+wHLBoDTVbsazpt4RVS/j+DX6ep8W++QE6bexxgA/iAqvOzLDHh4/3vWxLVUnh1zMYDWus4cMGHQIJJK7zjjUAjtZp0aoWybeFd3zvtnZ58o614qfT5D4Nb9vA657S4S3WZlOdjtOxA9s21jwVelrWPSfs+8/GiafQ7UK3vA9ODMc4dhVuek8p3NX295pi0f0X8ju5evtO5dObtf9LUeb4nY6RDqz37L7IWn/etFYFGEju45bLvkuYPlQ5GuB+bcMmZ4vk8+8dN5/E3yPj8lmV8PG4kni6bBCRO/mfXTHL+np9c0PS1xddJWd+Vvvlz1Ivll8XXOZfOsoY3fW3lBGlORn1/NttedP7Hln0/umUMWKAhOoTQfXy3E1jjSrD/F3Hy/xQiAg3sl/e28+3xs1GxLklwDq+NdQma1/Dy2Dcvx64cDUXirOrRvMAb+u5b5Pz2dtfL/hNdz+/w0lA3733pkI+2WYdWO2Hj8LoAChLEgdl16bfSS8eOrsbFG37j/Hb13F0Yh+OuBSxMA8F+dpUTWA+tCblEoWsdgSRUBBqJS06tRU2YOhQMNWAsGi0d+db36/7sb64zL2G5zh3COkydMzSCS+O7R/avCP9lxGgzxgkPH/WXPuoX+e3t/0L6Yrw0/0Lvr396qdM55WdXRr4soTpaIH0+XtqfHeuSxM6BeHrvrfwybwsINGgbWvrm/fl458C2b4n0yZDQtlWUJX38b5FrbHt4nbTuP5vvEdr4ecmpJc2NxFue63xD/dc5Tr01aSsShg/XaDRc/PIn9ZeMKg8Gvx5ffcCUbvR8XrLR+3wurjNijeveWxA2df6PrBysAyud9jbeZN8p5b8vZfk/9E1ktdUDuut9t+0v5wQaSW19J2gTKg81/3r++04Py+H8VrxpWvjW1dAnF0ib/kta94SafIAXZknfzgjjxpo5QJRtrX/82ZXSzr+3vLpN08J0RrSZdRQtCmwbuW+GUI4G9fNRP98NgENtGGzqpIUjpKXf85yedbk0s4dzucyXxiHteFFg9bP0Bt+vlTdzJhKx1WKP7Q323ZwpTl9Gll+tINBIUvtOsS4BwqXh9ezC+dJXP/d/RN0NT4W3LLl+HOB98eeDxVv/OItHS1/dK5WsD37b9YUI7AxJ/vstz7Pucf9GAnYXwVc9NFM/i0ZJ+R/4v41w+vgsH3cChdBuo2y79GGaU297PvY883cg22m/42u4k9z/87yjrmS9s66v7vFv28Z4DuYY7wI9o+dtLLryXYFdRo2LEOClDJ+P93/xXf9wOsLc/VH4ihQDBBpJSr0m1iVAuMzP9Hz+7V+l97tI5TtaXnbn6+EtS12V5/OSjU64Or43gJUEeQr92O7glmty11Nz2w+ybIfXSbVVoQ2i2tJBZM/Hwa87II3qoHynj4E/jfO3L9nke1VFC6XPrvacVlcrLbux0YE3gHr/2vsQNWHf18PBmNC7YPArXDSov4/Pqh9t3rX8nAznMmqV5cMbHPwq8GWO7wl/OaKIQCNJ7drHugSItMVjor/NYwVS6Rbn8Z5/SfPOlT69WCrb4v86wtG9+qEcafUj/s3r0ZdNgrwePGsrpFUP19/h44uvb8urH5TeS5I+6OpcKol2x37lO53w4K+SDc7tyiUbgt9mXY00K1WaN9j3aPSLrmnaJ9CnQwPbXyKhLsS+Z6rLnfZWLVl0jRMkIt0mqLH1v/E+PaAvHq1EXJxtCl5Qg1MC1gn1QzlYc7/j/E4Z5PwubeYbemPfvCQd3RV6GZaHue+QLc/V38brIYgPw4/6S8lnS+MifKfU0Txp3a+lgZPqG31f84W0e3bLyy4c6TTQ3bdE+mEzjaTdvNTDoqvr78LzZ5suodxxt/AKqaY8+OUl77d0e/DjbNHsPlJ1iXT9FinlHN/zucLcoTVS90v8LWGj4vhz9iqGB+1ju6W9n0j9fyx16NzCvHucTjdTBjpfiDb8Vrr079Ipg5pZKID3ZtOlRD9xhgaIhkCCjMuqieEvR0P+tBmq8tKYev1/trzc3vm+z0Q0duQb3695O0AZo5Y/uBu8XnFAWn6LtOv/PO9gK/pM2vLHlsvnutuouqTleX1x9Unjy6qH/V/Xnjn+ncUoXur/OgOx4k5pr59/W6m+3vzdH6IeOKK4vU+GSCt/7gwk2pLZvZ0vRMcLpaXjnP6Jvrg1gI01875qjjnrD2QZCxBogLjk7wdLCLepbvhty/P488HrzZIAL/H526V+6VbnG/+m/2p53sIspxfcWT2cg0Fj/o6n1VAo7X6a4/WMlw/Lb47cHXT+2PWWtOS62G0/nhnjNMZd+7j31ysPOL/9DneSSjfXP64qCa5cayZLG56ufx5Qp432INAA1op0nxvG+8CcvhzbI2XfLR1cFfim/B2C4ev7/W+4uHh0YHdUNXTgS2fE5sZtCj5Ma3nZaLRDyHs7TgYVjcB7/ewqqTjIv5tf/xON52nwHhp2RRCMA9nO3X6bpzmhszSI9X3zkrT+ydDKIcn9Pks2SVufd3p9bqn7Cs7QtBKX+RgcEIhbpumdVGFdvQms8WzpRqdPl08vCnxb/t6REcxZFV+2POv7tQXDnDuEGt8t1biDxliNWGyMtOrB2Gw7WIdW+xf2ao9LC72MLxUNDXvCNnWB3+nUsK3euseluQN9zNhMPayaKG38XcvzFszyfF66tdHYUieWa9iOat9i39ttBQg0Lv1vi3UJgAb8PFD6CgLhuDsqkNPiNqr1o3+ijb9v5sUg+sgJGyPtmB6hVQdS/gAC3a7/c84+RFSIAbPhWa8lY6R/ntLyWZbCT/y7iytYi3x0K7J2qufzuQNbbudlaqStL0glXHICEDUhHhTDMcJzcTS/zfl7IPJzvnBd9jkcDwMPehHJy1rfehlMM1y2Nwg0ddXSsTDcGl19xOnXKFiuZRsPTnqswPm9s4Wet/fOk+acEeBGY3RpZ8er0ppfOpduWyECDWCtZj4UK730gGqlIL9x570dpe17ez0al6EieEDc/krwyzYMWsd2S/Obufy44DJp9unSwa+9twfy1o7ENd6aaziH6jKnP6OZpwVf5vIdTpupj/pHN8DWHJWyRkhbng9u+YaXt7zdjejWYH/01rt4Q5b3Q0OgAWy1/4tYlyByqkqdNgKNL51Fo83Kv74T4vaicFAIdWwoX3a9G3zfNxX7nTvQch51bjWe3Uc61EwDcddruW9Ki73cNeXRjuSE/PedccP+daJtysGvnd815VLhAt+XUmornVv3d7zq/W+6YJjvcobLgS89n3/zsnM7f87k4NbXsP2ct7vv6qqdrgk89sfWPXgnHesB8Sgv1EbqYfjgiuq3tUblXXqDc4dSj8ujWIYTYt0zr18i9LdZcXuACzT4uy2/xbkDbcsfmzlj4GO/bNxDsi+uTgm9dfiX8x++l/v2b05ALpgl3ehj3KtIaxya/GnD1Sw/xgdbdLV0eYNxzRJaOofBGRoACC/X7dbB3nYdNnF6hiYeDjwlmzwHxWzYeWBNIL3QBlDHee8GsN4Ggu2/RVLEzmrsmRv8sodyPIdmaO7Lh8dI7K37DA2BBmiNXA0aEaI4PQDEQ1uHeYPDs55v/jc864mUuhqno7yiFsYuC4Qx0qGvA1/OdQl22U2NVxhqicK8ntgg0ADwLpoj7+79lzOAZkttQ+Kt3VCs+qEJdYymWPP3rqSv7nPa5Pijoij48jTn2785HeUtGhW+dQZ7WdN1Ka+6LLjlY7W/RgmBBkB82Panlrv0N7XRKUsoonH2pNm7WuJBM8G0qsTp38Uf3/6thfG2GhygK/y8s29Tc30LeVEToeEuwqm58dDaUKNgAg2A+OHPwJfR1Nwo7fFw2Sde+WrrUrZF2v1ReEZ63vB083dRHV4rLRknlWzwPDOx49XQtx1vju32/ZppO4GGu5wAIBilG9TaDxAREcxwHcY0vVyy4TfNL/PppU4g3fsv6eRAO76Lc8FeOmppOctDOmdoACAYwfbXEqn1hCJS/dp4s/LnQSwUxIG24dm18p1BbDOOBRQ8ovi3jTECDQDE0idDYl0C6f3kwAYijba6GumAnwOYtgUtjdnU0NrH6h+32M7I7jM0XHICgLAy0lHLbpuvPSYtHRfrUvg254zo3nUXbhUH/JsvlL5p/GFDo/oQcIYGQHwJ9pbUWKg63HTa4Rzpo77RL0trZk2Y8dJGZfN/S7N6+Lf40hvCW5yA2X2GhkADIL58kBLrEvivYl/Taet/7f/yh9eHryyIvXVPNJ3W8JJPOFjecDeSCDQNtT8p1iUA0JZ8cn6sS1Cv8UCgCNyBFZHfhq8BOEEbGk8kXwBAELY8G/yyu+dINUf9m7e2mb6R2jgCDQAAoWputO+WLLsxgJkj2PeR5ZezuOTkwe4/JgAAbRVnaCxSa9pp5dFBKq4+VT0TD+viLpvUPqHtdJoEAIgku7/UE2gayrhb2vGXWJfCq/mlw/TU3p+rsLr+9r+0xP16Mv1VXZeSHcOSAQCipnJ/rEsQt7jk1NCF/yNd/oGUMjjWJfEwv3SY7s97XIXV3T2mF1WfpvvzHtf80mExKhkAIKoi2leN3WdoCDQNdegs9f2BlNS95XmjpNa001N7f35iN/NsDGbUTpLRU3t/rlrDnxIA0HZxFIxzK48OOnGZyXvLdqN2KqzuoZVHB0W3YAAAxBHa0HgT7NDsEVBcfWpY54sFGjMDACKNQBPneiZ6GSsmhPmizdbGzIQwALALgSbOXdxlk9IS96uo+rQTbWY8JahOqYkHdXGXTTEoXfNcjZkbNzNzNWZ+pd8f4jLU2BrCACAkdKyHSGqfUKcn01+VlKAEeZ4hcJ4n6Mn0V+Pu7IGtjZm5owwtqTXtlF1+rj46PELZ5efG3T4MtFWcoWnJ0JekVQ80nd6hi/9jb4ToupRsvdLvD03OGqQmHozbswb1jZm9a9iYedjJG6JYMt9aCmEJqtNTe3+ua7p+FXcBUuIyWTTYevaOfQP+sfsMDYGmJWf/wnugST5bOpwTtWJcl5Kta7p+Zc2Hko2NmW0MYS4caCOPS6jRZdO+YTOPei7qoosHGrVvFz83xgSCQGOR9gl1cXcg9cXGxsw2hjCJA2002Hr2jn0jumwLYU3quUBKW7lIT477jq4bnBbbwgWBi79BszPBRourMXPjdj8uCapTWuL+uGrMbGMIo61SdNjYHxT7RnTNLx2my7fO0O07p+nhgkd1+85punzrjLgur9d6Lq3Q/W+t0fyNhTEqWfDia0+OG36ElTjqqyYe2diY2cYQxoE2Omw8e8e+ET22hbDm69nx1MebVVtnV5ua+Nor4tWVn0pdB0jXfOE5vdtFsSmPJVyNmVMTD3pMT008GJenum0MYRxoo8PGs3fsG9FhYwhruZ6lwtIKrcw9FNVyhYo2NN50Tvd8njZaumGr8zihvWRqpZ5XSIOfkP7ZLerFs4ltjZltu6OMA2102NgfFPtGdNh4M4Hf9XykIsIlCS8CjTcXPifVlEtn3tf0tRu2SXs+lv7t51KHk6JfNgvZ1JhZsiuEcaCNDtfZu/vzHleC6jzqOl7P3rFvRIeNIczvek7uFOGShFf8nAOLJ516SiM+lE4f2/S15DOlcx7xHWaSfCd12MMVwm48dZmGnbwhrg5UDdl4mczGtkoSl1CjwcZ9w8YQ1nI9S2kpnXRxhl1XIAg04XZzkefzk3pLF70Sm7KgTeBAGz3XpWTr83Pu0TtnTNWf+vw/vXPGVH1+zj1xV8cu7BuRZ2MIa76eHU+O+451/dEkGBP/gzeUlZUpJSVFpaWl6tq1a1jWWVVVpWnTpkmSpk6dqo4dOwa3orcb/cF/ZKSZPaTKA/XPvc0HhJn1fWDIjr5GbMS+EVmuu5wk4/VyZDyGR8lHPad0Cms/NJE4fvtCG5pQnXapdPBLz2ln3S9tfDo25UGbRVsl+MK+EVm23Uzg0qSevztNF583zLozMy4EmlCNWii9f3KjiV52hquXSwuH+17P6d+T9sxxHl+/Rao5Ii27STq+N1wlBeKObQdaRI9t+4ZtIczFo577JkmWhhmJQBO6Dl2k0y6WDq6U+vzAmXb6DdLG30mJp9TP1/Ny6coF0uLRzvOuA6WyLc7jcTukLv2l3R9Kx4uklHOc6TftdgbA/PQiqWxrtN4RACAItoWw1oZAEw4j50q7Z0v9bnWen3aRdP0mp0FwQw17F878kxNuBjzi3DklSX1/0HT+xJOlK+ZJc86on96+k1RrV/8AAIA4V1sZ6xKEhLucwqFTd+nf7pUSGzR4SvmO53NJHtWddo30wzIp839aXv/JGdKYtc7jU86Xbj0mjQ7wmmzf8YHNL0kjPgp8GQCAnY7mxboEIQkq0Lz88svKyMhQp06dlJmZqeXLlzc7/9KlS5WZmalOnTrpjDPO0PTp04MqrPV6DncCSb/bneeJyf4ve+r50vf3Std97Zy56X6plJji37I37ZG++450W400vlL6zlTpjJ9Jt/u4tjtyrrPMqUP8Lx8AADEUcKB577339Mgjj+iJJ55QTk6Ohg8frjFjxig/P9/r/Lm5uRo7dqyGDx+unJwcPf7443rooYc0c+bMkAtvnXaJ0pgc6btvB7d85zRnHS7fL5RuKpAGPCxl3CXdXCxd9LJz55XLmBzppHQnBLVrL7XvKF3wB+nSGScuaZ0IRZn/W79Mj8ucZU7qLfUcKaWODq68Lj+wazwQAGiTXO06LRVwPzSXXHKJLrzwQr3ySn1ncQMHDtRNN93k7teloV/96leaM2eOtmypr6gJEyZo3bp1ys7277KJ6z72/fv3h7Ufmueee06SNHny5OD7oYlH1eXSvkVS6jVSh87Nz3u8SDr4tZQ+1hnuofa41Dm1/nXX7nFolbRuqnTgxC3qPYZL+5dLGT+V8v4hjVosZX236fp7XC5dOb/+TrCrPpNOvUAqXCCtfkCqDFPYSepe3/cPACBw50ySzvtdWFdZVlamHj16RKUfmoACTVVVlU466SR98MEH+v73v++e/vDDD2vt2rVaunRpk2VGjBihIUOG6E9/+pN72ocffqhbb71Vx44dU2JiYpNlKisrVVlZ3ziprKxMffr00WOPPaZOnewaWwIAgLaqoqJCzzzzTFQCTUCXnA4cOKDa2lr16tXLY3qvXr1UVFTkdZmioiKv89fU1OjAAe/fqKdNm6aUlBT3T58+fQIpJgAAaGOCum07IcGz4x1jTJNpLc3vbbrL1KlTNWnSJPdz1xmayZMnc8kJCERdtWe7K38Y49nFQF2NlNDec5rk3OLZPsn78lLT+QNVc1xq19Fp+xVNx4ukugqnbyhXXRgjlW2WupxRfxn38FqnblMGNS23qZXad/Ze9upySQnO5d1O3Z1pddXOdrv0kaqPSvuXSd2GSiXrnfUn9XAuCbfvJNVVOdO7ZTrPj+11LhMnnPh+6ipzVZlUUSid1Mcpi6l1/o61J+p1/+dOw/9Dq53t1hyTOpxc341E9VGpeInTuWe/26T896WK/VKfm5311FU6/WR1Pl06mnuibDVS8llSx1Od9hhH86WT+0vJZzt30HTq5ZSz8qCzfHWZ1LGbtH+F1O0CydRJpsbpp6u2yhkEuOgzqduFUvkO56aKimKn/tp1dLZ7eI3znvr92OkXLLGLU581x6R2HaTiz6UuvZ1y7npbKtngtBNMGysVL5V6jnD+DnW1UuF8Z909R0ilm6S985wy9/+Rs79X7JVOPtuZflK687dJSJQqi53OULf9r9MfWcrZUskm529RU+70U9b9u9JJp0uqc5Y9vEGqLpFOPsuZ1qGLVLrF+Tv1/K60Z55zqX/go1LXc5w6y/uHlDJYOuU85/J/x1OlLqdLiadJ+xZLeW9Lx/ZIvUZKR3c53YLUVZ9ognB1/W3Z1WVS9SGpfJfz3hJORIGTM0L972mirKxMzzzzTNjX601cXnJqLK7HcgIAAF5FcyyngC45dezYUZmZmcrKyvKYnpWVpcsuu8zrMsOGDWsy/4IFCzR06FC/wgwAAEBLAr5te9KkSfrb3/6m1157TVu2bNEvf/lL5efna8KECZKcsx133XWXe/4JEyYoLy9PkyZN0pYtW/Taa69pxowZmjJlSvjeBQAAaNMCbkMzfvx4HTx4UL/73e9UWFiowYMHa968eerXr58kqbCw0KNPmoyMDM2bN0+//OUv9dJLLyk9PV0vvviibrnllvC9CwAA0KYF3A9NLNCGBgAA+8RtGxoAAIB4RKABAADWI9AAAADrEWgAAID1CDQAAMB6BBoAAGA9Ag0AALAegQYAAFiPQAMAAKwX8NAHseDqzLisrCxs66yqqlJFRYV7vfQUDABAeLmO29EYlMCKoQ92796tPn36xLoYAAAgCAUFBerdu3dEt2FFoKmrq9PevXuVnJyshISEsK23rKxMffr0UUFBQcTHmIh31EU96qIedVGPunBQD/Woi3q+6sIYoyNHjig9PV3t2kW2lYsVl5zatWsX0WTXtWvXNr8zulAX9aiLetRFPerCQT3Uoy7qeauLlJSUqGybRsEAAMB6BBoAAGC9Nh1okpKS9OSTTyopKSnWRYk56qIedVGPuqhHXTioh3rURb14qAsrGgUDAAA0p02foQEAAK0DgQYAAFiPQAMAAKxHoAEAANZr04Hm5ZdfVkZGhjp16qTMzEwtX7481kUK2rRp03TRRRcpOTlZPXv21E033aRt27Z5zPOTn/xECQkJHj+XXnqpxzyVlZV68MEH1b17d3Xp0kXf+973tHv3bo95Dh8+rDvvvFMpKSlKSUnRnXfeqZKSkki/Rb/99re/bfI+U1NT3a8bY/Tb3/5W6enp6ty5s6644gpt2rTJYx2toR4kqX///k3qIiEhQQ888ICk1r1PLFu2TOPGjVN6eroSEhI0e/Zsj9ejuR/k5+dr3Lhx6tKli7p3766HHnpIVVVVkXjbXjVXF9XV1frVr36lc889V126dFF6erruuusu7d2712MdV1xxRZN95bbbbvOYx/a6kKL7PxHvdeHtsyMhIUF//OMf3fPE1X5h2qh3333XJCYmmr/+9a9m8+bN5uGHHzZdunQxeXl5sS5aUK699lrz+uuvm40bN5q1a9ea66+/3vTt29eUl5e757n77rvNddddZwoLC90/Bw8e9FjPhAkTzOmnn26ysrLMmjVrzJVXXmnOP/98U1NT457nuuuuM4MHDzYrVqwwK1asMIMHDzY33HBD1N5rS5588kkzaNAgj/dZXFzsfv2ZZ54xycnJZubMmWbDhg1m/PjxJi0tzZSVlbnnaQ31YIwxxcXFHvWQlZVlJJnFixcbY1r3PjFv3jzzxBNPmJkzZxpJ5sMPP/R4PVr7QU1NjRk8eLC58sorzZo1a0xWVpZJT083EydOjHgduDRXFyUlJebqq6827733ntm6davJzs42l1xyicnMzPRYx8iRI819993nsa+UlJR4zGN7XRgTvf8JG+qiYR0UFhaa1157zSQkJJhvv/3WPU887RdtNtBcfPHFZsKECR7TzjnnHPPYY4/FqEThVVxcbCSZpUuXuqfdfffd5sYbb/S5TElJiUlMTDTvvvuue9qePXtMu3btzPz5840xxmzevNlIMl9++aV7nuzsbCPJbN26NfxvJAhPPvmkOf/8872+VldXZ1JTU80zzzzjnlZRUWFSUlLM9OnTjTGtpx68efjhh82ZZ55p6urqjDFtZ59o/GEdzf1g3rx5pl27dmbPnj3ued555x2TlJRkSktLI/J+m+PtwNXYypUrjSSPL3gjR440Dz/8sM9lWktdROt/woa6aOzGG280V111lce0eNov2uQlp6qqKq1evVqjR4/2mD569GitWLEiRqUKr9LSUklSt27dPKYvWbJEPXv21Nlnn6377rtPxcXF7tdWr16t6upqj3pJT0/X4MGD3fWSnZ2tlJQUXXLJJe55Lr30UqWkpMRV3W3fvl3p6enKyMjQbbfdpp07d0qScnNzVVRU5PEek5KSNHLkSHf5W1M9NFRVVaW33npLP/vZzzwGeW0r+0RD0dwPsrOzNXjwYKWnp7vnufbaa1VZWanVq1dH9H0Gq7S0VAkJCTrllFM8pv/jH/9Q9+7dNWjQIE2ZMkVHjhxxv9aa6iIa/xO21IXLvn37NHfuXN1zzz1NXouX/cKKwSnD7cCBA6qtrVWvXr08pvfq1UtFRUUxKlX4GGM0adIkXX755Ro8eLB7+pgxY/TDH/5Q/fr1U25urn7961/rqquu0urVq5WUlKSioiJ17NhRp556qsf6GtZLUVGRevbs2WSbPXv2jJu6u+SSS/Tmm2/q7LPP1r59+/T73/9el112mTZt2uQuo7e/fV5eniS1mnpobPbs2SopKdFPfvIT97S2sk80Fs39oKioqMl2Tj31VHXs2DEu66eiokKPPfaYfvSjH3kMMnjHHXcoIyNDqamp2rhxo6ZOnap169YpKytLUuupi2j9T9hQFw39/e9/V3Jysm6++WaP6fG0X7TJQOPS8Fuq5ASBxtNsNHHiRK1fv16ff/65x/Tx48e7Hw8ePFhDhw5Vv379NHfu3CY7aUON68VbHcVT3Y0ZM8b9+Nxzz9WwYcN05pln6u9//7u7cV8wf3vb6qGxGTNmaMyYMR7fgtrKPuFLtPYDW+qnurpat912m+rq6vTyyy97vHbfffe5Hw8ePFhnnXWWhg4dqjVr1ujCCy+U1DrqIpr/E/FeFw299tpruuOOO9SpUyeP6fG0X7TJS07du3dX+/btmyS/4uLiJinRNg8++KDmzJmjxYsXq3fv3s3Om5aWpn79+mn79u2SpNTUVFVVVenw4cMe8zWsl9TUVO3bt6/Juvbv3x+3ddelSxede+652r59u/tup+b+9q2xHvLy8rRw4ULde++9zc7XVvaJaO4HqampTbZz+PBhVVdXx1X9VFdX69Zbb1Vubq6ysrI8zs54c+GFFyoxMdFjX2ktddFQpP4nbKqL5cuXa9u2bS1+fkix3S/aZKDp2LGjMjMz3afEXLKysnTZZZfFqFShMcZo4sSJmjVrlhYtWqSMjIwWlzl48KAKCgqUlpYmScrMzFRiYqJHvRQWFmrjxo3uehk2bJhKS0u1cuVK9zxfffWVSktL47buKisrtWXLFqWlpblPjTZ8j1VVVVq6dKm7/K2xHl5//XX17NlT119/fbPztZV9Ipr7wbBhw7Rx40YVFha651mwYIGSkpKUmZkZ0ffpL1eY2b59uxYuXKjTTjutxWU2bdqk6upq977SWuqisUj9T9hUFzNmzFBmZqbOP//8FueN6X7hd/PhVsZ12/aMGTPM5s2bzSOPPGK6dOlidu3aFeuiBeX+++83KSkpZsmSJR63zx07dswYY8yRI0fM5MmTzYoVK0xubq5ZvHixGTZsmDn99NOb3Kbau3dvs3DhQrNmzRpz1VVXeb0d8bzzzjPZ2dkmOzvbnHvuuTG/RbehyZMnmyVLlpidO3eaL7/80txwww0mOTnZ/bd95plnTEpKipk1a5bZsGGDuf32273ermt7PbjU1taavn37ml/96lce01v7PnHkyBGTk5NjcnJyjCTz/PPPm5ycHPedO9HaD1y3pI4aNcqsWbPGLFy40PTu3Tuqt+c2VxfV1dXme9/7nundu7dZu3atx+dHZWWlMcaYHTt2mKeeesp8/fXXJjc318ydO9ecc845ZsiQIa2qLqL5PxHvdeFSWlpqTjrpJPPKK680WT7e9os2G2iMMeall14y/fr1Mx07djQXXnihxy3OtpHk9ef11183xhhz7NgxM3r0aNOjRw+TmJho+vbta+6++26Tn5/vsZ7jx4+biRMnmm7dupnOnTubG264ock8Bw8eNHfccYdJTk42ycnJ5o477jCHDx+O0jttmas/kcTERJOenm5uvvlms2nTJvfrdXV15sknnzSpqakmKSnJjBgxwmzYsMFjHa2hHlw+/fRTI8ls27bNY3pr3ycWL17s9X/i7rvvNsZEdz/Iy8sz119/vencubPp1q2bmThxoqmoqIjk2/fQXF3k5ub6/Pxw9VeUn59vRowYYbp162Y6duxozjzzTPPQQw816Z/F9rqI9v9EPNeFy1/+8hfTuXPnJn3LGBN/+0WCMcb4fz4HAAAg/rTJNjQAAKB1IdAAAADrEWgAAID1CDQAAMB6BBoAAGA9Ag0AALAegQYAAFiPQAMAAKxHoAEAANYj0AAAAOsRaAAAgPUINAAAwHr/HyY3W2Rrfi4UAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_log = []\n",
    "val_log = []\n",
    "\n",
    "model = Net()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "batchsize = 32\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = train(model, opt, batchsize=batchsize)\n",
    "    train_log.extend(train_loss)\n",
    "\n",
    "    val_loss = np.mean(test(model))\n",
    "    val_log.append(val_loss)\n",
    "    plot_history(train_log, val_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gW6UzITY8yt"
   },
   "source": [
    "## Метрики\n",
    "\n",
    "Logloss -- величина, которую трудно интерпретировать.\n",
    "Для отслеживания тренировки и сравнения моделей удобнее наблюдать за интерпретируемыми метриками, например точностью (accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Aa9VK7d3Y8yv",
    "outputId": "82b2da4a-e3c7-44ca-f378-0e2de1b4afbd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(model, optimizer, batchsize=32):\n",
    "    loss_log, acc_log = [], []\n",
    "    model.train()\n",
    "    for x_batch, y_batch in iterate_minibatches(X_train, y_train, batchsize=batchsize, shuffle=True):\n",
    "        # data preparation\n",
    "        data = torch.from_numpy(x_batch.astype(np.float32))\n",
    "        target = torch.from_numpy(y_batch.astype(np.int64))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # make a step\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "\n",
    "        probs = torch.softmax(output, dim=-1)\n",
    "        pred = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "        acc_log.append(np.mean(pred.detach().numpy().flatten() == y_batch))\n",
    "    return loss_log, acc_log\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    loss_log, acc_log = [], []\n",
    "    model.eval()\n",
    "    for x_batch, y_batch in iterate_minibatches(X_val, y_val, batchsize=batchsize, shuffle=True):\n",
    "        # data preparation\n",
    "        data = torch.from_numpy(x_batch.astype(np.float32))\n",
    "        target = torch.from_numpy(y_batch.astype(np.int64))\n",
    "\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "\n",
    "        probs = torch.softmax(output, dim=-1)\n",
    "        pred = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "        acc_log.append(np.mean(pred.detach().numpy().flatten() == y_batch))\n",
    "    return loss_log, acc_log\n",
    "\n",
    "\n",
    "train_log, train_acc_log = [], []\n",
    "val_log, val_acc_log = [], []\n",
    "\n",
    "model = Net()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "batchsize = 32\n",
    "\n",
    "\n",
    "train_log = []\n",
    "val_log = []\n",
    "\n",
    "model = Net()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "batchsize = 32\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train(model, opt, batchsize=batchsize)\n",
    "    train_log.extend(train_acc)\n",
    "\n",
    "    val_loss, val_acc = test(model)\n",
    "    val_log.append(np.mean(val_acc))\n",
    "\n",
    "    plot_history(train_log, val_log, title = 'acc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "hse_dl_year": 2019,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
